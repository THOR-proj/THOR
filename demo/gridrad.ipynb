{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import time\n",
    "import multiprocessing\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import numpy as np\n",
    "import thor.data as data\n",
    "import thor.data.dispatch as dispatch\n",
    "import thor.grid as grid\n",
    "import thor.option as option\n",
    "import thor.track as track\n",
    "import thor.analyze as analyze\n",
    "import thor.parallel as parallel\n",
    "import thor.visualize as visualize\n",
    "import thor.log as log\n",
    "\n",
    "notebook_name = \"gridrad_demo.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parent directory for saving outputs\n",
    "base_local = Path.home() / \"THOR_output\"\n",
    "start = \"2010-01-20T18:00:00\"\n",
    "end = \"2010-01-20T03:30:00\"\n",
    "event_start = \"2010-01-20\"\n",
    "\n",
    "period = parallel.get_period(start, end)\n",
    "intervals = parallel.get_time_intervals(start, end, period=period)\n",
    "\n",
    "output_parent = base_local / f\"runs/gridrad_demo_{event_start.replace('-', '')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 17:49:06,226 - thor.grid - WARNING - Shape not specified. Will attempt to infer from input.\n"
     ]
    }
   ],
   "source": [
    "if output_parent.exists():\n",
    "    shutil.rmtree(output_parent)\n",
    "options_directory = output_parent / \"options\"\n",
    "\n",
    "# Create the data_options dictionary\n",
    "converted_options = {\"save\": True, \"load\": False, \"parent_converted\": None}\n",
    "gridrad_options = data.gridrad.gridrad_data_options(\n",
    "    start=start, end=end, converted_options=converted_options, event_start=event_start\n",
    ")\n",
    "lon_range = [-102, -89]\n",
    "lat_range = [27, 39]\n",
    "era5_pl_options = data.era5.data_options(\n",
    "    start=start, end=end, longitude_range=lon_range, latitude_range=lat_range\n",
    ")\n",
    "args_dict = {\"start\": start, \"end\": end, \"data_format\": \"single-levels\"}\n",
    "args_dict.update({\"longitude_range\": lon_range, \"latitude_range\": lat_range})\n",
    "era5_sl_options = data.era5.data_options(**args_dict)\n",
    "\n",
    "data_options = option.consolidate_options(\n",
    "    [gridrad_options, era5_pl_options, era5_sl_options]\n",
    ")\n",
    "# for testing, ignore the era5 data\n",
    "# data_options = option.consolidate_options([gridrad_options])\n",
    "\n",
    "dispatch.check_data_options(data_options)\n",
    "data.option.save_data_options(data_options, options_directory=options_directory)\n",
    "gridrad_options = data_options[\"gridrad\"]\n",
    "\n",
    "# Create the grid_options dictionary using the first file in the cpol dataset\n",
    "grid_options = grid.create_options(\n",
    "    name=\"geographic\", regrid=False, altitude_spacing=None, geographic_spacing=None\n",
    ")\n",
    "grid.check_options(grid_options)\n",
    "grid.save_grid_options(grid_options, options_directory=options_directory)\n",
    "\n",
    "# Create the track_options dictionary\n",
    "track_options = option.default_track_options(dataset=\"gridrad\")\n",
    "# Modify the default options for gridrad. Because grids so large we now use a distinct\n",
    "# global flow box for each object.\n",
    "track_options.levels[1].objects[0].tracking.global_flow_margin = 70\n",
    "track_options.levels[1].objects[0].tracking.unique_global_flow = False\n",
    "# If testing, remove the profile and tag attributes\n",
    "track_options.levels[1].objects[0].attributes[\"mcs\"].pop(\"profile\")\n",
    "track_options.levels[1].objects[0].attributes[\"mcs\"].pop(\"tag\")\n",
    "track_options.to_yaml(options_directory / \"track.yml\")\n",
    "\n",
    "# Create the display_options dictionary\n",
    "visualize_options = {\n",
    "    obj: visualize.option.runtime_options(obj, save=True, style=\"presentation\")\n",
    "    for obj in [\"mcs\"]\n",
    "}\n",
    "visualize_options = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n"
     ]
    }
   ],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 17:30:44,018 - thor.track - INFO - Beginning thor run. Saving output to /home/ewan/THOR_output/runs/gridrad_demo_20100121.\n",
      "2024-10-21 17:30:44,024 - thor.track - INFO - Beginning simultaneous tracking.\n",
      "2024-10-21 17:30:44,083 - thor.track - INFO - Processing 2010-01-21T12:00:00.\n",
      "2024-10-21 17:30:44,084 - thor.data.gridrad - INFO - Updating gridrad dataset for 2010-01-21T12:00:00.\n",
      "2024-10-21 17:30:44,085 - thor.data.gridrad - INFO - Converting gridrad data from nexrad_3d_v4_2_20100121T120000Z.nc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   117   1825.5 MiB   1825.5 MiB           1   @profile\n",
      "   118                                         def reshape_variable(ds, variable):\n",
      "   119                                             \"\"\"\n",
      "   120                                             Reshape a variable in a GridRad dataset to a 3D grid. Adapted from code provided by\n",
      "   121                                             Stacey Hitchcock.\n",
      "   122                                             \"\"\"\n",
      "   123                                         \n",
      "   124   1836.3 MiB     10.9 MiB           1       values = ds[variable].values\n",
      "   125   1836.3 MiB      0.0 MiB           1       attrs = ds[variable].attrs\n",
      "   126   1836.3 MiB      0.0 MiB           1       alt, lat, lon = ds[\"Altitude\"], ds[\"Latitude\"], ds[\"Longitude\"]\n",
      "   127   1836.3 MiB      0.0 MiB           1       new_values = np.zeros(len(alt) * len(lat) * len(lon))\n",
      "   128   2070.0 MiB    233.6 MiB           1       new_values[ds.index.values] = values\n",
      "   129   2171.0 MiB    101.0 MiB           1       new_values = new_values.astype(ds[variable].dtype)\n",
      "   130   2171.0 MiB      0.0 MiB           1       new_shape = (len(alt), len(lat), len(lon))\n",
      "   131   2171.0 MiB      0.0 MiB           1       new_dims = [\"Altitude\", \"Latitude\", \"Longitude\"]\n",
      "   132   2171.0 MiB      0.0 MiB           1       new_coords = {\"Altitude\": alt, \"Latitude\": lat, \"Longitude\": lon}\n",
      "   133   2171.0 MiB      0.0 MiB           2       ds[variable] = xr.DataArray(\n",
      "   134   2171.0 MiB      0.0 MiB           1           new_values.reshape(new_shape), dims=new_dims, coords=new_coords\n",
      "   135                                             )\n",
      "   136   2171.0 MiB      0.0 MiB           1       ds[variable].attrs = attrs\n",
      "   137   2171.0 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   117   2171.0 MiB   2171.0 MiB           1   @profile\n",
      "   118                                         def reshape_variable(ds, variable):\n",
      "   119                                             \"\"\"\n",
      "   120                                             Reshape a variable in a GridRad dataset to a 3D grid. Adapted from code provided by\n",
      "   121                                             Stacey Hitchcock.\n",
      "   122                                             \"\"\"\n",
      "   123                                         \n",
      "   124   2193.9 MiB     23.0 MiB           1       values = ds[variable].values\n",
      "   125   2193.9 MiB      0.0 MiB           1       attrs = ds[variable].attrs\n",
      "   126   2193.9 MiB      0.0 MiB           1       alt, lat, lon = ds[\"Altitude\"], ds[\"Latitude\"], ds[\"Longitude\"]\n",
      "   127   2193.9 MiB      0.0 MiB           1       new_values = np.zeros(len(alt) * len(lat) * len(lon))\n",
      "   128   2411.1 MiB    217.1 MiB           1       new_values[ds.index.values] = values\n",
      "   129   2512.1 MiB    101.0 MiB           1       new_values = new_values.astype(ds[variable].dtype)\n",
      "   130   2512.1 MiB      0.0 MiB           1       new_shape = (len(alt), len(lat), len(lon))\n",
      "   131   2512.1 MiB      0.0 MiB           1       new_dims = [\"Altitude\", \"Latitude\", \"Longitude\"]\n",
      "   132   2512.1 MiB      0.0 MiB           1       new_coords = {\"Altitude\": alt, \"Latitude\": lat, \"Longitude\": lon}\n",
      "   133   2512.1 MiB      0.0 MiB           2       ds[variable] = xr.DataArray(\n",
      "   134   2512.1 MiB      0.0 MiB           1           new_values.reshape(new_shape), dims=new_dims, coords=new_coords\n",
      "   135                                             )\n",
      "   136   2512.1 MiB      0.0 MiB           1       ds[variable].attrs = attrs\n",
      "   137   2512.1 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "    99   1825.5 MiB   1825.5 MiB           1   @profile\n",
      "   100                                         def open_gridrad(path, dataset_options):\n",
      "   101                                             \"\"\"\n",
      "   102                                             Open a GridRad netcdf file, converting variables with an \"Index\" dimension back to 3D\n",
      "   103                                             \"\"\"\n",
      "   104                                         \n",
      "   105   1825.5 MiB      0.0 MiB           4       kept_variables = [gridrad_names_dict[f] for f in dataset_options[\"fields\"]]\n",
      "   106   1825.5 MiB      0.0 MiB           1       kept_variables += [\"Nradobs\", \"Nradecho\", \"wReflectivity\", \"CorrelationCoefficient\"]\n",
      "   107   1825.5 MiB      0.0 MiB           1       ds = xr.open_dataset(path)\n",
      "   108   1825.5 MiB      0.0 MiB           8       kept_variables = [v for v in kept_variables if v in ds.data_vars]\n",
      "   109   1825.5 MiB      0.0 MiB          15       dropped_variables = [v for v in ds.data_vars if v not in kept_variables]\n",
      "   110   2512.1 MiB      0.0 MiB           5       for var in kept_variables:\n",
      "   111   2171.0 MiB      0.0 MiB           4           if var != \"index\" and \"Index\" in ds[var].dims:\n",
      "   112   2512.1 MiB    686.6 MiB           2               ds = reshape_variable(ds, var)\n",
      "   113   2512.1 MiB      0.0 MiB           1       ds = ds.drop_vars(dropped_variables + [\"index\"])\n",
      "   114   2512.1 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   140   2512.1 MiB   2512.1 MiB           1   @profile\n",
      "   141                                         def filter(\n",
      "   142                                             ds,\n",
      "   143                                             weight_thresh=1.5,\n",
      "   144                                             echo_frac_thresh=0.6,\n",
      "   145                                             refl_thresh=0,\n",
      "   146                                             obs_thresh=2,\n",
      "   147                                             variables=None,\n",
      "   148                                         ):\n",
      "   149                                             \"\"\"\n",
      "   150                                             Filter a GridRad dataset. Based on code from the GridRad website\n",
      "   151                                             https://gridrad.org/software.html and edits by Stacey Hitchcock.\n",
      "   152                                         \n",
      "   153                                             Parameters\n",
      "   154                                             ----------\n",
      "   155                                             ds : xarray.Dataset\n",
      "   156                                                 The GridRad dataset.\n",
      "   157                                             weight_thresh : float, optional\n",
      "   158                                                 The bin weight threshold. Default is 1.5.\n",
      "   159                                             echo_frac_thresh : float, optional\n",
      "   160                                                 The echo fraction threshold. Default is 0.6.\n",
      "   161                                             refl_thresh : float, optional\n",
      "   162                                                 The reflectivity threshold. Default is 0.\n",
      "   163                                             obs_thresh : int, optional\n",
      "   164                                                 The number of observations. Default is 2.\n",
      "   165                                         \n",
      "   166                                             Returns\n",
      "   167                                             -------\n",
      "   168                                             ds : xarray.Dataset\n",
      "   169                                                 The filtered GridRad dataset\n",
      "   170                                             \"\"\"\n",
      "   171                                         \n",
      "   172   2512.1 MiB      0.0 MiB           1       logger.debug(\"Filtering GridRad data\")\n",
      "   173                                         \n",
      "   174   2512.1 MiB      0.0 MiB           1       if variables is None:\n",
      "   175   2512.1 MiB      0.0 MiB          10           variables = [v for v in gridrad_variables if v in ds.variables]\n",
      "   176                                         \n",
      "   177                                             # echo_fraction = xr.zeros_like(ds[\"Nradecho\"]).astype(np.float32)\n",
      "   178                                             # Calcualate echo fraction efficiently using lazy loading and where\n",
      "   179   2512.1 MiB      0.0 MiB           1       kwargs = {\"keep_attrs\": True}\n",
      "   180   3307.5 MiB    -79.5 MiB           3       echo_fraction = xr.where(\n",
      "   181   3307.5 MiB    795.4 MiB           2           ds[\"Nradobs\"] > 0, ds[\"Nradecho\"] / ds[\"Nradobs\"], 0.0, **kwargs\n",
      "   182                                             )\n",
      "   183   2909.9 MiB   -397.6 MiB           1       echo_fraction = echo_fraction.astype(np.float32)\n",
      "   184                                         \n",
      "   185                                             # Get indices to filter\n",
      "   186   2989.4 MiB     79.5 MiB           1       weight_cond = xr.where(ds[\"wReflectivity\"] < weight_thresh, True, False, **kwargs)\n",
      "   187   3068.9 MiB     79.5 MiB           1       refl_cond = xr.where(ds[\"Reflectivity\"] <= refl_thresh, True, False, **kwargs)\n",
      "   188   3148.4 MiB     79.5 MiB           1       frac_cond = xr.where(echo_fraction < echo_frac_thresh, True, False, **kwargs)\n",
      "   189   3228.0 MiB     79.5 MiB           1       obs_cond = xr.where(ds[\"Nradobs\"] <= obs_thresh, True, False, **kwargs)\n",
      "   190                                             # Filter cells below weight and reflectivity thresholds\n",
      "   191   3307.5 MiB     79.5 MiB           1       cond_refl = xr.where(weight_cond & refl_cond, True, False, **kwargs)\n",
      "   192                                             # Filter cells containing at < obs_thresh observations. If at least obs_thresh\n",
      "   193                                             # observations, filter cells with echoes in less than echo_fraction_thresh of the\n",
      "   194                                             # total observations\n",
      "   195   3387.0 MiB     79.5 MiB           1       cond_frac = xr.where(obs_cond | frac_cond, True, False, **kwargs)\n",
      "   196                                             # Retain values not filtered\n",
      "   197   3466.5 MiB     79.5 MiB           1       preserved = xr.where(~cond_refl & ~cond_frac, True, False, **kwargs)\n",
      "   198   3466.8 MiB      0.0 MiB           2       for var in variables:\n",
      "   199   3466.8 MiB      0.2 MiB           1           ds[var] = ds[var].where(preserved)\n",
      "   200                                         \n",
      "   201   3466.8 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   204   2671.5 MiB   2671.5 MiB           1   @profile\n",
      "   205                                         def remove_speckles(ds, window_size=5, coverage_thresh=0.32, variables=None):\n",
      "   206                                             \"\"\"\n",
      "   207                                             Remove speckles in GridRad data. Based on code from the GridRad website\n",
      "   208                                             https://gridrad.org/software.html and edits by Stacey Hitchcock. Modified from the\n",
      "   209                                             original to use xr.rolling instead of np.roll to correctly handle edges and corners.\n",
      "   210                                             \"\"\"\n",
      "   211                                         \n",
      "   212   2671.5 MiB      0.0 MiB           1       logger.debug(\"Removing speckles from the GridRad data\")\n",
      "   213                                         \n",
      "   214   2671.5 MiB      0.0 MiB           1       if variables is None:\n",
      "   215                                                 variables = [v for v in gridrad_variables if v in ds.variables]\n",
      "   216                                         \n",
      "   217                                             # refl_exists = np.isfinite(ds[\"Reflectivity\"]).astype(float)\n",
      "   218   2750.9 MiB     79.4 MiB           1       refl_exists = xr.where(ds[\"Reflectivity\"] != np.nan, True, False)\n",
      "   219   2750.9 MiB      0.0 MiB           1       min_size = window_size**3 * coverage_thresh\n",
      "   220   2830.4 MiB     79.5 MiB           1       speckle_mask = remove_small_objects(refl_exists.values > 0, min_size=min_size)\n",
      "   221   2830.5 MiB      0.0 MiB           2       for var in variables:\n",
      "   222   2830.5 MiB      0.1 MiB           1           ds[var] = ds[var].where(speckle_mask)\n",
      "   223                                         \n",
      "   224   2830.5 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   227   2671.4 MiB   2671.4 MiB           1   @profile\n",
      "   228                                         def remove_low_level_clutter(ds, variables=None):\n",
      "   229                                             \"\"\"\n",
      "   230                                             Remove low level clutter from GridRad data. Based on code from the GridRad website\n",
      "   231                                             https://gridrad.org/software.html and edits by Stacey Hitchcock.\n",
      "   232                                             \"\"\"\n",
      "   233                                         \n",
      "   234   2671.4 MiB      0.0 MiB           1       logger.debug(\"Removing low level clutter from the GridRad data\")\n",
      "   235                                         \n",
      "   236                                             # Determine max heights of non-nan reflectivity values. If entire column is nan,\n",
      "   237                                             # set max altitude to zero.\n",
      "   238   2671.4 MiB      0.0 MiB           1       refl_max = ds.Reflectivity.max(dim=\"Altitude\", skipna=True)\n",
      "   239   3307.6 MiB    636.2 MiB           1       refl_0_alts = ds.Altitude.where(ds.Reflectivity > 0.0, 0.0)\n",
      "   240   3313.2 MiB      5.6 MiB           1       refl_0_max_alt = refl_0_alts.max(dim=\"Altitude\")\n",
      "   241   3335.0 MiB     21.8 MiB           1       refl_0_min_alt = refl_0_alts.min(dim=\"Altitude\")\n",
      "   242   3357.1 MiB     22.1 MiB           1       refl_5_max_alt = ds.Altitude.where(ds.Reflectivity > 5.0, 0.0).max(dim=\"Altitude\")\n",
      "   243   3379.0 MiB     21.9 MiB           1       refl_15_max_alt = ds.Altitude.where(ds.Reflectivity > 15.0, 0.0).max(dim=\"Altitude\")\n",
      "   244                                         \n",
      "   245                                             # Check for very weak echos below 4 km\n",
      "   246   3379.0 MiB      0.0 MiB           1       cond_1 = (refl_max < 20.0) & (refl_0_max_alt <= 4.0) & (refl_0_min_alt <= 3.0)\n",
      "   247                                             # Check for very weak echos below 5 km\n",
      "   248   3381.6 MiB      2.6 MiB           1       cond_2 = (refl_max < 10.0) & (refl_0_max_alt <= 5.0) & (refl_0_min_alt <= 3.0)\n",
      "   249                                             # Check for weak echos below 5 km. Note the > 0.0 ensures values actually exist\n",
      "   250   3384.4 MiB      2.8 MiB           1       cond_3 = (refl_5_max_alt <= 5.0) & (refl_5_max_alt > 0.0) & (refl_15_max_alt <= 3.0)\n",
      "   251                                             # Check for weak echos below 2 km\n",
      "   252   3387.1 MiB      2.8 MiB           1       cond_4 = (refl_15_max_alt < 2.0) & (refl_15_max_alt > 0.0)\n",
      "   253   3387.1 MiB      0.0 MiB           1       cond = np.logical_not(cond_1 | cond_2 | cond_3 | cond_4)\n",
      "   254   3387.2 MiB      0.0 MiB           2       for var in variables:\n",
      "   255   3387.2 MiB      0.1 MiB           1           ds[var] = ds[var].where(cond)\n",
      "   256   3387.2 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   204   2655.1 MiB   2655.1 MiB           1   @profile\n",
      "   205                                         def remove_speckles(ds, window_size=5, coverage_thresh=0.32, variables=None):\n",
      "   206                                             \"\"\"\n",
      "   207                                             Remove speckles in GridRad data. Based on code from the GridRad website\n",
      "   208                                             https://gridrad.org/software.html and edits by Stacey Hitchcock. Modified from the\n",
      "   209                                             original to use xr.rolling instead of np.roll to correctly handle edges and corners.\n",
      "   210                                             \"\"\"\n",
      "   211                                         \n",
      "   212   2655.1 MiB      0.0 MiB           1       logger.debug(\"Removing speckles from the GridRad data\")\n",
      "   213                                         \n",
      "   214   2655.1 MiB      0.0 MiB           1       if variables is None:\n",
      "   215                                                 variables = [v for v in gridrad_variables if v in ds.variables]\n",
      "   216                                         \n",
      "   217                                             # refl_exists = np.isfinite(ds[\"Reflectivity\"]).astype(float)\n",
      "   218   2734.6 MiB     79.5 MiB           1       refl_exists = xr.where(ds[\"Reflectivity\"] != np.nan, True, False)\n",
      "   219   2734.6 MiB      0.0 MiB           1       min_size = window_size**3 * coverage_thresh\n",
      "   220   2814.1 MiB     79.5 MiB           1       speckle_mask = remove_small_objects(refl_exists.values > 0, min_size=min_size)\n",
      "   221   2814.2 MiB      0.0 MiB           2       for var in variables:\n",
      "   222   2814.2 MiB      0.1 MiB           1           ds[var] = ds[var].where(speckle_mask)\n",
      "   223                                         \n",
      "   224   2814.2 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   281   2591.9 MiB   2591.9 MiB           1   @profile\n",
      "   282                                         def remove_clutter(ds, variables=None, low_level=True, below_anvil=False):\n",
      "   283                                             \"\"\"\n",
      "   284                                             Remove clutter from GridRad data. Based on code from the GridRad website\n",
      "   285                                             https://gridrad.org/software.html and edits by Stacey Hitchcock.\n",
      "   286                                         \n",
      "   287                                             Parameters\n",
      "   288                                             ----------\n",
      "   289                                             ds : xarray.Dataset\n",
      "   290                                                 The GridRad dataset.\n",
      "   291                                             variables : list, optional\n",
      "   292                                                 The variables to remove clutter from. Default is [\"Reflectivity\"].\n",
      "   293                                         \n",
      "   294                                             Returns\n",
      "   295                                             -------\n",
      "   296                                             ds : xarray.Dataset\n",
      "   297                                                 The GridRad dataset with clutter removed.\n",
      "   298                                             \"\"\"\n",
      "   299                                         \n",
      "   300   2591.9 MiB      0.0 MiB           1       logger.debug(\"Removing clutter from the GridRad data\")\n",
      "   301                                         \n",
      "   302   2591.9 MiB      0.0 MiB           1       if variables is None:\n",
      "   303   2591.9 MiB      0.0 MiB          10           variables = [v for v in gridrad_variables if v in ds.variables]\n",
      "   304                                         \n",
      "   305                                             # Remove low reflectivity low level clutter\n",
      "   306   2671.4 MiB     79.5 MiB           1       cond = (ds.Reflectivity >= 10.0) | (ds.Altitude > 4.0)\n",
      "   307   2671.5 MiB      0.0 MiB           2       for var in variables:\n",
      "   308   2671.5 MiB      0.1 MiB           1           ds[var] = ds[var].where(cond)\n",
      "   309                                         \n",
      "   310                                             # Attempt correlation based clutter removal if relevant variables exist\n",
      "   311   2671.5 MiB      0.0 MiB           1       correlation_var_list = [\"DifferentialReflectivity\", \"CorrelationCoefficient\"]\n",
      "   312   2671.5 MiB      0.0 MiB           4       if all(corr_var in ds.variables for corr_var in correlation_var_list):\n",
      "   313                                         \n",
      "   314                                                 # Require either high correlation or reflectivity\n",
      "   315                                                 cond1 = ds[\"Reflectivity\"] >= 40.0 | ds[\"r_HV\"] >= 0.9\n",
      "   316                                                 # Require moderate reflectivity or high correlation or low altitude\n",
      "   317                                                 cond2 = ds[\"Reflectivity\"] >= 25.0 | ds[\"CorrelationCoefficient\"] >= 0.95\n",
      "   318                                                 cond2 = cond2 | ds[\"Altitude\"] < 10.0\n",
      "   319                                                 # Require both conditions above be met\n",
      "   320                                                 for var in variables:\n",
      "   321                                                     ds[var] = ds[var].where(cond1 & cond2)\n",
      "   322                                         \n",
      "   323                                             # First pass at speckle removal\n",
      "   324   2671.4 MiB     -0.1 MiB           1       ds = remove_speckles(ds, variables=variables)\n",
      "   325                                         \n",
      "   326   2671.4 MiB      0.0 MiB           1       if low_level:\n",
      "   327                                                 # Remove low level clutter. Note this can remove some low level cloud/drizzle\n",
      "   328   2655.1 MiB    -16.3 MiB           1           ds = remove_low_level_clutter(ds, variables=variables)\n",
      "   329                                         \n",
      "   330   2655.1 MiB      0.0 MiB           1       if below_anvil:\n",
      "   331                                                 # Remove clutter below anvils\n",
      "   332                                                 ds = remove_clutter_below_anvils(ds, variables=variables)\n",
      "   333                                         \n",
      "   334                                             # Second pass at speckle removal\n",
      "   335   2655.1 MiB     -0.0 MiB           1       ds = remove_speckles(ds, variables=variables)\n",
      "   336                                         \n",
      "   337   2655.1 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   350   1825.5 MiB   1825.5 MiB           1   @profile\n",
      "   351                                         def convert_gridrad(time, filepath, track_options, dataset_options, grid_options):\n",
      "   352                                             \"\"\"Convert gridrad data to the standard format.\"\"\"\n",
      "   353                                         \n",
      "   354   1825.5 MiB      0.0 MiB           1       logger.debug(f\"Converting GridRad dataset at time {time}.\")\n",
      "   355                                         \n",
      "   356                                             # Open the dataset and perform preliminary filtering and decluttering\n",
      "   357   1825.5 MiB      0.0 MiB           1       lock = multiprocessing.Lock()\n",
      "   358   2512.1 MiB      0.0 MiB           2       with lock:\n",
      "   359   2512.1 MiB    686.6 MiB           1           ds = open_gridrad(filepath, dataset_options)\n",
      "   360   2591.9 MiB     79.8 MiB           1       ds = filter(ds, refl_thresh=-10)\n",
      "   361   2575.6 MiB    -16.3 MiB           1       ds = remove_clutter(ds)\n",
      "   362                                         \n",
      "   363                                             # Ensure the intended time is in the dataset\n",
      "   364   2575.6 MiB      0.0 MiB           1       if time not in ds.time.values:\n",
      "   365                                                 raise ValueError(f\"{time} not in {filepath}\")\n",
      "   366                                         \n",
      "   367                                             # Restructure the dataset\n",
      "   368   2575.6 MiB      0.0 MiB           1       names_dict = {\"Latitude\": \"latitude\", \"Longitude\": \"longitude\"}\n",
      "   369   2575.6 MiB      0.0 MiB           1       names_dict.update({\"Altitude\": \"altitude\", \"Reflectivity\": \"reflectivity\"})\n",
      "   370   2575.6 MiB      0.0 MiB           1       names_dict.update({\"Nradobs\": \"number_of_observations\"})\n",
      "   371   2575.6 MiB      0.0 MiB           1       names_dict.update({\"Nradecho\": \"number_of_echoes\"})\n",
      "   372                                         \n",
      "   373   2575.6 MiB      0.0 MiB           1       ds = ds.rename(names_dict)\n",
      "   374                                         \n",
      "   375   2575.6 MiB      0.0 MiB           4       for dim in [\"latitude\", \"longitude\", \"altitude\"]:\n",
      "   376   2575.6 MiB      0.0 MiB           3           ds[dim].attrs[\"standard_name\"] = dim\n",
      "   377   2575.6 MiB      0.0 MiB           3           ds[dim].attrs[\"long_name\"] = dim\n",
      "   378   2575.6 MiB      0.0 MiB           1       ds[\"altitude\"] = ds[\"altitude\"] * 1000  # Convert to meters\n",
      "   379   2575.6 MiB      0.0 MiB           1       kept_fields = dataset_options[\"fields\"] + [\"number_of_observations\"]\n",
      "   380   2575.6 MiB      0.0 MiB           1       kept_fields += [\"number_of_echoes\"]\n",
      "   381   2575.6 MiB      0.0 MiB           7       dropped_fields = [f for f in ds.data_vars if f not in kept_fields]\n",
      "   382   2257.6 MiB   -318.0 MiB           1       ds = ds.drop_vars(dropped_fields)\n",
      "   383                                         \n",
      "   384   2257.6 MiB      0.0 MiB           2       for field in dataset_options[\"fields\"]:\n",
      "   385   2257.6 MiB      0.0 MiB           1           ds[field] = ds[field].expand_dims(\"time\")\n",
      "   386   2257.6 MiB      0.0 MiB           1           ds[field].attrs[\"long_name\"] = field\n",
      "   387                                         \n",
      "   388   2257.6 MiB      0.0 MiB           1       spacing = [ds.latitude.delta, ds.longitude.delta]\n",
      "   389   2257.6 MiB      0.0 MiB           1       if grid_options[\"name\"] == \"geographic\":\n",
      "   390   2257.6 MiB      0.0 MiB           1           grid_options[\"latitude\"] = ds.latitude.values\n",
      "   391   2257.6 MiB      0.0 MiB           1           grid_options[\"longitude\"] = ds.longitude.values\n",
      "   392   2257.6 MiB      0.0 MiB           1           grid_options[\"altitude\"] = ds.altitude.values\n",
      "   393   2257.6 MiB      0.0 MiB           1           grid_options[\"geographic_spacing\"] = spacing\n",
      "   394   2257.6 MiB      0.0 MiB           1           grid_options[\"shape\"] = [len(ds.latitude), len(ds.longitude)]\n",
      "   395                                         \n",
      "   396   2257.6 MiB      0.0 MiB           1       ds[\"longitude\"] = ds[\"longitude\"] % 360\n",
      "   397                                         \n",
      "   398                                             # Get the domain mask associated with the given object\n",
      "   399                                             # Note the relevant domain mask is a function of how the object is detected, e.g.\n",
      "   400                                             # which levels!\n",
      "   401   2290.2 MiB     32.7 MiB           1       domain_mask = get_domain_mask(ds, track_options, dataset_options)\n",
      "   402   2257.6 MiB    -32.7 MiB           1       boundary_coords, boundary_mask = utils.get_mask_boundary(domain_mask, grid_options)\n",
      "   403   2257.6 MiB      0.0 MiB           1       ds[\"domain_mask\"] = domain_mask\n",
      "   404   2257.6 MiB      0.0 MiB           1       ds[\"boundary_mask\"] = boundary_mask\n",
      "   405                                         \n",
      "   406                                             # Don't mask the gridcell areas\n",
      "   407   2312.1 MiB     54.6 MiB           1       cell_areas = grid.get_cell_areas(grid_options)\n",
      "   408   2312.1 MiB      0.0 MiB           1       ds[\"gridcell_area\"] = ([\"latitude\", \"longitude\"], cell_areas)\n",
      "   409   2312.1 MiB      0.0 MiB           1       area_attrs = {\"units\": \"km^2\", \"standard_name\": \"area\", \"valid_min\": 0}\n",
      "   410   2312.1 MiB      0.0 MiB           1       ds[\"gridcell_area\"].attrs.update(area_attrs)\n",
      "   411                                         \n",
      "   412                                             # Apply the domain mask to the current grid\n",
      "   413   2391.7 MiB     79.6 MiB           1       ds = utils.apply_mask(ds, grid_options)\n",
      "   414   2232.7 MiB   -159.1 MiB           1       ds = ds.drop_vars([\"number_of_observations\", \"number_of_echoes\"])\n",
      "   415   2232.7 MiB      0.0 MiB           1       return ds, boundary_coords\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 17:30:57,493 - thor.track - INFO - Processing hierarchy level 0.\n",
      "2024-10-21 17:30:57,494 - thor.track - INFO - Tracking convective.\n",
      "2024-10-21 17:31:19,532 - thor.track - INFO - Tracking middle.\n",
      "2024-10-21 17:31:25,278 - thor.track - INFO - Tracking anvil.\n",
      "2024-10-21 17:31:27,757 - thor.track - INFO - Processing hierarchy level 1.\n",
      "2024-10-21 17:31:27,758 - thor.track - INFO - Tracking mcs.\n",
      "2024-10-21 17:31:39,836 - thor.match.match - INFO - Matching mcs objects.\n",
      "2024-10-21 17:31:39,858 - thor.match.match - INFO - No previous mask, or no objects in previous mask.\n",
      "2024-10-21 17:31:40,009 - thor.track - INFO - Processing 2010-01-21T12:10:00.\n",
      "2024-10-21 17:31:40,011 - thor.data.gridrad - INFO - Updating gridrad dataset for 2010-01-21T12:10:00.\n",
      "2024-10-21 17:31:40,012 - thor.data.gridrad - INFO - Converting gridrad data from nexrad_3d_v4_2_20100121T121000Z.nc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   117   2418.9 MiB   2418.9 MiB           1   @profile\n",
      "   118                                         def reshape_variable(ds, variable):\n",
      "   119                                             \"\"\"\n",
      "   120                                             Reshape a variable in a GridRad dataset to a 3D grid. Adapted from code provided by\n",
      "   121                                             Stacey Hitchcock.\n",
      "   122                                             \"\"\"\n",
      "   123                                         \n",
      "   124   2418.9 MiB      0.0 MiB           1       values = ds[variable].values\n",
      "   125   2418.9 MiB      0.0 MiB           1       attrs = ds[variable].attrs\n",
      "   126   2418.9 MiB      0.0 MiB           1       alt, lat, lon = ds[\"Altitude\"], ds[\"Latitude\"], ds[\"Longitude\"]\n",
      "   127   2418.9 MiB      0.0 MiB           1       new_values = np.zeros(len(alt) * len(lat) * len(lon))\n",
      "   128   2639.2 MiB    220.2 MiB           1       new_values[ds.index.values] = values\n",
      "   129   2737.1 MiB     97.9 MiB           1       new_values = new_values.astype(ds[variable].dtype)\n",
      "   130   2737.1 MiB      0.0 MiB           1       new_shape = (len(alt), len(lat), len(lon))\n",
      "   131   2737.1 MiB      0.0 MiB           1       new_dims = [\"Altitude\", \"Latitude\", \"Longitude\"]\n",
      "   132   2737.1 MiB      0.0 MiB           1       new_coords = {\"Altitude\": alt, \"Latitude\": lat, \"Longitude\": lon}\n",
      "   133   2737.1 MiB      0.0 MiB           2       ds[variable] = xr.DataArray(\n",
      "   134   2737.1 MiB      0.0 MiB           1           new_values.reshape(new_shape), dims=new_dims, coords=new_coords\n",
      "   135                                             )\n",
      "   136   2737.1 MiB      0.0 MiB           1       ds[variable].attrs = attrs\n",
      "   137   2737.1 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   117   2737.1 MiB   2737.1 MiB           1   @profile\n",
      "   118                                         def reshape_variable(ds, variable):\n",
      "   119                                             \"\"\"\n",
      "   120                                             Reshape a variable in a GridRad dataset to a 3D grid. Adapted from code provided by\n",
      "   121                                             Stacey Hitchcock.\n",
      "   122                                             \"\"\"\n",
      "   123                                         \n",
      "   124   2739.0 MiB      1.9 MiB           1       values = ds[variable].values\n",
      "   125   2739.0 MiB      0.0 MiB           1       attrs = ds[variable].attrs\n",
      "   126   2739.0 MiB      0.0 MiB           1       alt, lat, lon = ds[\"Altitude\"], ds[\"Latitude\"], ds[\"Longitude\"]\n",
      "   127   2739.0 MiB      0.0 MiB           1       new_values = np.zeros(len(alt) * len(lat) * len(lon))\n",
      "   128   2959.2 MiB    220.2 MiB           1       new_values[ds.index.values] = values\n",
      "   129   3057.2 MiB     98.0 MiB           1       new_values = new_values.astype(ds[variable].dtype)\n",
      "   130   3057.2 MiB      0.0 MiB           1       new_shape = (len(alt), len(lat), len(lon))\n",
      "   131   3057.2 MiB      0.0 MiB           1       new_dims = [\"Altitude\", \"Latitude\", \"Longitude\"]\n",
      "   132   3057.2 MiB      0.0 MiB           1       new_coords = {\"Altitude\": alt, \"Latitude\": lat, \"Longitude\": lon}\n",
      "   133   3057.2 MiB      0.0 MiB           2       ds[variable] = xr.DataArray(\n",
      "   134   3057.2 MiB      0.0 MiB           1           new_values.reshape(new_shape), dims=new_dims, coords=new_coords\n",
      "   135                                             )\n",
      "   136   3057.2 MiB      0.0 MiB           1       ds[variable].attrs = attrs\n",
      "   137   3057.2 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "    99   2418.9 MiB   2418.9 MiB           1   @profile\n",
      "   100                                         def open_gridrad(path, dataset_options):\n",
      "   101                                             \"\"\"\n",
      "   102                                             Open a GridRad netcdf file, converting variables with an \"Index\" dimension back to 3D\n",
      "   103                                             \"\"\"\n",
      "   104                                         \n",
      "   105   2418.9 MiB      0.0 MiB           4       kept_variables = [gridrad_names_dict[f] for f in dataset_options[\"fields\"]]\n",
      "   106   2418.9 MiB      0.0 MiB           1       kept_variables += [\"Nradobs\", \"Nradecho\", \"wReflectivity\", \"CorrelationCoefficient\"]\n",
      "   107   2418.9 MiB      0.0 MiB           1       ds = xr.open_dataset(path)\n",
      "   108   2418.9 MiB      0.0 MiB           8       kept_variables = [v for v in kept_variables if v in ds.data_vars]\n",
      "   109   2418.9 MiB      0.0 MiB          15       dropped_variables = [v for v in ds.data_vars if v not in kept_variables]\n",
      "   110   3057.2 MiB      0.0 MiB           5       for var in kept_variables:\n",
      "   111   2737.1 MiB      0.0 MiB           4           if var != \"index\" and \"Index\" in ds[var].dims:\n",
      "   112   3057.2 MiB    638.2 MiB           2               ds = reshape_variable(ds, var)\n",
      "   113   3057.2 MiB      0.0 MiB           1       ds = ds.drop_vars(dropped_variables + [\"index\"])\n",
      "   114   3057.2 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   140   3057.2 MiB   3057.2 MiB           1   @profile\n",
      "   141                                         def filter(\n",
      "   142                                             ds,\n",
      "   143                                             weight_thresh=1.5,\n",
      "   144                                             echo_frac_thresh=0.6,\n",
      "   145                                             refl_thresh=0,\n",
      "   146                                             obs_thresh=2,\n",
      "   147                                             variables=None,\n",
      "   148                                         ):\n",
      "   149                                             \"\"\"\n",
      "   150                                             Filter a GridRad dataset. Based on code from the GridRad website\n",
      "   151                                             https://gridrad.org/software.html and edits by Stacey Hitchcock.\n",
      "   152                                         \n",
      "   153                                             Parameters\n",
      "   154                                             ----------\n",
      "   155                                             ds : xarray.Dataset\n",
      "   156                                                 The GridRad dataset.\n",
      "   157                                             weight_thresh : float, optional\n",
      "   158                                                 The bin weight threshold. Default is 1.5.\n",
      "   159                                             echo_frac_thresh : float, optional\n",
      "   160                                                 The echo fraction threshold. Default is 0.6.\n",
      "   161                                             refl_thresh : float, optional\n",
      "   162                                                 The reflectivity threshold. Default is 0.\n",
      "   163                                             obs_thresh : int, optional\n",
      "   164                                                 The number of observations. Default is 2.\n",
      "   165                                         \n",
      "   166                                             Returns\n",
      "   167                                             -------\n",
      "   168                                             ds : xarray.Dataset\n",
      "   169                                                 The filtered GridRad dataset\n",
      "   170                                             \"\"\"\n",
      "   171                                         \n",
      "   172   3057.2 MiB      0.0 MiB           1       logger.debug(\"Filtering GridRad data\")\n",
      "   173                                         \n",
      "   174   3057.2 MiB      0.0 MiB           1       if variables is None:\n",
      "   175   3057.2 MiB      0.0 MiB          10           variables = [v for v in gridrad_variables if v in ds.variables]\n",
      "   176                                         \n",
      "   177                                             # echo_fraction = xr.zeros_like(ds[\"Nradecho\"]).astype(np.float32)\n",
      "   178                                             # Calcualate echo fraction efficiently using lazy loading and where\n",
      "   179   3057.2 MiB      0.0 MiB           1       kwargs = {\"keep_attrs\": True}\n",
      "   180   3852.6 MiB    -79.5 MiB           3       echo_fraction = xr.where(\n",
      "   181   3852.6 MiB    795.4 MiB           2           ds[\"Nradobs\"] > 0, ds[\"Nradecho\"] / ds[\"Nradobs\"], 0.0, **kwargs\n",
      "   182                                             )\n",
      "   183   3454.9 MiB   -397.6 MiB           1       echo_fraction = echo_fraction.astype(np.float32)\n",
      "   184                                         \n",
      "   185                                             # Get indices to filter\n",
      "   186   3534.5 MiB     79.5 MiB           1       weight_cond = xr.where(ds[\"wReflectivity\"] < weight_thresh, True, False, **kwargs)\n",
      "   187   3614.0 MiB     79.5 MiB           1       refl_cond = xr.where(ds[\"Reflectivity\"] <= refl_thresh, True, False, **kwargs)\n",
      "   188   3693.6 MiB     79.6 MiB           1       frac_cond = xr.where(echo_fraction < echo_frac_thresh, True, False, **kwargs)\n",
      "   189   3773.1 MiB     79.5 MiB           1       obs_cond = xr.where(ds[\"Nradobs\"] <= obs_thresh, True, False, **kwargs)\n",
      "   190                                             # Filter cells below weight and reflectivity thresholds\n",
      "   191   3852.7 MiB     79.5 MiB           1       cond_refl = xr.where(weight_cond & refl_cond, True, False, **kwargs)\n",
      "   192                                             # Filter cells containing at < obs_thresh observations. If at least obs_thresh\n",
      "   193                                             # observations, filter cells with echoes in less than echo_fraction_thresh of the\n",
      "   194                                             # total observations\n",
      "   195   3932.2 MiB     79.5 MiB           1       cond_frac = xr.where(obs_cond | frac_cond, True, False, **kwargs)\n",
      "   196                                             # Retain values not filtered\n",
      "   197   4011.7 MiB     79.5 MiB           1       preserved = xr.where(~cond_refl & ~cond_frac, True, False, **kwargs)\n",
      "   198   4011.8 MiB      0.0 MiB           2       for var in variables:\n",
      "   199   4011.8 MiB      0.1 MiB           1           ds[var] = ds[var].where(preserved)\n",
      "   200                                         \n",
      "   201   4011.8 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   204   3216.5 MiB   3216.5 MiB           1   @profile\n",
      "   205                                         def remove_speckles(ds, window_size=5, coverage_thresh=0.32, variables=None):\n",
      "   206                                             \"\"\"\n",
      "   207                                             Remove speckles in GridRad data. Based on code from the GridRad website\n",
      "   208                                             https://gridrad.org/software.html and edits by Stacey Hitchcock. Modified from the\n",
      "   209                                             original to use xr.rolling instead of np.roll to correctly handle edges and corners.\n",
      "   210                                             \"\"\"\n",
      "   211                                         \n",
      "   212   3216.5 MiB      0.0 MiB           1       logger.debug(\"Removing speckles from the GridRad data\")\n",
      "   213                                         \n",
      "   214   3216.5 MiB      0.0 MiB           1       if variables is None:\n",
      "   215                                                 variables = [v for v in gridrad_variables if v in ds.variables]\n",
      "   216                                         \n",
      "   217                                             # refl_exists = np.isfinite(ds[\"Reflectivity\"]).astype(float)\n",
      "   218   3296.0 MiB     79.4 MiB           1       refl_exists = xr.where(ds[\"Reflectivity\"] != np.nan, True, False)\n",
      "   219   3296.0 MiB      0.0 MiB           1       min_size = window_size**3 * coverage_thresh\n",
      "   220   3375.5 MiB     79.5 MiB           1       speckle_mask = remove_small_objects(refl_exists.values > 0, min_size=min_size)\n",
      "   221   3375.6 MiB      0.0 MiB           2       for var in variables:\n",
      "   222   3375.6 MiB      0.1 MiB           1           ds[var] = ds[var].where(speckle_mask)\n",
      "   223                                         \n",
      "   224   3375.6 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   227   3216.5 MiB   3216.5 MiB           1   @profile\n",
      "   228                                         def remove_low_level_clutter(ds, variables=None):\n",
      "   229                                             \"\"\"\n",
      "   230                                             Remove low level clutter from GridRad data. Based on code from the GridRad website\n",
      "   231                                             https://gridrad.org/software.html and edits by Stacey Hitchcock.\n",
      "   232                                             \"\"\"\n",
      "   233                                         \n",
      "   234   3216.5 MiB      0.0 MiB           1       logger.debug(\"Removing low level clutter from the GridRad data\")\n",
      "   235                                         \n",
      "   236                                             # Determine max heights of non-nan reflectivity values. If entire column is nan,\n",
      "   237                                             # set max altitude to zero.\n",
      "   238   3216.5 MiB      0.0 MiB           1       refl_max = ds.Reflectivity.max(dim=\"Altitude\", skipna=True)\n",
      "   239   3852.7 MiB    636.2 MiB           1       refl_0_alts = ds.Altitude.where(ds.Reflectivity > 0.0, 0.0)\n",
      "   240   3852.8 MiB      0.1 MiB           1       refl_0_max_alt = refl_0_alts.max(dim=\"Altitude\")\n",
      "   241   3874.6 MiB     21.8 MiB           1       refl_0_min_alt = refl_0_alts.min(dim=\"Altitude\")\n",
      "   242   3896.7 MiB     22.1 MiB           1       refl_5_max_alt = ds.Altitude.where(ds.Reflectivity > 5.0, 0.0).max(dim=\"Altitude\")\n",
      "   243   3918.6 MiB     21.9 MiB           1       refl_15_max_alt = ds.Altitude.where(ds.Reflectivity > 15.0, 0.0).max(dim=\"Altitude\")\n",
      "   244                                         \n",
      "   245                                             # Check for very weak echos below 4 km\n",
      "   246   3918.6 MiB      0.0 MiB           1       cond_1 = (refl_max < 20.0) & (refl_0_max_alt <= 4.0) & (refl_0_min_alt <= 3.0)\n",
      "   247                                             # Check for very weak echos below 5 km\n",
      "   248   3918.6 MiB      0.0 MiB           1       cond_2 = (refl_max < 10.0) & (refl_0_max_alt <= 5.0) & (refl_0_min_alt <= 3.0)\n",
      "   249                                             # Check for weak echos below 5 km. Note the > 0.0 ensures values actually exist\n",
      "   250   3918.6 MiB      0.0 MiB           1       cond_3 = (refl_5_max_alt <= 5.0) & (refl_5_max_alt > 0.0) & (refl_15_max_alt <= 3.0)\n",
      "   251                                             # Check for weak echos below 2 km\n",
      "   252   3918.6 MiB      0.0 MiB           1       cond_4 = (refl_15_max_alt < 2.0) & (refl_15_max_alt > 0.0)\n",
      "   253   3918.6 MiB      0.0 MiB           1       cond = np.logical_not(cond_1 | cond_2 | cond_3 | cond_4)\n",
      "   254   3918.7 MiB      0.0 MiB           2       for var in variables:\n",
      "   255   3918.7 MiB      0.1 MiB           1           ds[var] = ds[var].where(cond)\n",
      "   256   3918.7 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   204   3194.7 MiB   3194.7 MiB           1   @profile\n",
      "   205                                         def remove_speckles(ds, window_size=5, coverage_thresh=0.32, variables=None):\n",
      "   206                                             \"\"\"\n",
      "   207                                             Remove speckles in GridRad data. Based on code from the GridRad website\n",
      "   208                                             https://gridrad.org/software.html and edits by Stacey Hitchcock. Modified from the\n",
      "   209                                             original to use xr.rolling instead of np.roll to correctly handle edges and corners.\n",
      "   210                                             \"\"\"\n",
      "   211                                         \n",
      "   212   3194.7 MiB      0.0 MiB           1       logger.debug(\"Removing speckles from the GridRad data\")\n",
      "   213                                         \n",
      "   214   3194.7 MiB      0.0 MiB           1       if variables is None:\n",
      "   215                                                 variables = [v for v in gridrad_variables if v in ds.variables]\n",
      "   216                                         \n",
      "   217                                             # refl_exists = np.isfinite(ds[\"Reflectivity\"]).astype(float)\n",
      "   218   3274.2 MiB     79.5 MiB           1       refl_exists = xr.where(ds[\"Reflectivity\"] != np.nan, True, False)\n",
      "   219   3274.2 MiB      0.0 MiB           1       min_size = window_size**3 * coverage_thresh\n",
      "   220   3353.7 MiB     79.5 MiB           1       speckle_mask = remove_small_objects(refl_exists.values > 0, min_size=min_size)\n",
      "   221   3353.8 MiB      0.0 MiB           2       for var in variables:\n",
      "   222   3353.8 MiB      0.1 MiB           1           ds[var] = ds[var].where(speckle_mask)\n",
      "   223                                         \n",
      "   224   3353.8 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   281   3136.9 MiB   3136.9 MiB           1   @profile\n",
      "   282                                         def remove_clutter(ds, variables=None, low_level=True, below_anvil=False):\n",
      "   283                                             \"\"\"\n",
      "   284                                             Remove clutter from GridRad data. Based on code from the GridRad website\n",
      "   285                                             https://gridrad.org/software.html and edits by Stacey Hitchcock.\n",
      "   286                                         \n",
      "   287                                             Parameters\n",
      "   288                                             ----------\n",
      "   289                                             ds : xarray.Dataset\n",
      "   290                                                 The GridRad dataset.\n",
      "   291                                             variables : list, optional\n",
      "   292                                                 The variables to remove clutter from. Default is [\"Reflectivity\"].\n",
      "   293                                         \n",
      "   294                                             Returns\n",
      "   295                                             -------\n",
      "   296                                             ds : xarray.Dataset\n",
      "   297                                                 The GridRad dataset with clutter removed.\n",
      "   298                                             \"\"\"\n",
      "   299                                         \n",
      "   300   3136.9 MiB      0.0 MiB           1       logger.debug(\"Removing clutter from the GridRad data\")\n",
      "   301                                         \n",
      "   302   3136.9 MiB      0.0 MiB           1       if variables is None:\n",
      "   303   3136.9 MiB      0.0 MiB          10           variables = [v for v in gridrad_variables if v in ds.variables]\n",
      "   304                                         \n",
      "   305                                             # Remove low reflectivity low level clutter\n",
      "   306   3216.4 MiB     79.5 MiB           1       cond = (ds.Reflectivity >= 10.0) | (ds.Altitude > 4.0)\n",
      "   307   3216.5 MiB      0.0 MiB           2       for var in variables:\n",
      "   308   3216.5 MiB      0.1 MiB           1           ds[var] = ds[var].where(cond)\n",
      "   309                                         \n",
      "   310                                             # Attempt correlation based clutter removal if relevant variables exist\n",
      "   311   3216.5 MiB      0.0 MiB           1       correlation_var_list = [\"DifferentialReflectivity\", \"CorrelationCoefficient\"]\n",
      "   312   3216.5 MiB      0.0 MiB           4       if all(corr_var in ds.variables for corr_var in correlation_var_list):\n",
      "   313                                         \n",
      "   314                                                 # Require either high correlation or reflectivity\n",
      "   315                                                 cond1 = ds[\"Reflectivity\"] >= 40.0 | ds[\"r_HV\"] >= 0.9\n",
      "   316                                                 # Require moderate reflectivity or high correlation or low altitude\n",
      "   317                                                 cond2 = ds[\"Reflectivity\"] >= 25.0 | ds[\"CorrelationCoefficient\"] >= 0.95\n",
      "   318                                                 cond2 = cond2 | ds[\"Altitude\"] < 10.0\n",
      "   319                                                 # Require both conditions above be met\n",
      "   320                                                 for var in variables:\n",
      "   321                                                     ds[var] = ds[var].where(cond1 & cond2)\n",
      "   322                                         \n",
      "   323                                             # First pass at speckle removal\n",
      "   324   3216.5 MiB     -0.1 MiB           1       ds = remove_speckles(ds, variables=variables)\n",
      "   325                                         \n",
      "   326   3216.5 MiB      0.0 MiB           1       if low_level:\n",
      "   327                                                 # Remove low level clutter. Note this can remove some low level cloud/drizzle\n",
      "   328   3194.7 MiB    -21.8 MiB           1           ds = remove_low_level_clutter(ds, variables=variables)\n",
      "   329                                         \n",
      "   330   3194.7 MiB      0.0 MiB           1       if below_anvil:\n",
      "   331                                                 # Remove clutter below anvils\n",
      "   332                                                 ds = remove_clutter_below_anvils(ds, variables=variables)\n",
      "   333                                         \n",
      "   334                                             # Second pass at speckle removal\n",
      "   335   3194.7 MiB     -0.0 MiB           1       ds = remove_speckles(ds, variables=variables)\n",
      "   336                                         \n",
      "   337   3194.7 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   350   2418.9 MiB   2418.9 MiB           1   @profile\n",
      "   351                                         def convert_gridrad(time, filepath, track_options, dataset_options, grid_options):\n",
      "   352                                             \"\"\"Convert gridrad data to the standard format.\"\"\"\n",
      "   353                                         \n",
      "   354   2418.9 MiB      0.0 MiB           1       logger.debug(f\"Converting GridRad dataset at time {time}.\")\n",
      "   355                                         \n",
      "   356                                             # Open the dataset and perform preliminary filtering and decluttering\n",
      "   357   2418.9 MiB      0.0 MiB           1       lock = multiprocessing.Lock()\n",
      "   358   3057.2 MiB      0.0 MiB           2       with lock:\n",
      "   359   3057.2 MiB    638.2 MiB           1           ds = open_gridrad(filepath, dataset_options)\n",
      "   360   3136.9 MiB     79.8 MiB           1       ds = filter(ds, refl_thresh=-10)\n",
      "   361   3115.1 MiB    -21.8 MiB           1       ds = remove_clutter(ds)\n",
      "   362                                         \n",
      "   363                                             # Ensure the intended time is in the dataset\n",
      "   364   3115.1 MiB      0.0 MiB           1       if time not in ds.time.values:\n",
      "   365                                                 raise ValueError(f\"{time} not in {filepath}\")\n",
      "   366                                         \n",
      "   367                                             # Restructure the dataset\n",
      "   368   3115.1 MiB      0.0 MiB           1       names_dict = {\"Latitude\": \"latitude\", \"Longitude\": \"longitude\"}\n",
      "   369   3115.1 MiB      0.0 MiB           1       names_dict.update({\"Altitude\": \"altitude\", \"Reflectivity\": \"reflectivity\"})\n",
      "   370   3115.1 MiB      0.0 MiB           1       names_dict.update({\"Nradobs\": \"number_of_observations\"})\n",
      "   371   3115.1 MiB      0.0 MiB           1       names_dict.update({\"Nradecho\": \"number_of_echoes\"})\n",
      "   372                                         \n",
      "   373   3115.1 MiB      0.0 MiB           1       ds = ds.rename(names_dict)\n",
      "   374                                         \n",
      "   375   3115.1 MiB      0.0 MiB           4       for dim in [\"latitude\", \"longitude\", \"altitude\"]:\n",
      "   376   3115.1 MiB      0.0 MiB           3           ds[dim].attrs[\"standard_name\"] = dim\n",
      "   377   3115.1 MiB      0.0 MiB           3           ds[dim].attrs[\"long_name\"] = dim\n",
      "   378   3115.1 MiB      0.0 MiB           1       ds[\"altitude\"] = ds[\"altitude\"] * 1000  # Convert to meters\n",
      "   379   3115.1 MiB      0.0 MiB           1       kept_fields = dataset_options[\"fields\"] + [\"number_of_observations\"]\n",
      "   380   3115.1 MiB      0.0 MiB           1       kept_fields += [\"number_of_echoes\"]\n",
      "   381   3115.1 MiB      0.0 MiB           7       dropped_fields = [f for f in ds.data_vars if f not in kept_fields]\n",
      "   382   2797.1 MiB   -318.0 MiB           1       ds = ds.drop_vars(dropped_fields)\n",
      "   383                                         \n",
      "   384   2797.1 MiB      0.0 MiB           2       for field in dataset_options[\"fields\"]:\n",
      "   385   2797.1 MiB      0.0 MiB           1           ds[field] = ds[field].expand_dims(\"time\")\n",
      "   386   2797.1 MiB      0.0 MiB           1           ds[field].attrs[\"long_name\"] = field\n",
      "   387                                         \n",
      "   388   2797.1 MiB      0.0 MiB           1       spacing = [ds.latitude.delta, ds.longitude.delta]\n",
      "   389   2797.1 MiB      0.0 MiB           1       if grid_options[\"name\"] == \"geographic\":\n",
      "   390   2797.1 MiB      0.0 MiB           1           grid_options[\"latitude\"] = ds.latitude.values\n",
      "   391   2797.1 MiB      0.0 MiB           1           grid_options[\"longitude\"] = ds.longitude.values\n",
      "   392   2797.1 MiB      0.0 MiB           1           grid_options[\"altitude\"] = ds.altitude.values\n",
      "   393   2797.1 MiB      0.0 MiB           1           grid_options[\"geographic_spacing\"] = spacing\n",
      "   394   2797.1 MiB      0.0 MiB           1           grid_options[\"shape\"] = [len(ds.latitude), len(ds.longitude)]\n",
      "   395                                         \n",
      "   396   2797.1 MiB      0.0 MiB           1       ds[\"longitude\"] = ds[\"longitude\"] % 360\n",
      "   397                                         \n",
      "   398                                             # Get the domain mask associated with the given object\n",
      "   399                                             # Note the relevant domain mask is a function of how the object is detected, e.g.\n",
      "   400                                             # which levels!\n",
      "   401   2818.8 MiB     21.7 MiB           1       domain_mask = get_domain_mask(ds, track_options, dataset_options)\n",
      "   402   2797.0 MiB    -21.8 MiB           1       boundary_coords, boundary_mask = utils.get_mask_boundary(domain_mask, grid_options)\n",
      "   403   2797.0 MiB      0.0 MiB           1       ds[\"domain_mask\"] = domain_mask\n",
      "   404   2797.0 MiB      0.0 MiB           1       ds[\"boundary_mask\"] = boundary_mask\n",
      "   405                                         \n",
      "   406                                             # Don't mask the gridcell areas\n",
      "   407   2797.0 MiB      0.0 MiB           1       cell_areas = grid.get_cell_areas(grid_options)\n",
      "   408   2797.0 MiB      0.0 MiB           1       ds[\"gridcell_area\"] = ([\"latitude\", \"longitude\"], cell_areas)\n",
      "   409   2797.0 MiB      0.0 MiB           1       area_attrs = {\"units\": \"km^2\", \"standard_name\": \"area\", \"valid_min\": 0}\n",
      "   410   2797.0 MiB      0.0 MiB           1       ds[\"gridcell_area\"].attrs.update(area_attrs)\n",
      "   411                                         \n",
      "   412                                             # Apply the domain mask to the current grid\n",
      "   413   2876.6 MiB     79.5 MiB           1       ds = utils.apply_mask(ds, grid_options)\n",
      "   414   2717.5 MiB   -159.1 MiB           1       ds = ds.drop_vars([\"number_of_observations\", \"number_of_echoes\"])\n",
      "   415   2717.5 MiB      0.0 MiB           1       return ds, boundary_coords\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 17:31:53,408 - thor.data.era5 - INFO - Updating era5_pl dataset for 2010-01-21T12:00:00.\n",
      "2024-10-21 17:31:55,278 - thor.data.era5 - INFO - Updating era5_sl dataset for 2010-01-21T12:00:00.\n",
      "2024-10-21 17:31:55,439 - thor.track - INFO - Processing hierarchy level 0.\n",
      "2024-10-21 17:31:55,440 - thor.track - INFO - Tracking convective.\n",
      "2024-10-21 17:32:17,086 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:32:17,089 - thor.track - INFO - Tracking middle.\n",
      "2024-10-21 17:32:23,404 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:32:23,406 - thor.track - INFO - Tracking anvil.\n",
      "2024-10-21 17:32:25,662 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:32:25,663 - thor.track - INFO - Processing hierarchy level 1.\n",
      "2024-10-21 17:32:25,664 - thor.track - INFO - Tracking mcs.\n",
      "2024-10-21 17:32:25,693 - thor.write.mask - INFO - Writing mcs masks to /home/ewan/THOR_output/runs/gridrad_demo_20100121/masks/mcs.zarr.\n",
      "2024-10-21 17:32:38,145 - thor.match.match - INFO - Matching mcs objects.\n",
      "2024-10-21 17:32:38,588 - thor.match.match - INFO - New matchable objects. Initializing object record.\n",
      "2024-10-21 17:32:38,725 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:32:39,309 - thor.track - INFO - Processing 2010-01-21T12:20:00.\n",
      "2024-10-21 17:32:39,310 - thor.data.gridrad - INFO - Updating gridrad dataset for 2010-01-21T12:20:00.\n",
      "2024-10-21 17:32:39,311 - thor.data.gridrad - INFO - Converting gridrad data from nexrad_3d_v4_2_20100121T122000Z.nc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   117   2993.3 MiB   2993.3 MiB           1   @profile\n",
      "   118                                         def reshape_variable(ds, variable):\n",
      "   119                                             \"\"\"\n",
      "   120                                             Reshape a variable in a GridRad dataset to a 3D grid. Adapted from code provided by\n",
      "   121                                             Stacey Hitchcock.\n",
      "   122                                             \"\"\"\n",
      "   123                                         \n",
      "   124   2993.3 MiB      0.0 MiB           1       values = ds[variable].values\n",
      "   125   2993.3 MiB      0.0 MiB           1       attrs = ds[variable].attrs\n",
      "   126   2993.3 MiB      0.0 MiB           1       alt, lat, lon = ds[\"Altitude\"], ds[\"Latitude\"], ds[\"Longitude\"]\n",
      "   127   2993.3 MiB      0.0 MiB           1       new_values = np.zeros(len(alt) * len(lat) * len(lon))\n",
      "   128   3227.3 MiB    234.0 MiB           1       new_values[ds.index.values] = values\n",
      "   129   3322.7 MiB     95.4 MiB           1       new_values = new_values.astype(ds[variable].dtype)\n",
      "   130   3322.7 MiB      0.0 MiB           1       new_shape = (len(alt), len(lat), len(lon))\n",
      "   131   3322.7 MiB      0.0 MiB           1       new_dims = [\"Altitude\", \"Latitude\", \"Longitude\"]\n",
      "   132   3322.7 MiB      0.0 MiB           1       new_coords = {\"Altitude\": alt, \"Latitude\": lat, \"Longitude\": lon}\n",
      "   133   3322.7 MiB      0.0 MiB           2       ds[variable] = xr.DataArray(\n",
      "   134   3322.7 MiB      0.0 MiB           1           new_values.reshape(new_shape), dims=new_dims, coords=new_coords\n",
      "   135                                             )\n",
      "   136   3322.7 MiB      0.0 MiB           1       ds[variable].attrs = attrs\n",
      "   137   3322.7 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   117   3322.7 MiB   3322.7 MiB           1   @profile\n",
      "   118                                         def reshape_variable(ds, variable):\n",
      "   119                                             \"\"\"\n",
      "   120                                             Reshape a variable in a GridRad dataset to a 3D grid. Adapted from code provided by\n",
      "   121                                             Stacey Hitchcock.\n",
      "   122                                             \"\"\"\n",
      "   123                                         \n",
      "   124   3322.7 MiB      0.0 MiB           1       values = ds[variable].values\n",
      "   125   3322.7 MiB      0.0 MiB           1       attrs = ds[variable].attrs\n",
      "   126   3322.7 MiB      0.0 MiB           1       alt, lat, lon = ds[\"Altitude\"], ds[\"Latitude\"], ds[\"Longitude\"]\n",
      "   127   3322.7 MiB      0.0 MiB           1       new_values = np.zeros(len(alt) * len(lat) * len(lon))\n",
      "   128   3545.6 MiB    222.9 MiB           1       new_values[ds.index.values] = values\n",
      "   129   3641.0 MiB     95.4 MiB           1       new_values = new_values.astype(ds[variable].dtype)\n",
      "   130   3641.0 MiB      0.0 MiB           1       new_shape = (len(alt), len(lat), len(lon))\n",
      "   131   3641.0 MiB      0.0 MiB           1       new_dims = [\"Altitude\", \"Latitude\", \"Longitude\"]\n",
      "   132   3641.0 MiB      0.0 MiB           1       new_coords = {\"Altitude\": alt, \"Latitude\": lat, \"Longitude\": lon}\n",
      "   133   3641.0 MiB      0.0 MiB           2       ds[variable] = xr.DataArray(\n",
      "   134   3641.0 MiB      0.0 MiB           1           new_values.reshape(new_shape), dims=new_dims, coords=new_coords\n",
      "   135                                             )\n",
      "   136   3641.0 MiB      0.0 MiB           1       ds[variable].attrs = attrs\n",
      "   137   3641.0 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "    99   2993.3 MiB   2993.3 MiB           1   @profile\n",
      "   100                                         def open_gridrad(path, dataset_options):\n",
      "   101                                             \"\"\"\n",
      "   102                                             Open a GridRad netcdf file, converting variables with an \"Index\" dimension back to 3D\n",
      "   103                                             \"\"\"\n",
      "   104                                         \n",
      "   105   2993.3 MiB      0.0 MiB           4       kept_variables = [gridrad_names_dict[f] for f in dataset_options[\"fields\"]]\n",
      "   106   2993.3 MiB      0.0 MiB           1       kept_variables += [\"Nradobs\", \"Nradecho\", \"wReflectivity\", \"CorrelationCoefficient\"]\n",
      "   107   2993.3 MiB      0.0 MiB           1       ds = xr.open_dataset(path)\n",
      "   108   2993.3 MiB      0.0 MiB           8       kept_variables = [v for v in kept_variables if v in ds.data_vars]\n",
      "   109   2993.3 MiB      0.0 MiB          15       dropped_variables = [v for v in ds.data_vars if v not in kept_variables]\n",
      "   110   3641.0 MiB      0.0 MiB           5       for var in kept_variables:\n",
      "   111   3322.7 MiB      0.0 MiB           4           if var != \"index\" and \"Index\" in ds[var].dims:\n",
      "   112   3641.0 MiB    647.6 MiB           2               ds = reshape_variable(ds, var)\n",
      "   113   3641.0 MiB      0.0 MiB           1       ds = ds.drop_vars(dropped_variables + [\"index\"])\n",
      "   114   3641.0 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   140   3641.0 MiB   3641.0 MiB           1   @profile\n",
      "   141                                         def filter(\n",
      "   142                                             ds,\n",
      "   143                                             weight_thresh=1.5,\n",
      "   144                                             echo_frac_thresh=0.6,\n",
      "   145                                             refl_thresh=0,\n",
      "   146                                             obs_thresh=2,\n",
      "   147                                             variables=None,\n",
      "   148                                         ):\n",
      "   149                                             \"\"\"\n",
      "   150                                             Filter a GridRad dataset. Based on code from the GridRad website\n",
      "   151                                             https://gridrad.org/software.html and edits by Stacey Hitchcock.\n",
      "   152                                         \n",
      "   153                                             Parameters\n",
      "   154                                             ----------\n",
      "   155                                             ds : xarray.Dataset\n",
      "   156                                                 The GridRad dataset.\n",
      "   157                                             weight_thresh : float, optional\n",
      "   158                                                 The bin weight threshold. Default is 1.5.\n",
      "   159                                             echo_frac_thresh : float, optional\n",
      "   160                                                 The echo fraction threshold. Default is 0.6.\n",
      "   161                                             refl_thresh : float, optional\n",
      "   162                                                 The reflectivity threshold. Default is 0.\n",
      "   163                                             obs_thresh : int, optional\n",
      "   164                                                 The number of observations. Default is 2.\n",
      "   165                                         \n",
      "   166                                             Returns\n",
      "   167                                             -------\n",
      "   168                                             ds : xarray.Dataset\n",
      "   169                                                 The filtered GridRad dataset\n",
      "   170                                             \"\"\"\n",
      "   171                                         \n",
      "   172   3641.0 MiB      0.0 MiB           1       logger.debug(\"Filtering GridRad data\")\n",
      "   173                                         \n",
      "   174   3641.0 MiB      0.0 MiB           1       if variables is None:\n",
      "   175   3641.0 MiB      0.0 MiB          10           variables = [v for v in gridrad_variables if v in ds.variables]\n",
      "   176                                         \n",
      "   177                                             # echo_fraction = xr.zeros_like(ds[\"Nradecho\"]).astype(np.float32)\n",
      "   178                                             # Calcualate echo fraction efficiently using lazy loading and where\n",
      "   179   3641.0 MiB      0.0 MiB           1       kwargs = {\"keep_attrs\": True}\n",
      "   180   4436.2 MiB    -79.5 MiB           3       echo_fraction = xr.where(\n",
      "   181   4436.2 MiB    795.2 MiB           2           ds[\"Nradobs\"] > 0, ds[\"Nradecho\"] / ds[\"Nradobs\"], 0.0, **kwargs\n",
      "   182                                             )\n",
      "   183   4038.6 MiB   -397.6 MiB           1       echo_fraction = echo_fraction.astype(np.float32)\n",
      "   184                                         \n",
      "   185                                             # Get indices to filter\n",
      "   186   4118.2 MiB     79.6 MiB           1       weight_cond = xr.where(ds[\"wReflectivity\"] < weight_thresh, True, False, **kwargs)\n",
      "   187   4197.7 MiB     79.5 MiB           1       refl_cond = xr.where(ds[\"Reflectivity\"] <= refl_thresh, True, False, **kwargs)\n",
      "   188   4277.2 MiB     79.5 MiB           1       frac_cond = xr.where(echo_fraction < echo_frac_thresh, True, False, **kwargs)\n",
      "   189   4356.8 MiB     79.5 MiB           1       obs_cond = xr.where(ds[\"Nradobs\"] <= obs_thresh, True, False, **kwargs)\n",
      "   190                                             # Filter cells below weight and reflectivity thresholds\n",
      "   191   4436.3 MiB     79.5 MiB           1       cond_refl = xr.where(weight_cond & refl_cond, True, False, **kwargs)\n",
      "   192                                             # Filter cells containing at < obs_thresh observations. If at least obs_thresh\n",
      "   193                                             # observations, filter cells with echoes in less than echo_fraction_thresh of the\n",
      "   194                                             # total observations\n",
      "   195   4515.8 MiB     79.5 MiB           1       cond_frac = xr.where(obs_cond | frac_cond, True, False, **kwargs)\n",
      "   196                                             # Retain values not filtered\n",
      "   197   4595.3 MiB     79.5 MiB           1       preserved = xr.where(~cond_refl & ~cond_frac, True, False, **kwargs)\n",
      "   198   4595.4 MiB      0.0 MiB           2       for var in variables:\n",
      "   199   4595.4 MiB      0.1 MiB           1           ds[var] = ds[var].where(preserved)\n",
      "   200                                         \n",
      "   201   4595.4 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   204   3800.3 MiB   3800.3 MiB           1   @profile\n",
      "   205                                         def remove_speckles(ds, window_size=5, coverage_thresh=0.32, variables=None):\n",
      "   206                                             \"\"\"\n",
      "   207                                             Remove speckles in GridRad data. Based on code from the GridRad website\n",
      "   208                                             https://gridrad.org/software.html and edits by Stacey Hitchcock. Modified from the\n",
      "   209                                             original to use xr.rolling instead of np.roll to correctly handle edges and corners.\n",
      "   210                                             \"\"\"\n",
      "   211                                         \n",
      "   212   3800.3 MiB      0.0 MiB           1       logger.debug(\"Removing speckles from the GridRad data\")\n",
      "   213                                         \n",
      "   214   3800.3 MiB      0.0 MiB           1       if variables is None:\n",
      "   215                                                 variables = [v for v in gridrad_variables if v in ds.variables]\n",
      "   216                                         \n",
      "   217                                             # refl_exists = np.isfinite(ds[\"Reflectivity\"]).astype(float)\n",
      "   218   3879.7 MiB     79.4 MiB           1       refl_exists = xr.where(ds[\"Reflectivity\"] != np.nan, True, False)\n",
      "   219   3879.7 MiB      0.0 MiB           1       min_size = window_size**3 * coverage_thresh\n",
      "   220   3959.2 MiB     79.5 MiB           1       speckle_mask = remove_small_objects(refl_exists.values > 0, min_size=min_size)\n",
      "   221   3959.3 MiB      0.0 MiB           2       for var in variables:\n",
      "   222   3959.3 MiB      0.1 MiB           1           ds[var] = ds[var].where(speckle_mask)\n",
      "   223                                         \n",
      "   224   3959.3 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   227   3800.2 MiB   3800.2 MiB           1   @profile\n",
      "   228                                         def remove_low_level_clutter(ds, variables=None):\n",
      "   229                                             \"\"\"\n",
      "   230                                             Remove low level clutter from GridRad data. Based on code from the GridRad website\n",
      "   231                                             https://gridrad.org/software.html and edits by Stacey Hitchcock.\n",
      "   232                                             \"\"\"\n",
      "   233                                         \n",
      "   234   3800.2 MiB      0.0 MiB           1       logger.debug(\"Removing low level clutter from the GridRad data\")\n",
      "   235                                         \n",
      "   236                                             # Determine max heights of non-nan reflectivity values. If entire column is nan,\n",
      "   237                                             # set max altitude to zero.\n",
      "   238   3800.2 MiB      0.0 MiB           1       refl_max = ds.Reflectivity.max(dim=\"Altitude\", skipna=True)\n",
      "   239   4436.4 MiB    636.2 MiB           1       refl_0_alts = ds.Altitude.where(ds.Reflectivity > 0.0, 0.0)\n",
      "   240   4443.3 MiB      6.9 MiB           1       refl_0_max_alt = refl_0_alts.max(dim=\"Altitude\")\n",
      "   241   4465.2 MiB     21.9 MiB           1       refl_0_min_alt = refl_0_alts.min(dim=\"Altitude\")\n",
      "   242   4487.2 MiB     22.0 MiB           1       refl_5_max_alt = ds.Altitude.where(ds.Reflectivity > 5.0, 0.0).max(dim=\"Altitude\")\n",
      "   243   4509.1 MiB     21.8 MiB           1       refl_15_max_alt = ds.Altitude.where(ds.Reflectivity > 15.0, 0.0).max(dim=\"Altitude\")\n",
      "   244                                         \n",
      "   245                                             # Check for very weak echos below 4 km\n",
      "   246   4509.1 MiB      0.0 MiB           1       cond_1 = (refl_max < 20.0) & (refl_0_max_alt <= 4.0) & (refl_0_min_alt <= 3.0)\n",
      "   247                                             # Check for very weak echos below 5 km\n",
      "   248   4511.6 MiB      2.5 MiB           1       cond_2 = (refl_max < 10.0) & (refl_0_max_alt <= 5.0) & (refl_0_min_alt <= 3.0)\n",
      "   249                                             # Check for weak echos below 5 km. Note the > 0.0 ensures values actually exist\n",
      "   250   4514.3 MiB      2.8 MiB           1       cond_3 = (refl_5_max_alt <= 5.0) & (refl_5_max_alt > 0.0) & (refl_15_max_alt <= 3.0)\n",
      "   251                                             # Check for weak echos below 2 km\n",
      "   252   4517.1 MiB      2.8 MiB           1       cond_4 = (refl_15_max_alt < 2.0) & (refl_15_max_alt > 0.0)\n",
      "   253   4517.1 MiB      0.0 MiB           1       cond = np.logical_not(cond_1 | cond_2 | cond_3 | cond_4)\n",
      "   254   4517.3 MiB      0.0 MiB           2       for var in variables:\n",
      "   255   4517.3 MiB      0.2 MiB           1           ds[var] = ds[var].where(cond)\n",
      "   256   4517.3 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   204   3774.2 MiB   3774.2 MiB           1   @profile\n",
      "   205                                         def remove_speckles(ds, window_size=5, coverage_thresh=0.32, variables=None):\n",
      "   206                                             \"\"\"\n",
      "   207                                             Remove speckles in GridRad data. Based on code from the GridRad website\n",
      "   208                                             https://gridrad.org/software.html and edits by Stacey Hitchcock. Modified from the\n",
      "   209                                             original to use xr.rolling instead of np.roll to correctly handle edges and corners.\n",
      "   210                                             \"\"\"\n",
      "   211                                         \n",
      "   212   3774.2 MiB      0.0 MiB           1       logger.debug(\"Removing speckles from the GridRad data\")\n",
      "   213                                         \n",
      "   214   3774.2 MiB      0.0 MiB           1       if variables is None:\n",
      "   215                                                 variables = [v for v in gridrad_variables if v in ds.variables]\n",
      "   216                                         \n",
      "   217                                             # refl_exists = np.isfinite(ds[\"Reflectivity\"]).astype(float)\n",
      "   218   3853.7 MiB     79.5 MiB           1       refl_exists = xr.where(ds[\"Reflectivity\"] != np.nan, True, False)\n",
      "   219   3853.7 MiB      0.0 MiB           1       min_size = window_size**3 * coverage_thresh\n",
      "   220   3933.3 MiB     79.6 MiB           1       speckle_mask = remove_small_objects(refl_exists.values > 0, min_size=min_size)\n",
      "   221   3933.4 MiB      0.0 MiB           2       for var in variables:\n",
      "   222   3933.4 MiB      0.1 MiB           1           ds[var] = ds[var].where(speckle_mask)\n",
      "   223                                         \n",
      "   224   3933.4 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   281   3720.6 MiB   3720.6 MiB           1   @profile\n",
      "   282                                         def remove_clutter(ds, variables=None, low_level=True, below_anvil=False):\n",
      "   283                                             \"\"\"\n",
      "   284                                             Remove clutter from GridRad data. Based on code from the GridRad website\n",
      "   285                                             https://gridrad.org/software.html and edits by Stacey Hitchcock.\n",
      "   286                                         \n",
      "   287                                             Parameters\n",
      "   288                                             ----------\n",
      "   289                                             ds : xarray.Dataset\n",
      "   290                                                 The GridRad dataset.\n",
      "   291                                             variables : list, optional\n",
      "   292                                                 The variables to remove clutter from. Default is [\"Reflectivity\"].\n",
      "   293                                         \n",
      "   294                                             Returns\n",
      "   295                                             -------\n",
      "   296                                             ds : xarray.Dataset\n",
      "   297                                                 The GridRad dataset with clutter removed.\n",
      "   298                                             \"\"\"\n",
      "   299                                         \n",
      "   300   3720.6 MiB      0.0 MiB           1       logger.debug(\"Removing clutter from the GridRad data\")\n",
      "   301                                         \n",
      "   302   3720.6 MiB      0.0 MiB           1       if variables is None:\n",
      "   303   3720.6 MiB      0.0 MiB          10           variables = [v for v in gridrad_variables if v in ds.variables]\n",
      "   304                                         \n",
      "   305                                             # Remove low reflectivity low level clutter\n",
      "   306   3800.1 MiB     79.5 MiB           1       cond = (ds.Reflectivity >= 10.0) | (ds.Altitude > 4.0)\n",
      "   307   3800.3 MiB      0.0 MiB           2       for var in variables:\n",
      "   308   3800.3 MiB      0.2 MiB           1           ds[var] = ds[var].where(cond)\n",
      "   309                                         \n",
      "   310                                             # Attempt correlation based clutter removal if relevant variables exist\n",
      "   311   3800.3 MiB      0.0 MiB           1       correlation_var_list = [\"DifferentialReflectivity\", \"CorrelationCoefficient\"]\n",
      "   312   3800.3 MiB      0.0 MiB           4       if all(corr_var in ds.variables for corr_var in correlation_var_list):\n",
      "   313                                         \n",
      "   314                                                 # Require either high correlation or reflectivity\n",
      "   315                                                 cond1 = ds[\"Reflectivity\"] >= 40.0 | ds[\"r_HV\"] >= 0.9\n",
      "   316                                                 # Require moderate reflectivity or high correlation or low altitude\n",
      "   317                                                 cond2 = ds[\"Reflectivity\"] >= 25.0 | ds[\"CorrelationCoefficient\"] >= 0.95\n",
      "   318                                                 cond2 = cond2 | ds[\"Altitude\"] < 10.0\n",
      "   319                                                 # Require both conditions above be met\n",
      "   320                                                 for var in variables:\n",
      "   321                                                     ds[var] = ds[var].where(cond1 & cond2)\n",
      "   322                                         \n",
      "   323                                             # First pass at speckle removal\n",
      "   324   3800.2 MiB     -0.1 MiB           1       ds = remove_speckles(ds, variables=variables)\n",
      "   325                                         \n",
      "   326   3800.2 MiB      0.0 MiB           1       if low_level:\n",
      "   327                                                 # Remove low level clutter. Note this can remove some low level cloud/drizzle\n",
      "   328   3774.2 MiB    -26.0 MiB           1           ds = remove_low_level_clutter(ds, variables=variables)\n",
      "   329                                         \n",
      "   330   3774.2 MiB      0.0 MiB           1       if below_anvil:\n",
      "   331                                                 # Remove clutter below anvils\n",
      "   332                                                 ds = remove_clutter_below_anvils(ds, variables=variables)\n",
      "   333                                         \n",
      "   334                                             # Second pass at speckle removal\n",
      "   335   3774.3 MiB      0.1 MiB           1       ds = remove_speckles(ds, variables=variables)\n",
      "   336                                         \n",
      "   337   3774.3 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   350   2993.3 MiB   2993.3 MiB           1   @profile\n",
      "   351                                         def convert_gridrad(time, filepath, track_options, dataset_options, grid_options):\n",
      "   352                                             \"\"\"Convert gridrad data to the standard format.\"\"\"\n",
      "   353                                         \n",
      "   354   2993.3 MiB      0.0 MiB           1       logger.debug(f\"Converting GridRad dataset at time {time}.\")\n",
      "   355                                         \n",
      "   356                                             # Open the dataset and perform preliminary filtering and decluttering\n",
      "   357   2993.3 MiB      0.0 MiB           1       lock = multiprocessing.Lock()\n",
      "   358   3641.0 MiB      0.0 MiB           2       with lock:\n",
      "   359   3641.0 MiB    647.6 MiB           1           ds = open_gridrad(filepath, dataset_options)\n",
      "   360   3720.6 MiB     79.6 MiB           1       ds = filter(ds, refl_thresh=-10)\n",
      "   361   3694.7 MiB    -25.8 MiB           1       ds = remove_clutter(ds)\n",
      "   362                                         \n",
      "   363                                             # Ensure the intended time is in the dataset\n",
      "   364   3694.7 MiB      0.0 MiB           1       if time not in ds.time.values:\n",
      "   365                                                 raise ValueError(f\"{time} not in {filepath}\")\n",
      "   366                                         \n",
      "   367                                             # Restructure the dataset\n",
      "   368   3694.7 MiB      0.0 MiB           1       names_dict = {\"Latitude\": \"latitude\", \"Longitude\": \"longitude\"}\n",
      "   369   3694.7 MiB      0.0 MiB           1       names_dict.update({\"Altitude\": \"altitude\", \"Reflectivity\": \"reflectivity\"})\n",
      "   370   3694.7 MiB      0.0 MiB           1       names_dict.update({\"Nradobs\": \"number_of_observations\"})\n",
      "   371   3694.7 MiB      0.0 MiB           1       names_dict.update({\"Nradecho\": \"number_of_echoes\"})\n",
      "   372                                         \n",
      "   373   3694.7 MiB      0.0 MiB           1       ds = ds.rename(names_dict)\n",
      "   374                                         \n",
      "   375   3694.7 MiB      0.0 MiB           4       for dim in [\"latitude\", \"longitude\", \"altitude\"]:\n",
      "   376   3694.7 MiB      0.0 MiB           3           ds[dim].attrs[\"standard_name\"] = dim\n",
      "   377   3694.7 MiB      0.0 MiB           3           ds[dim].attrs[\"long_name\"] = dim\n",
      "   378   3694.7 MiB      0.0 MiB           1       ds[\"altitude\"] = ds[\"altitude\"] * 1000  # Convert to meters\n",
      "   379   3694.7 MiB      0.0 MiB           1       kept_fields = dataset_options[\"fields\"] + [\"number_of_observations\"]\n",
      "   380   3694.7 MiB      0.0 MiB           1       kept_fields += [\"number_of_echoes\"]\n",
      "   381   3694.7 MiB      0.0 MiB           7       dropped_fields = [f for f in ds.data_vars if f not in kept_fields]\n",
      "   382   3376.7 MiB   -318.0 MiB           1       ds = ds.drop_vars(dropped_fields)\n",
      "   383                                         \n",
      "   384   3376.7 MiB      0.0 MiB           2       for field in dataset_options[\"fields\"]:\n",
      "   385   3376.7 MiB      0.0 MiB           1           ds[field] = ds[field].expand_dims(\"time\")\n",
      "   386   3376.7 MiB      0.0 MiB           1           ds[field].attrs[\"long_name\"] = field\n",
      "   387                                         \n",
      "   388   3376.7 MiB      0.0 MiB           1       spacing = [ds.latitude.delta, ds.longitude.delta]\n",
      "   389   3376.7 MiB      0.0 MiB           1       if grid_options[\"name\"] == \"geographic\":\n",
      "   390   3376.7 MiB      0.0 MiB           1           grid_options[\"latitude\"] = ds.latitude.values\n",
      "   391   3376.7 MiB      0.0 MiB           1           grid_options[\"longitude\"] = ds.longitude.values\n",
      "   392   3376.7 MiB      0.0 MiB           1           grid_options[\"altitude\"] = ds.altitude.values\n",
      "   393   3376.7 MiB      0.0 MiB           1           grid_options[\"geographic_spacing\"] = spacing\n",
      "   394   3376.7 MiB      0.0 MiB           1           grid_options[\"shape\"] = [len(ds.latitude), len(ds.longitude)]\n",
      "   395                                         \n",
      "   396   3376.7 MiB      0.0 MiB           1       ds[\"longitude\"] = ds[\"longitude\"] % 360\n",
      "   397                                         \n",
      "   398                                             # Get the domain mask associated with the given object\n",
      "   399                                             # Note the relevant domain mask is a function of how the object is detected, e.g.\n",
      "   400                                             # which levels!\n",
      "   401   3423.0 MiB     46.3 MiB           1       domain_mask = get_domain_mask(ds, track_options, dataset_options)\n",
      "   402   3382.1 MiB    -40.9 MiB           1       boundary_coords, boundary_mask = utils.get_mask_boundary(domain_mask, grid_options)\n",
      "   403   3382.1 MiB      0.0 MiB           1       ds[\"domain_mask\"] = domain_mask\n",
      "   404   3382.1 MiB      0.0 MiB           1       ds[\"boundary_mask\"] = boundary_mask\n",
      "   405                                         \n",
      "   406                                             # Don't mask the gridcell areas\n",
      "   407   3436.8 MiB     54.6 MiB           1       cell_areas = grid.get_cell_areas(grid_options)\n",
      "   408   3436.8 MiB      0.0 MiB           1       ds[\"gridcell_area\"] = ([\"latitude\", \"longitude\"], cell_areas)\n",
      "   409   3436.8 MiB      0.0 MiB           1       area_attrs = {\"units\": \"km^2\", \"standard_name\": \"area\", \"valid_min\": 0}\n",
      "   410   3436.8 MiB      0.0 MiB           1       ds[\"gridcell_area\"].attrs.update(area_attrs)\n",
      "   411                                         \n",
      "   412                                             # Apply the domain mask to the current grid\n",
      "   413   3516.4 MiB     79.6 MiB           1       ds = utils.apply_mask(ds, grid_options)\n",
      "   414   3357.3 MiB   -159.1 MiB           1       ds = ds.drop_vars([\"number_of_observations\", \"number_of_echoes\"])\n",
      "   415   3357.3 MiB      0.0 MiB           1       return ds, boundary_coords\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 17:32:53,033 - thor.track - INFO - Processing hierarchy level 0.\n",
      "2024-10-21 17:32:53,034 - thor.track - INFO - Tracking convective.\n",
      "2024-10-21 17:33:14,327 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:33:14,328 - thor.track - INFO - Tracking middle.\n",
      "2024-10-21 17:33:20,099 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:33:20,100 - thor.track - INFO - Tracking anvil.\n",
      "2024-10-21 17:33:22,531 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:33:22,532 - thor.track - INFO - Processing hierarchy level 1.\n",
      "2024-10-21 17:33:22,533 - thor.track - INFO - Tracking mcs.\n",
      "2024-10-21 17:33:22,560 - thor.write.mask - INFO - Writing mcs masks to /home/ewan/THOR_output/runs/gridrad_demo_20100121/masks/mcs.zarr.\n",
      "2024-10-21 17:33:34,600 - thor.match.match - INFO - Matching mcs objects.\n",
      "2024-10-21 17:33:35,130 - thor.match.match - INFO - Updating object record.\n",
      "2024-10-21 17:33:35,261 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:33:35,263 - thor.attribute.core - INFO - Object 0 has a nan u_displacement.\n",
      "2024-10-21 17:33:36,166 - thor.attribute.core - INFO - Object 0 has a nan u_displacement.\n",
      "2024-10-21 17:33:36,209 - thor.track - INFO - Processing 2010-01-21T12:30:00.\n",
      "2024-10-21 17:33:36,211 - thor.data.gridrad - INFO - Updating gridrad dataset for 2010-01-21T12:30:00.\n",
      "2024-10-21 17:33:36,211 - thor.data.gridrad - INFO - Converting gridrad data from nexrad_3d_v4_2_20100121T123000Z.nc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   117   3598.7 MiB   3598.7 MiB           1   @profile\n",
      "   118                                         def reshape_variable(ds, variable):\n",
      "   119                                             \"\"\"\n",
      "   120                                             Reshape a variable in a GridRad dataset to a 3D grid. Adapted from code provided by\n",
      "   121                                             Stacey Hitchcock.\n",
      "   122                                             \"\"\"\n",
      "   123                                         \n",
      "   124   3610.2 MiB     11.5 MiB           1       values = ds[variable].values\n",
      "   125   3610.2 MiB      0.0 MiB           1       attrs = ds[variable].attrs\n",
      "   126   3610.2 MiB      0.0 MiB           1       alt, lat, lon = ds[\"Altitude\"], ds[\"Latitude\"], ds[\"Longitude\"]\n",
      "   127   3610.2 MiB      0.0 MiB           1       new_values = np.zeros(len(alt) * len(lat) * len(lon))\n",
      "   128   3859.2 MiB    249.0 MiB           1       new_values[ds.index.values] = values\n",
      "   129   3945.3 MiB     86.0 MiB           1       new_values = new_values.astype(ds[variable].dtype)\n",
      "   130   3945.3 MiB      0.0 MiB           1       new_shape = (len(alt), len(lat), len(lon))\n",
      "   131   3945.3 MiB      0.0 MiB           1       new_dims = [\"Altitude\", \"Latitude\", \"Longitude\"]\n",
      "   132   3945.3 MiB      0.0 MiB           1       new_coords = {\"Altitude\": alt, \"Latitude\": lat, \"Longitude\": lon}\n",
      "   133   3945.3 MiB      0.0 MiB           2       ds[variable] = xr.DataArray(\n",
      "   134   3945.3 MiB      0.0 MiB           1           new_values.reshape(new_shape), dims=new_dims, coords=new_coords\n",
      "   135                                             )\n",
      "   136   3945.3 MiB      0.0 MiB           1       ds[variable].attrs = attrs\n",
      "   137   3945.3 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   117   3945.3 MiB   3945.3 MiB           1   @profile\n",
      "   118                                         def reshape_variable(ds, variable):\n",
      "   119                                             \"\"\"\n",
      "   120                                             Reshape a variable in a GridRad dataset to a 3D grid. Adapted from code provided by\n",
      "   121                                             Stacey Hitchcock.\n",
      "   122                                             \"\"\"\n",
      "   123                                         \n",
      "   124   3945.3 MiB      0.0 MiB           1       values = ds[variable].values\n",
      "   125   3945.3 MiB      0.0 MiB           1       attrs = ds[variable].attrs\n",
      "   126   3945.3 MiB      0.0 MiB           1       alt, lat, lon = ds[\"Altitude\"], ds[\"Latitude\"], ds[\"Longitude\"]\n",
      "   127   3945.3 MiB      0.0 MiB           1       new_values = np.zeros(len(alt) * len(lat) * len(lon))\n",
      "   128   4177.4 MiB    232.1 MiB           1       new_values[ds.index.values] = values\n",
      "   129   4263.4 MiB     86.0 MiB           1       new_values = new_values.astype(ds[variable].dtype)\n",
      "   130   4263.4 MiB      0.0 MiB           1       new_shape = (len(alt), len(lat), len(lon))\n",
      "   131   4263.4 MiB      0.0 MiB           1       new_dims = [\"Altitude\", \"Latitude\", \"Longitude\"]\n",
      "   132   4263.4 MiB      0.0 MiB           1       new_coords = {\"Altitude\": alt, \"Latitude\": lat, \"Longitude\": lon}\n",
      "   133   4263.4 MiB      0.0 MiB           2       ds[variable] = xr.DataArray(\n",
      "   134   4263.4 MiB      0.0 MiB           1           new_values.reshape(new_shape), dims=new_dims, coords=new_coords\n",
      "   135                                             )\n",
      "   136   4263.4 MiB      0.0 MiB           1       ds[variable].attrs = attrs\n",
      "   137   4263.4 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "    99   3598.7 MiB   3598.7 MiB           1   @profile\n",
      "   100                                         def open_gridrad(path, dataset_options):\n",
      "   101                                             \"\"\"\n",
      "   102                                             Open a GridRad netcdf file, converting variables with an \"Index\" dimension back to 3D\n",
      "   103                                             \"\"\"\n",
      "   104                                         \n",
      "   105   3598.7 MiB      0.0 MiB           4       kept_variables = [gridrad_names_dict[f] for f in dataset_options[\"fields\"]]\n",
      "   106   3598.7 MiB      0.0 MiB           1       kept_variables += [\"Nradobs\", \"Nradecho\", \"wReflectivity\", \"CorrelationCoefficient\"]\n",
      "   107   3598.7 MiB      0.0 MiB           1       ds = xr.open_dataset(path)\n",
      "   108   3598.7 MiB      0.0 MiB           8       kept_variables = [v for v in kept_variables if v in ds.data_vars]\n",
      "   109   3598.7 MiB      0.0 MiB          15       dropped_variables = [v for v in ds.data_vars if v not in kept_variables]\n",
      "   110   4263.4 MiB      0.0 MiB           5       for var in kept_variables:\n",
      "   111   3945.3 MiB      0.0 MiB           4           if var != \"index\" and \"Index\" in ds[var].dims:\n",
      "   112   4263.4 MiB    664.6 MiB           2               ds = reshape_variable(ds, var)\n",
      "   113   4213.1 MiB    -50.2 MiB           1       ds = ds.drop_vars(dropped_variables + [\"index\"])\n",
      "   114   4213.1 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   140   4213.1 MiB   4213.1 MiB           1   @profile\n",
      "   141                                         def filter(\n",
      "   142                                             ds,\n",
      "   143                                             weight_thresh=1.5,\n",
      "   144                                             echo_frac_thresh=0.6,\n",
      "   145                                             refl_thresh=0,\n",
      "   146                                             obs_thresh=2,\n",
      "   147                                             variables=None,\n",
      "   148                                         ):\n",
      "   149                                             \"\"\"\n",
      "   150                                             Filter a GridRad dataset. Based on code from the GridRad website\n",
      "   151                                             https://gridrad.org/software.html and edits by Stacey Hitchcock.\n",
      "   152                                         \n",
      "   153                                             Parameters\n",
      "   154                                             ----------\n",
      "   155                                             ds : xarray.Dataset\n",
      "   156                                                 The GridRad dataset.\n",
      "   157                                             weight_thresh : float, optional\n",
      "   158                                                 The bin weight threshold. Default is 1.5.\n",
      "   159                                             echo_frac_thresh : float, optional\n",
      "   160                                                 The echo fraction threshold. Default is 0.6.\n",
      "   161                                             refl_thresh : float, optional\n",
      "   162                                                 The reflectivity threshold. Default is 0.\n",
      "   163                                             obs_thresh : int, optional\n",
      "   164                                                 The number of observations. Default is 2.\n",
      "   165                                         \n",
      "   166                                             Returns\n",
      "   167                                             -------\n",
      "   168                                             ds : xarray.Dataset\n",
      "   169                                                 The filtered GridRad dataset\n",
      "   170                                             \"\"\"\n",
      "   171                                         \n",
      "   172   4213.1 MiB      0.0 MiB           1       logger.debug(\"Filtering GridRad data\")\n",
      "   173                                         \n",
      "   174   4213.1 MiB      0.0 MiB           1       if variables is None:\n",
      "   175   4213.1 MiB      0.0 MiB          10           variables = [v for v in gridrad_variables if v in ds.variables]\n",
      "   176                                         \n",
      "   177                                             # echo_fraction = xr.zeros_like(ds[\"Nradecho\"]).astype(np.float32)\n",
      "   178                                             # Calcualate echo fraction efficiently using lazy loading and where\n",
      "   179   4213.1 MiB      0.0 MiB           1       kwargs = {\"keep_attrs\": True}\n",
      "   180   5008.5 MiB    -79.5 MiB           3       echo_fraction = xr.where(\n",
      "   181   5008.5 MiB    795.4 MiB           2           ds[\"Nradobs\"] > 0, ds[\"Nradecho\"] / ds[\"Nradobs\"], 0.0, **kwargs\n",
      "   182                                             )\n",
      "   183   4610.9 MiB   -397.6 MiB           1       echo_fraction = echo_fraction.astype(np.float32)\n",
      "   184                                         \n",
      "   185                                             # Get indices to filter\n",
      "   186   4690.4 MiB     79.5 MiB           1       weight_cond = xr.where(ds[\"wReflectivity\"] < weight_thresh, True, False, **kwargs)\n",
      "   187   4769.9 MiB     79.5 MiB           1       refl_cond = xr.where(ds[\"Reflectivity\"] <= refl_thresh, True, False, **kwargs)\n",
      "   188   4849.5 MiB     79.5 MiB           1       frac_cond = xr.where(echo_fraction < echo_frac_thresh, True, False, **kwargs)\n",
      "   189   4929.0 MiB     79.5 MiB           1       obs_cond = xr.where(ds[\"Nradobs\"] <= obs_thresh, True, False, **kwargs)\n",
      "   190                                             # Filter cells below weight and reflectivity thresholds\n",
      "   191   5008.5 MiB     79.5 MiB           1       cond_refl = xr.where(weight_cond & refl_cond, True, False, **kwargs)\n",
      "   192                                             # Filter cells containing at < obs_thresh observations. If at least obs_thresh\n",
      "   193                                             # observations, filter cells with echoes in less than echo_fraction_thresh of the\n",
      "   194                                             # total observations\n",
      "   195   5088.1 MiB     79.5 MiB           1       cond_frac = xr.where(obs_cond | frac_cond, True, False, **kwargs)\n",
      "   196                                             # Retain values not filtered\n",
      "   197   5167.6 MiB     79.5 MiB           1       preserved = xr.where(~cond_refl & ~cond_frac, True, False, **kwargs)\n",
      "   198   5167.7 MiB      0.0 MiB           2       for var in variables:\n",
      "   199   5167.7 MiB      0.1 MiB           1           ds[var] = ds[var].where(preserved)\n",
      "   200                                         \n",
      "   201   5167.7 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   204   4372.4 MiB   4372.4 MiB           1   @profile\n",
      "   205                                         def remove_speckles(ds, window_size=5, coverage_thresh=0.32, variables=None):\n",
      "   206                                             \"\"\"\n",
      "   207                                             Remove speckles in GridRad data. Based on code from the GridRad website\n",
      "   208                                             https://gridrad.org/software.html and edits by Stacey Hitchcock. Modified from the\n",
      "   209                                             original to use xr.rolling instead of np.roll to correctly handle edges and corners.\n",
      "   210                                             \"\"\"\n",
      "   211                                         \n",
      "   212   4372.4 MiB      0.0 MiB           1       logger.debug(\"Removing speckles from the GridRad data\")\n",
      "   213                                         \n",
      "   214   4372.4 MiB      0.0 MiB           1       if variables is None:\n",
      "   215                                                 variables = [v for v in gridrad_variables if v in ds.variables]\n",
      "   216                                         \n",
      "   217                                             # refl_exists = np.isfinite(ds[\"Reflectivity\"]).astype(float)\n",
      "   218   4451.8 MiB     79.4 MiB           1       refl_exists = xr.where(ds[\"Reflectivity\"] != np.nan, True, False)\n",
      "   219   4451.8 MiB      0.0 MiB           1       min_size = window_size**3 * coverage_thresh\n",
      "   220   4531.5 MiB     79.6 MiB           1       speckle_mask = remove_small_objects(refl_exists.values > 0, min_size=min_size)\n",
      "   221   4531.6 MiB      0.0 MiB           2       for var in variables:\n",
      "   222   4531.6 MiB      0.1 MiB           1           ds[var] = ds[var].where(speckle_mask)\n",
      "   223                                         \n",
      "   224   4531.6 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   227   4372.4 MiB   4372.4 MiB           1   @profile\n",
      "   228                                         def remove_low_level_clutter(ds, variables=None):\n",
      "   229                                             \"\"\"\n",
      "   230                                             Remove low level clutter from GridRad data. Based on code from the GridRad website\n",
      "   231                                             https://gridrad.org/software.html and edits by Stacey Hitchcock.\n",
      "   232                                             \"\"\"\n",
      "   233                                         \n",
      "   234   4372.4 MiB      0.0 MiB           1       logger.debug(\"Removing low level clutter from the GridRad data\")\n",
      "   235                                         \n",
      "   236                                             # Determine max heights of non-nan reflectivity values. If entire column is nan,\n",
      "   237                                             # set max altitude to zero.\n",
      "   238   4372.4 MiB      0.0 MiB           1       refl_max = ds.Reflectivity.max(dim=\"Altitude\", skipna=True)\n",
      "   239   5008.6 MiB    636.2 MiB           1       refl_0_alts = ds.Altitude.where(ds.Reflectivity > 0.0, 0.0)\n",
      "   240   5030.5 MiB     21.9 MiB           1       refl_0_max_alt = refl_0_alts.max(dim=\"Altitude\")\n",
      "   241   5052.4 MiB     21.9 MiB           1       refl_0_min_alt = refl_0_alts.min(dim=\"Altitude\")\n",
      "   242   5074.4 MiB     22.0 MiB           1       refl_5_max_alt = ds.Altitude.where(ds.Reflectivity > 5.0, 0.0).max(dim=\"Altitude\")\n",
      "   243   5096.4 MiB     21.9 MiB           1       refl_15_max_alt = ds.Altitude.where(ds.Reflectivity > 15.0, 0.0).max(dim=\"Altitude\")\n",
      "   244                                         \n",
      "   245                                             # Check for very weak echos below 4 km\n",
      "   246   5096.4 MiB      0.0 MiB           1       cond_1 = (refl_max < 20.0) & (refl_0_max_alt <= 4.0) & (refl_0_min_alt <= 3.0)\n",
      "   247                                             # Check for very weak echos below 5 km\n",
      "   248   5096.4 MiB      0.0 MiB           1       cond_2 = (refl_max < 10.0) & (refl_0_max_alt <= 5.0) & (refl_0_min_alt <= 3.0)\n",
      "   249                                             # Check for weak echos below 5 km. Note the > 0.0 ensures values actually exist\n",
      "   250   5096.4 MiB      0.0 MiB           1       cond_3 = (refl_5_max_alt <= 5.0) & (refl_5_max_alt > 0.0) & (refl_15_max_alt <= 3.0)\n",
      "   251                                             # Check for weak echos below 2 km\n",
      "   252   5096.4 MiB      0.0 MiB           1       cond_4 = (refl_15_max_alt < 2.0) & (refl_15_max_alt > 0.0)\n",
      "   253   5096.4 MiB      0.0 MiB           1       cond = np.logical_not(cond_1 | cond_2 | cond_3 | cond_4)\n",
      "   254   5096.4 MiB      0.0 MiB           2       for var in variables:\n",
      "   255   5096.4 MiB      0.1 MiB           1           ds[var] = ds[var].where(cond)\n",
      "   256   5096.4 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   204   4372.4 MiB   4372.4 MiB           1   @profile\n",
      "   205                                         def remove_speckles(ds, window_size=5, coverage_thresh=0.32, variables=None):\n",
      "   206                                             \"\"\"\n",
      "   207                                             Remove speckles in GridRad data. Based on code from the GridRad website\n",
      "   208                                             https://gridrad.org/software.html and edits by Stacey Hitchcock. Modified from the\n",
      "   209                                             original to use xr.rolling instead of np.roll to correctly handle edges and corners.\n",
      "   210                                             \"\"\"\n",
      "   211                                         \n",
      "   212   4372.4 MiB      0.0 MiB           1       logger.debug(\"Removing speckles from the GridRad data\")\n",
      "   213                                         \n",
      "   214   4372.4 MiB      0.0 MiB           1       if variables is None:\n",
      "   215                                                 variables = [v for v in gridrad_variables if v in ds.variables]\n",
      "   216                                         \n",
      "   217                                             # refl_exists = np.isfinite(ds[\"Reflectivity\"]).astype(float)\n",
      "   218   4451.9 MiB     79.5 MiB           1       refl_exists = xr.where(ds[\"Reflectivity\"] != np.nan, True, False)\n",
      "   219   4451.9 MiB      0.0 MiB           1       min_size = window_size**3 * coverage_thresh\n",
      "   220   4531.5 MiB     79.5 MiB           1       speckle_mask = remove_small_objects(refl_exists.values > 0, min_size=min_size)\n",
      "   221   4531.6 MiB      0.0 MiB           2       for var in variables:\n",
      "   222   4531.6 MiB      0.1 MiB           1           ds[var] = ds[var].where(speckle_mask)\n",
      "   223                                         \n",
      "   224   4531.6 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   281   4292.8 MiB   4292.8 MiB           1   @profile\n",
      "   282                                         def remove_clutter(ds, variables=None, low_level=True, below_anvil=False):\n",
      "   283                                             \"\"\"\n",
      "   284                                             Remove clutter from GridRad data. Based on code from the GridRad website\n",
      "   285                                             https://gridrad.org/software.html and edits by Stacey Hitchcock.\n",
      "   286                                         \n",
      "   287                                             Parameters\n",
      "   288                                             ----------\n",
      "   289                                             ds : xarray.Dataset\n",
      "   290                                                 The GridRad dataset.\n",
      "   291                                             variables : list, optional\n",
      "   292                                                 The variables to remove clutter from. Default is [\"Reflectivity\"].\n",
      "   293                                         \n",
      "   294                                             Returns\n",
      "   295                                             -------\n",
      "   296                                             ds : xarray.Dataset\n",
      "   297                                                 The GridRad dataset with clutter removed.\n",
      "   298                                             \"\"\"\n",
      "   299                                         \n",
      "   300   4292.8 MiB      0.0 MiB           1       logger.debug(\"Removing clutter from the GridRad data\")\n",
      "   301                                         \n",
      "   302   4292.8 MiB      0.0 MiB           1       if variables is None:\n",
      "   303   4292.8 MiB      0.0 MiB          10           variables = [v for v in gridrad_variables if v in ds.variables]\n",
      "   304                                         \n",
      "   305                                             # Remove low reflectivity low level clutter\n",
      "   306   4372.3 MiB     79.5 MiB           1       cond = (ds.Reflectivity >= 10.0) | (ds.Altitude > 4.0)\n",
      "   307   4372.4 MiB      0.0 MiB           2       for var in variables:\n",
      "   308   4372.4 MiB      0.1 MiB           1           ds[var] = ds[var].where(cond)\n",
      "   309                                         \n",
      "   310                                             # Attempt correlation based clutter removal if relevant variables exist\n",
      "   311   4372.4 MiB      0.0 MiB           1       correlation_var_list = [\"DifferentialReflectivity\", \"CorrelationCoefficient\"]\n",
      "   312   4372.4 MiB      0.0 MiB           4       if all(corr_var in ds.variables for corr_var in correlation_var_list):\n",
      "   313                                         \n",
      "   314                                                 # Require either high correlation or reflectivity\n",
      "   315                                                 cond1 = ds[\"Reflectivity\"] >= 40.0 | ds[\"r_HV\"] >= 0.9\n",
      "   316                                                 # Require moderate reflectivity or high correlation or low altitude\n",
      "   317                                                 cond2 = ds[\"Reflectivity\"] >= 25.0 | ds[\"CorrelationCoefficient\"] >= 0.95\n",
      "   318                                                 cond2 = cond2 | ds[\"Altitude\"] < 10.0\n",
      "   319                                                 # Require both conditions above be met\n",
      "   320                                                 for var in variables:\n",
      "   321                                                     ds[var] = ds[var].where(cond1 & cond2)\n",
      "   322                                         \n",
      "   323                                             # First pass at speckle removal\n",
      "   324   4372.4 MiB     -0.0 MiB           1       ds = remove_speckles(ds, variables=variables)\n",
      "   325                                         \n",
      "   326   4372.4 MiB      0.0 MiB           1       if low_level:\n",
      "   327                                                 # Remove low level clutter. Note this can remove some low level cloud/drizzle\n",
      "   328   4372.4 MiB      0.0 MiB           1           ds = remove_low_level_clutter(ds, variables=variables)\n",
      "   329                                         \n",
      "   330   4372.4 MiB      0.0 MiB           1       if below_anvil:\n",
      "   331                                                 # Remove clutter below anvils\n",
      "   332                                                 ds = remove_clutter_below_anvils(ds, variables=variables)\n",
      "   333                                         \n",
      "   334                                             # Second pass at speckle removal\n",
      "   335   4372.4 MiB     -0.0 MiB           1       ds = remove_speckles(ds, variables=variables)\n",
      "   336                                         \n",
      "   337   4372.4 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   350   3598.7 MiB   3598.7 MiB           1   @profile\n",
      "   351                                         def convert_gridrad(time, filepath, track_options, dataset_options, grid_options):\n",
      "   352                                             \"\"\"Convert gridrad data to the standard format.\"\"\"\n",
      "   353                                         \n",
      "   354   3598.7 MiB      0.0 MiB           1       logger.debug(f\"Converting GridRad dataset at time {time}.\")\n",
      "   355                                         \n",
      "   356                                             # Open the dataset and perform preliminary filtering and decluttering\n",
      "   357   3598.7 MiB      0.0 MiB           1       lock = multiprocessing.Lock()\n",
      "   358   4213.1 MiB      0.0 MiB           2       with lock:\n",
      "   359   4213.1 MiB    614.4 MiB           1           ds = open_gridrad(filepath, dataset_options)\n",
      "   360   4292.8 MiB     79.6 MiB           1       ds = filter(ds, refl_thresh=-10)\n",
      "   361   4292.9 MiB      0.1 MiB           1       ds = remove_clutter(ds)\n",
      "   362                                         \n",
      "   363                                             # Ensure the intended time is in the dataset\n",
      "   364   4292.9 MiB      0.0 MiB           1       if time not in ds.time.values:\n",
      "   365                                                 raise ValueError(f\"{time} not in {filepath}\")\n",
      "   366                                         \n",
      "   367                                             # Restructure the dataset\n",
      "   368   4292.9 MiB      0.0 MiB           1       names_dict = {\"Latitude\": \"latitude\", \"Longitude\": \"longitude\"}\n",
      "   369   4292.9 MiB      0.0 MiB           1       names_dict.update({\"Altitude\": \"altitude\", \"Reflectivity\": \"reflectivity\"})\n",
      "   370   4292.9 MiB      0.0 MiB           1       names_dict.update({\"Nradobs\": \"number_of_observations\"})\n",
      "   371   4292.9 MiB      0.0 MiB           1       names_dict.update({\"Nradecho\": \"number_of_echoes\"})\n",
      "   372                                         \n",
      "   373   4292.9 MiB      0.0 MiB           1       ds = ds.rename(names_dict)\n",
      "   374                                         \n",
      "   375   4292.9 MiB      0.0 MiB           4       for dim in [\"latitude\", \"longitude\", \"altitude\"]:\n",
      "   376   4292.9 MiB      0.0 MiB           3           ds[dim].attrs[\"standard_name\"] = dim\n",
      "   377   4292.9 MiB      0.0 MiB           3           ds[dim].attrs[\"long_name\"] = dim\n",
      "   378   4292.9 MiB      0.0 MiB           1       ds[\"altitude\"] = ds[\"altitude\"] * 1000  # Convert to meters\n",
      "   379   4292.9 MiB      0.0 MiB           1       kept_fields = dataset_options[\"fields\"] + [\"number_of_observations\"]\n",
      "   380   4292.9 MiB      0.0 MiB           1       kept_fields += [\"number_of_echoes\"]\n",
      "   381   4292.9 MiB      0.0 MiB           7       dropped_fields = [f for f in ds.data_vars if f not in kept_fields]\n",
      "   382   3974.9 MiB   -318.0 MiB           1       ds = ds.drop_vars(dropped_fields)\n",
      "   383                                         \n",
      "   384   3974.9 MiB      0.0 MiB           2       for field in dataset_options[\"fields\"]:\n",
      "   385   3974.9 MiB      0.0 MiB           1           ds[field] = ds[field].expand_dims(\"time\")\n",
      "   386   3974.9 MiB      0.0 MiB           1           ds[field].attrs[\"long_name\"] = field\n",
      "   387                                         \n",
      "   388   3974.9 MiB      0.0 MiB           1       spacing = [ds.latitude.delta, ds.longitude.delta]\n",
      "   389   3974.9 MiB      0.0 MiB           1       if grid_options[\"name\"] == \"geographic\":\n",
      "   390   3974.9 MiB      0.0 MiB           1           grid_options[\"latitude\"] = ds.latitude.values\n",
      "   391   3974.9 MiB      0.0 MiB           1           grid_options[\"longitude\"] = ds.longitude.values\n",
      "   392   3974.9 MiB      0.0 MiB           1           grid_options[\"altitude\"] = ds.altitude.values\n",
      "   393   3974.9 MiB      0.0 MiB           1           grid_options[\"geographic_spacing\"] = spacing\n",
      "   394   3974.9 MiB      0.0 MiB           1           grid_options[\"shape\"] = [len(ds.latitude), len(ds.longitude)]\n",
      "   395                                         \n",
      "   396   3974.9 MiB      0.0 MiB           1       ds[\"longitude\"] = ds[\"longitude\"] % 360\n",
      "   397                                         \n",
      "   398                                             # Get the domain mask associated with the given object\n",
      "   399                                             # Note the relevant domain mask is a function of how the object is detected, e.g.\n",
      "   400                                             # which levels!\n",
      "   401   3996.6 MiB     21.7 MiB           1       domain_mask = get_domain_mask(ds, track_options, dataset_options)\n",
      "   402   3974.8 MiB    -21.8 MiB           1       boundary_coords, boundary_mask = utils.get_mask_boundary(domain_mask, grid_options)\n",
      "   403   3974.8 MiB      0.0 MiB           1       ds[\"domain_mask\"] = domain_mask\n",
      "   404   3974.8 MiB      0.0 MiB           1       ds[\"boundary_mask\"] = boundary_mask\n",
      "   405                                         \n",
      "   406                                             # Don't mask the gridcell areas\n",
      "   407   3974.8 MiB      0.0 MiB           1       cell_areas = grid.get_cell_areas(grid_options)\n",
      "   408   3974.8 MiB      0.0 MiB           1       ds[\"gridcell_area\"] = ([\"latitude\", \"longitude\"], cell_areas)\n",
      "   409   3974.8 MiB      0.0 MiB           1       area_attrs = {\"units\": \"km^2\", \"standard_name\": \"area\", \"valid_min\": 0}\n",
      "   410   3974.8 MiB      0.0 MiB           1       ds[\"gridcell_area\"].attrs.update(area_attrs)\n",
      "   411                                         \n",
      "   412                                             # Apply the domain mask to the current grid\n",
      "   413   4054.3 MiB     79.5 MiB           1       ds = utils.apply_mask(ds, grid_options)\n",
      "   414   3895.2 MiB   -159.1 MiB           1       ds = ds.drop_vars([\"number_of_observations\", \"number_of_echoes\"])\n",
      "   415   3895.2 MiB      0.0 MiB           1       return ds, boundary_coords\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 17:33:49,990 - thor.track - INFO - Processing hierarchy level 0.\n",
      "2024-10-21 17:33:49,991 - thor.track - INFO - Tracking convective.\n",
      "2024-10-21 17:34:10,249 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:34:10,249 - thor.track - INFO - Tracking middle.\n",
      "2024-10-21 17:34:16,266 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:34:16,267 - thor.track - INFO - Tracking anvil.\n",
      "2024-10-21 17:34:18,635 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:34:18,636 - thor.track - INFO - Processing hierarchy level 1.\n",
      "2024-10-21 17:34:18,637 - thor.track - INFO - Tracking mcs.\n",
      "2024-10-21 17:34:18,659 - thor.write.mask - INFO - Writing mcs masks to /home/ewan/THOR_output/runs/gridrad_demo_20100121/masks/mcs.zarr.\n",
      "2024-10-21 17:34:30,379 - thor.match.match - INFO - Matching mcs objects.\n",
      "2024-10-21 17:34:30,851 - thor.match.match - INFO - Updating object record.\n",
      "2024-10-21 17:34:30,981 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:34:31,875 - thor.track - INFO - Processing 2010-01-21T12:40:00.\n",
      "2024-10-21 17:34:31,876 - thor.data.gridrad - INFO - Updating gridrad dataset for 2010-01-21T12:40:00.\n",
      "2024-10-21 17:34:31,876 - thor.data.gridrad - INFO - Converting gridrad data from nexrad_3d_v4_2_20100121T124000Z.nc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   117   3752.2 MiB   3752.2 MiB           1   @profile\n",
      "   118                                         def reshape_variable(ds, variable):\n",
      "   119                                             \"\"\"\n",
      "   120                                             Reshape a variable in a GridRad dataset to a 3D grid. Adapted from code provided by\n",
      "   121                                             Stacey Hitchcock.\n",
      "   122                                             \"\"\"\n",
      "   123                                         \n",
      "   124   3752.2 MiB      0.0 MiB           1       values = ds[variable].values\n",
      "   125   3752.2 MiB      0.0 MiB           1       attrs = ds[variable].attrs\n",
      "   126   3752.2 MiB      0.0 MiB           1       alt, lat, lon = ds[\"Altitude\"], ds[\"Latitude\"], ds[\"Longitude\"]\n",
      "   127   3752.2 MiB      0.0 MiB           1       new_values = np.zeros(len(alt) * len(lat) * len(lon))\n",
      "   128   3983.1 MiB    230.9 MiB           1       new_values[ds.index.values] = values\n",
      "   129   4070.3 MiB     87.3 MiB           1       new_values = new_values.astype(ds[variable].dtype)\n",
      "   130   4070.3 MiB      0.0 MiB           1       new_shape = (len(alt), len(lat), len(lon))\n",
      "   131   4070.3 MiB      0.0 MiB           1       new_dims = [\"Altitude\", \"Latitude\", \"Longitude\"]\n",
      "   132   4070.3 MiB      0.0 MiB           1       new_coords = {\"Altitude\": alt, \"Latitude\": lat, \"Longitude\": lon}\n",
      "   133   4070.3 MiB      0.0 MiB           2       ds[variable] = xr.DataArray(\n",
      "   134   4070.3 MiB      0.0 MiB           1           new_values.reshape(new_shape), dims=new_dims, coords=new_coords\n",
      "   135                                             )\n",
      "   136   4070.3 MiB      0.0 MiB           1       ds[variable].attrs = attrs\n",
      "   137   4070.3 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   117   4070.3 MiB   4070.3 MiB           1   @profile\n",
      "   118                                         def reshape_variable(ds, variable):\n",
      "   119                                             \"\"\"\n",
      "   120                                             Reshape a variable in a GridRad dataset to a 3D grid. Adapted from code provided by\n",
      "   121                                             Stacey Hitchcock.\n",
      "   122                                             \"\"\"\n",
      "   123                                         \n",
      "   124   4070.3 MiB      0.0 MiB           1       values = ds[variable].values\n",
      "   125   4070.3 MiB      0.0 MiB           1       attrs = ds[variable].attrs\n",
      "   126   4070.3 MiB      0.0 MiB           1       alt, lat, lon = ds[\"Altitude\"], ds[\"Latitude\"], ds[\"Longitude\"]\n",
      "   127   4070.3 MiB      0.0 MiB           1       new_values = np.zeros(len(alt) * len(lat) * len(lon))\n",
      "   128   4301.2 MiB    230.9 MiB           1       new_values[ds.index.values] = values\n",
      "   129   4388.4 MiB     87.2 MiB           1       new_values = new_values.astype(ds[variable].dtype)\n",
      "   130   4388.4 MiB      0.0 MiB           1       new_shape = (len(alt), len(lat), len(lon))\n",
      "   131   4388.4 MiB      0.0 MiB           1       new_dims = [\"Altitude\", \"Latitude\", \"Longitude\"]\n",
      "   132   4388.4 MiB      0.0 MiB           1       new_coords = {\"Altitude\": alt, \"Latitude\": lat, \"Longitude\": lon}\n",
      "   133   4388.4 MiB      0.0 MiB           2       ds[variable] = xr.DataArray(\n",
      "   134   4388.4 MiB      0.0 MiB           1           new_values.reshape(new_shape), dims=new_dims, coords=new_coords\n",
      "   135                                             )\n",
      "   136   4388.4 MiB      0.0 MiB           1       ds[variable].attrs = attrs\n",
      "   137   4388.4 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "    99   3752.2 MiB   3752.2 MiB           1   @profile\n",
      "   100                                         def open_gridrad(path, dataset_options):\n",
      "   101                                             \"\"\"\n",
      "   102                                             Open a GridRad netcdf file, converting variables with an \"Index\" dimension back to 3D\n",
      "   103                                             \"\"\"\n",
      "   104                                         \n",
      "   105   3752.2 MiB      0.0 MiB           4       kept_variables = [gridrad_names_dict[f] for f in dataset_options[\"fields\"]]\n",
      "   106   3752.2 MiB      0.0 MiB           1       kept_variables += [\"Nradobs\", \"Nradecho\", \"wReflectivity\", \"CorrelationCoefficient\"]\n",
      "   107   3752.2 MiB      0.0 MiB           1       ds = xr.open_dataset(path)\n",
      "   108   3752.2 MiB      0.0 MiB           8       kept_variables = [v for v in kept_variables if v in ds.data_vars]\n",
      "   109   3752.2 MiB      0.0 MiB          15       dropped_variables = [v for v in ds.data_vars if v not in kept_variables]\n",
      "   110   4388.4 MiB      0.0 MiB           5       for var in kept_variables:\n",
      "   111   4070.3 MiB      0.0 MiB           4           if var != \"index\" and \"Index\" in ds[var].dims:\n",
      "   112   4388.4 MiB    636.2 MiB           2               ds = reshape_variable(ds, var)\n",
      "   113   4388.4 MiB      0.0 MiB           1       ds = ds.drop_vars(dropped_variables + [\"index\"])\n",
      "   114   4388.4 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   140   4388.4 MiB   4388.4 MiB           1   @profile\n",
      "   141                                         def filter(\n",
      "   142                                             ds,\n",
      "   143                                             weight_thresh=1.5,\n",
      "   144                                             echo_frac_thresh=0.6,\n",
      "   145                                             refl_thresh=0,\n",
      "   146                                             obs_thresh=2,\n",
      "   147                                             variables=None,\n",
      "   148                                         ):\n",
      "   149                                             \"\"\"\n",
      "   150                                             Filter a GridRad dataset. Based on code from the GridRad website\n",
      "   151                                             https://gridrad.org/software.html and edits by Stacey Hitchcock.\n",
      "   152                                         \n",
      "   153                                             Parameters\n",
      "   154                                             ----------\n",
      "   155                                             ds : xarray.Dataset\n",
      "   156                                                 The GridRad dataset.\n",
      "   157                                             weight_thresh : float, optional\n",
      "   158                                                 The bin weight threshold. Default is 1.5.\n",
      "   159                                             echo_frac_thresh : float, optional\n",
      "   160                                                 The echo fraction threshold. Default is 0.6.\n",
      "   161                                             refl_thresh : float, optional\n",
      "   162                                                 The reflectivity threshold. Default is 0.\n",
      "   163                                             obs_thresh : int, optional\n",
      "   164                                                 The number of observations. Default is 2.\n",
      "   165                                         \n",
      "   166                                             Returns\n",
      "   167                                             -------\n",
      "   168                                             ds : xarray.Dataset\n",
      "   169                                                 The filtered GridRad dataset\n",
      "   170                                             \"\"\"\n",
      "   171                                         \n",
      "   172   4388.4 MiB      0.0 MiB           1       logger.debug(\"Filtering GridRad data\")\n",
      "   173                                         \n",
      "   174   4388.4 MiB      0.0 MiB           1       if variables is None:\n",
      "   175   4388.4 MiB      0.0 MiB          10           variables = [v for v in gridrad_variables if v in ds.variables]\n",
      "   176                                         \n",
      "   177                                             # echo_fraction = xr.zeros_like(ds[\"Nradecho\"]).astype(np.float32)\n",
      "   178                                             # Calcualate echo fraction efficiently using lazy loading and where\n",
      "   179   4388.4 MiB      0.0 MiB           1       kwargs = {\"keep_attrs\": True}\n",
      "   180   5183.7 MiB    -79.5 MiB           3       echo_fraction = xr.where(\n",
      "   181   5183.7 MiB    795.2 MiB           2           ds[\"Nradobs\"] > 0, ds[\"Nradecho\"] / ds[\"Nradobs\"], 0.0, **kwargs\n",
      "   182                                             )\n",
      "   183   4786.0 MiB   -397.6 MiB           1       echo_fraction = echo_fraction.astype(np.float32)\n",
      "   184                                         \n",
      "   185                                             # Get indices to filter\n",
      "   186   4865.6 MiB     79.5 MiB           1       weight_cond = xr.where(ds[\"wReflectivity\"] < weight_thresh, True, False, **kwargs)\n",
      "   187   4945.1 MiB     79.5 MiB           1       refl_cond = xr.where(ds[\"Reflectivity\"] <= refl_thresh, True, False, **kwargs)\n",
      "   188   5024.6 MiB     79.5 MiB           1       frac_cond = xr.where(echo_fraction < echo_frac_thresh, True, False, **kwargs)\n",
      "   189   5104.2 MiB     79.5 MiB           1       obs_cond = xr.where(ds[\"Nradobs\"] <= obs_thresh, True, False, **kwargs)\n",
      "   190                                             # Filter cells below weight and reflectivity thresholds\n",
      "   191   5183.7 MiB     79.5 MiB           1       cond_refl = xr.where(weight_cond & refl_cond, True, False, **kwargs)\n",
      "   192                                             # Filter cells containing at < obs_thresh observations. If at least obs_thresh\n",
      "   193                                             # observations, filter cells with echoes in less than echo_fraction_thresh of the\n",
      "   194                                             # total observations\n",
      "   195   5263.2 MiB     79.5 MiB           1       cond_frac = xr.where(obs_cond | frac_cond, True, False, **kwargs)\n",
      "   196                                             # Retain values not filtered\n",
      "   197   5342.8 MiB     79.5 MiB           1       preserved = xr.where(~cond_refl & ~cond_frac, True, False, **kwargs)\n",
      "   198   5342.8 MiB      0.0 MiB           2       for var in variables:\n",
      "   199   5342.8 MiB      0.1 MiB           1           ds[var] = ds[var].where(preserved)\n",
      "   200                                         \n",
      "   201   5342.8 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   204   4547.6 MiB   4547.6 MiB           1   @profile\n",
      "   205                                         def remove_speckles(ds, window_size=5, coverage_thresh=0.32, variables=None):\n",
      "   206                                             \"\"\"\n",
      "   207                                             Remove speckles in GridRad data. Based on code from the GridRad website\n",
      "   208                                             https://gridrad.org/software.html and edits by Stacey Hitchcock. Modified from the\n",
      "   209                                             original to use xr.rolling instead of np.roll to correctly handle edges and corners.\n",
      "   210                                             \"\"\"\n",
      "   211                                         \n",
      "   212   4547.6 MiB      0.0 MiB           1       logger.debug(\"Removing speckles from the GridRad data\")\n",
      "   213                                         \n",
      "   214   4547.6 MiB      0.0 MiB           1       if variables is None:\n",
      "   215                                                 variables = [v for v in gridrad_variables if v in ds.variables]\n",
      "   216                                         \n",
      "   217                                             # refl_exists = np.isfinite(ds[\"Reflectivity\"]).astype(float)\n",
      "   218   4627.0 MiB     79.4 MiB           1       refl_exists = xr.where(ds[\"Reflectivity\"] != np.nan, True, False)\n",
      "   219   4627.0 MiB      0.0 MiB           1       min_size = window_size**3 * coverage_thresh\n",
      "   220   4706.4 MiB     79.4 MiB           1       speckle_mask = remove_small_objects(refl_exists.values > 0, min_size=min_size)\n",
      "   221   4706.5 MiB      0.0 MiB           2       for var in variables:\n",
      "   222   4706.5 MiB      0.1 MiB           1           ds[var] = ds[var].where(speckle_mask)\n",
      "   223                                         \n",
      "   224   4706.5 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   227   4547.4 MiB   4547.4 MiB           1   @profile\n",
      "   228                                         def remove_low_level_clutter(ds, variables=None):\n",
      "   229                                             \"\"\"\n",
      "   230                                             Remove low level clutter from GridRad data. Based on code from the GridRad website\n",
      "   231                                             https://gridrad.org/software.html and edits by Stacey Hitchcock.\n",
      "   232                                             \"\"\"\n",
      "   233                                         \n",
      "   234   4547.4 MiB      0.0 MiB           1       logger.debug(\"Removing low level clutter from the GridRad data\")\n",
      "   235                                         \n",
      "   236                                             # Determine max heights of non-nan reflectivity values. If entire column is nan,\n",
      "   237                                             # set max altitude to zero.\n",
      "   238   4547.4 MiB      0.0 MiB           1       refl_max = ds.Reflectivity.max(dim=\"Altitude\", skipna=True)\n",
      "   239   5183.6 MiB    636.2 MiB           1       refl_0_alts = ds.Altitude.where(ds.Reflectivity > 0.0, 0.0)\n",
      "   240   5183.6 MiB      0.0 MiB           1       refl_0_max_alt = refl_0_alts.max(dim=\"Altitude\")\n",
      "   241   5183.6 MiB      0.0 MiB           1       refl_0_min_alt = refl_0_alts.min(dim=\"Altitude\")\n",
      "   242   5183.6 MiB      0.0 MiB           1       refl_5_max_alt = ds.Altitude.where(ds.Reflectivity > 5.0, 0.0).max(dim=\"Altitude\")\n",
      "   243   5183.6 MiB      0.0 MiB           1       refl_15_max_alt = ds.Altitude.where(ds.Reflectivity > 15.0, 0.0).max(dim=\"Altitude\")\n",
      "   244                                         \n",
      "   245                                             # Check for very weak echos below 4 km\n",
      "   246   5183.6 MiB      0.0 MiB           1       cond_1 = (refl_max < 20.0) & (refl_0_max_alt <= 4.0) & (refl_0_min_alt <= 3.0)\n",
      "   247                                             # Check for very weak echos below 5 km\n",
      "   248   5183.6 MiB      0.0 MiB           1       cond_2 = (refl_max < 10.0) & (refl_0_max_alt <= 5.0) & (refl_0_min_alt <= 3.0)\n",
      "   249                                             # Check for weak echos below 5 km. Note the > 0.0 ensures values actually exist\n",
      "   250   5183.6 MiB      0.0 MiB           1       cond_3 = (refl_5_max_alt <= 5.0) & (refl_5_max_alt > 0.0) & (refl_15_max_alt <= 3.0)\n",
      "   251                                             # Check for weak echos below 2 km\n",
      "   252   5183.6 MiB      0.0 MiB           1       cond_4 = (refl_15_max_alt < 2.0) & (refl_15_max_alt > 0.0)\n",
      "   253   5183.6 MiB      0.0 MiB           1       cond = np.logical_not(cond_1 | cond_2 | cond_3 | cond_4)\n",
      "   254   5183.7 MiB      0.0 MiB           2       for var in variables:\n",
      "   255   5183.7 MiB      0.1 MiB           1           ds[var] = ds[var].where(cond)\n",
      "   256   5183.7 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   204   4547.4 MiB   4547.4 MiB           1   @profile\n",
      "   205                                         def remove_speckles(ds, window_size=5, coverage_thresh=0.32, variables=None):\n",
      "   206                                             \"\"\"\n",
      "   207                                             Remove speckles in GridRad data. Based on code from the GridRad website\n",
      "   208                                             https://gridrad.org/software.html and edits by Stacey Hitchcock. Modified from the\n",
      "   209                                             original to use xr.rolling instead of np.roll to correctly handle edges and corners.\n",
      "   210                                             \"\"\"\n",
      "   211                                         \n",
      "   212   4547.4 MiB      0.0 MiB           1       logger.debug(\"Removing speckles from the GridRad data\")\n",
      "   213                                         \n",
      "   214   4547.4 MiB      0.0 MiB           1       if variables is None:\n",
      "   215                                                 variables = [v for v in gridrad_variables if v in ds.variables]\n",
      "   216                                         \n",
      "   217                                             # refl_exists = np.isfinite(ds[\"Reflectivity\"]).astype(float)\n",
      "   218   4626.9 MiB     79.5 MiB           1       refl_exists = xr.where(ds[\"Reflectivity\"] != np.nan, True, False)\n",
      "   219   4626.9 MiB      0.0 MiB           1       min_size = window_size**3 * coverage_thresh\n",
      "   220   4706.4 MiB     79.5 MiB           1       speckle_mask = remove_small_objects(refl_exists.values > 0, min_size=min_size)\n",
      "   221   4706.6 MiB      0.0 MiB           2       for var in variables:\n",
      "   222   4706.6 MiB      0.2 MiB           1           ds[var] = ds[var].where(speckle_mask)\n",
      "   223                                         \n",
      "   224   4706.6 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   281   4468.0 MiB   4468.0 MiB           1   @profile\n",
      "   282                                         def remove_clutter(ds, variables=None, low_level=True, below_anvil=False):\n",
      "   283                                             \"\"\"\n",
      "   284                                             Remove clutter from GridRad data. Based on code from the GridRad website\n",
      "   285                                             https://gridrad.org/software.html and edits by Stacey Hitchcock.\n",
      "   286                                         \n",
      "   287                                             Parameters\n",
      "   288                                             ----------\n",
      "   289                                             ds : xarray.Dataset\n",
      "   290                                                 The GridRad dataset.\n",
      "   291                                             variables : list, optional\n",
      "   292                                                 The variables to remove clutter from. Default is [\"Reflectivity\"].\n",
      "   293                                         \n",
      "   294                                             Returns\n",
      "   295                                             -------\n",
      "   296                                             ds : xarray.Dataset\n",
      "   297                                                 The GridRad dataset with clutter removed.\n",
      "   298                                             \"\"\"\n",
      "   299                                         \n",
      "   300   4468.0 MiB      0.0 MiB           1       logger.debug(\"Removing clutter from the GridRad data\")\n",
      "   301                                         \n",
      "   302   4468.0 MiB      0.0 MiB           1       if variables is None:\n",
      "   303   4468.0 MiB      0.0 MiB          10           variables = [v for v in gridrad_variables if v in ds.variables]\n",
      "   304                                         \n",
      "   305                                             # Remove low reflectivity low level clutter\n",
      "   306   4547.5 MiB     79.5 MiB           1       cond = (ds.Reflectivity >= 10.0) | (ds.Altitude > 4.0)\n",
      "   307   4547.6 MiB      0.0 MiB           2       for var in variables:\n",
      "   308   4547.6 MiB      0.1 MiB           1           ds[var] = ds[var].where(cond)\n",
      "   309                                         \n",
      "   310                                             # Attempt correlation based clutter removal if relevant variables exist\n",
      "   311   4547.6 MiB      0.0 MiB           1       correlation_var_list = [\"DifferentialReflectivity\", \"CorrelationCoefficient\"]\n",
      "   312   4547.6 MiB      0.0 MiB           4       if all(corr_var in ds.variables for corr_var in correlation_var_list):\n",
      "   313                                         \n",
      "   314                                                 # Require either high correlation or reflectivity\n",
      "   315                                                 cond1 = ds[\"Reflectivity\"] >= 40.0 | ds[\"r_HV\"] >= 0.9\n",
      "   316                                                 # Require moderate reflectivity or high correlation or low altitude\n",
      "   317                                                 cond2 = ds[\"Reflectivity\"] >= 25.0 | ds[\"CorrelationCoefficient\"] >= 0.95\n",
      "   318                                                 cond2 = cond2 | ds[\"Altitude\"] < 10.0\n",
      "   319                                                 # Require both conditions above be met\n",
      "   320                                                 for var in variables:\n",
      "   321                                                     ds[var] = ds[var].where(cond1 & cond2)\n",
      "   322                                         \n",
      "   323                                             # First pass at speckle removal\n",
      "   324   4547.4 MiB     -0.2 MiB           1       ds = remove_speckles(ds, variables=variables)\n",
      "   325                                         \n",
      "   326   4547.4 MiB      0.0 MiB           1       if low_level:\n",
      "   327                                                 # Remove low level clutter. Note this can remove some low level cloud/drizzle\n",
      "   328   4547.4 MiB      0.0 MiB           1           ds = remove_low_level_clutter(ds, variables=variables)\n",
      "   329                                         \n",
      "   330   4547.4 MiB      0.0 MiB           1       if below_anvil:\n",
      "   331                                                 # Remove clutter below anvils\n",
      "   332                                                 ds = remove_clutter_below_anvils(ds, variables=variables)\n",
      "   333                                         \n",
      "   334                                             # Second pass at speckle removal\n",
      "   335   4547.5 MiB      0.1 MiB           1       ds = remove_speckles(ds, variables=variables)\n",
      "   336                                         \n",
      "   337   4547.5 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   350   3752.2 MiB   3752.2 MiB           1   @profile\n",
      "   351                                         def convert_gridrad(time, filepath, track_options, dataset_options, grid_options):\n",
      "   352                                             \"\"\"Convert gridrad data to the standard format.\"\"\"\n",
      "   353                                         \n",
      "   354   3752.2 MiB      0.0 MiB           1       logger.debug(f\"Converting GridRad dataset at time {time}.\")\n",
      "   355                                         \n",
      "   356                                             # Open the dataset and perform preliminary filtering and decluttering\n",
      "   357   3752.2 MiB      0.0 MiB           1       lock = multiprocessing.Lock()\n",
      "   358   4388.4 MiB      0.0 MiB           2       with lock:\n",
      "   359   4388.4 MiB    636.2 MiB           1           ds = open_gridrad(filepath, dataset_options)\n",
      "   360   4468.0 MiB     79.5 MiB           1       ds = filter(ds, refl_thresh=-10)\n",
      "   361   4468.0 MiB      0.0 MiB           1       ds = remove_clutter(ds)\n",
      "   362                                         \n",
      "   363                                             # Ensure the intended time is in the dataset\n",
      "   364   4468.0 MiB      0.0 MiB           1       if time not in ds.time.values:\n",
      "   365                                                 raise ValueError(f\"{time} not in {filepath}\")\n",
      "   366                                         \n",
      "   367                                             # Restructure the dataset\n",
      "   368   4468.0 MiB      0.0 MiB           1       names_dict = {\"Latitude\": \"latitude\", \"Longitude\": \"longitude\"}\n",
      "   369   4468.0 MiB      0.0 MiB           1       names_dict.update({\"Altitude\": \"altitude\", \"Reflectivity\": \"reflectivity\"})\n",
      "   370   4468.0 MiB      0.0 MiB           1       names_dict.update({\"Nradobs\": \"number_of_observations\"})\n",
      "   371   4468.0 MiB      0.0 MiB           1       names_dict.update({\"Nradecho\": \"number_of_echoes\"})\n",
      "   372                                         \n",
      "   373   4468.0 MiB      0.0 MiB           1       ds = ds.rename(names_dict)\n",
      "   374                                         \n",
      "   375   4468.0 MiB      0.0 MiB           4       for dim in [\"latitude\", \"longitude\", \"altitude\"]:\n",
      "   376   4468.0 MiB      0.0 MiB           3           ds[dim].attrs[\"standard_name\"] = dim\n",
      "   377   4468.0 MiB      0.0 MiB           3           ds[dim].attrs[\"long_name\"] = dim\n",
      "   378   4468.0 MiB      0.0 MiB           1       ds[\"altitude\"] = ds[\"altitude\"] * 1000  # Convert to meters\n",
      "   379   4468.0 MiB      0.0 MiB           1       kept_fields = dataset_options[\"fields\"] + [\"number_of_observations\"]\n",
      "   380   4468.0 MiB      0.0 MiB           1       kept_fields += [\"number_of_echoes\"]\n",
      "   381   4468.0 MiB      0.0 MiB           7       dropped_fields = [f for f in ds.data_vars if f not in kept_fields]\n",
      "   382   4150.0 MiB   -318.0 MiB           1       ds = ds.drop_vars(dropped_fields)\n",
      "   383                                         \n",
      "   384   4150.0 MiB      0.0 MiB           2       for field in dataset_options[\"fields\"]:\n",
      "   385   4150.0 MiB      0.0 MiB           1           ds[field] = ds[field].expand_dims(\"time\")\n",
      "   386   4150.0 MiB      0.0 MiB           1           ds[field].attrs[\"long_name\"] = field\n",
      "   387                                         \n",
      "   388   4150.0 MiB      0.0 MiB           1       spacing = [ds.latitude.delta, ds.longitude.delta]\n",
      "   389   4150.0 MiB      0.0 MiB           1       if grid_options[\"name\"] == \"geographic\":\n",
      "   390   4150.0 MiB      0.0 MiB           1           grid_options[\"latitude\"] = ds.latitude.values\n",
      "   391   4150.0 MiB      0.0 MiB           1           grid_options[\"longitude\"] = ds.longitude.values\n",
      "   392   4150.0 MiB      0.0 MiB           1           grid_options[\"altitude\"] = ds.altitude.values\n",
      "   393   4150.0 MiB      0.0 MiB           1           grid_options[\"geographic_spacing\"] = spacing\n",
      "   394   4150.0 MiB      0.0 MiB           1           grid_options[\"shape\"] = [len(ds.latitude), len(ds.longitude)]\n",
      "   395                                         \n",
      "   396   4150.0 MiB      0.0 MiB           1       ds[\"longitude\"] = ds[\"longitude\"] % 360\n",
      "   397                                         \n",
      "   398                                             # Get the domain mask associated with the given object\n",
      "   399                                             # Note the relevant domain mask is a function of how the object is detected, e.g.\n",
      "   400                                             # which levels!\n",
      "   401   4150.0 MiB      0.0 MiB           1       domain_mask = get_domain_mask(ds, track_options, dataset_options)\n",
      "   402   4150.0 MiB      0.0 MiB           1       boundary_coords, boundary_mask = utils.get_mask_boundary(domain_mask, grid_options)\n",
      "   403   4150.0 MiB      0.0 MiB           1       ds[\"domain_mask\"] = domain_mask\n",
      "   404   4150.0 MiB      0.0 MiB           1       ds[\"boundary_mask\"] = boundary_mask\n",
      "   405                                         \n",
      "   406                                             # Don't mask the gridcell areas\n",
      "   407   4150.0 MiB      0.0 MiB           1       cell_areas = grid.get_cell_areas(grid_options)\n",
      "   408   4150.0 MiB      0.0 MiB           1       ds[\"gridcell_area\"] = ([\"latitude\", \"longitude\"], cell_areas)\n",
      "   409   4150.0 MiB      0.0 MiB           1       area_attrs = {\"units\": \"km^2\", \"standard_name\": \"area\", \"valid_min\": 0}\n",
      "   410   4150.0 MiB      0.0 MiB           1       ds[\"gridcell_area\"].attrs.update(area_attrs)\n",
      "   411                                         \n",
      "   412                                             # Apply the domain mask to the current grid\n",
      "   413   4229.4 MiB     79.4 MiB           1       ds = utils.apply_mask(ds, grid_options)\n",
      "   414   4070.3 MiB   -159.1 MiB           1       ds = ds.drop_vars([\"number_of_observations\", \"number_of_echoes\"])\n",
      "   415   4070.3 MiB      0.0 MiB           1       return ds, boundary_coords\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 17:34:45,326 - thor.track - INFO - Processing hierarchy level 0.\n",
      "2024-10-21 17:34:45,327 - thor.track - INFO - Tracking convective.\n",
      "2024-10-21 17:35:06,631 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:35:06,631 - thor.track - INFO - Tracking middle.\n",
      "2024-10-21 17:35:13,015 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:35:13,016 - thor.track - INFO - Tracking anvil.\n",
      "2024-10-21 17:35:15,138 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:35:15,139 - thor.track - INFO - Processing hierarchy level 1.\n",
      "2024-10-21 17:35:15,139 - thor.track - INFO - Tracking mcs.\n",
      "2024-10-21 17:35:15,158 - thor.write.mask - INFO - Writing mcs masks to /home/ewan/THOR_output/runs/gridrad_demo_20100121/masks/mcs.zarr.\n",
      "2024-10-21 17:35:27,249 - thor.match.match - INFO - Matching mcs objects.\n",
      "2024-10-21 17:35:27,752 - thor.match.match - INFO - Updating object record.\n",
      "2024-10-21 17:35:27,881 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:35:28,827 - thor.track - INFO - Processing 2010-01-21T12:50:00.\n",
      "2024-10-21 17:35:28,828 - thor.data.gridrad - INFO - Updating gridrad dataset for 2010-01-21T12:50:00.\n",
      "2024-10-21 17:35:28,829 - thor.data.gridrad - INFO - Converting gridrad data from nexrad_3d_v4_2_20100121T125000Z.nc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   117   3796.2 MiB   3796.2 MiB           1   @profile\n",
      "   118                                         def reshape_variable(ds, variable):\n",
      "   119                                             \"\"\"\n",
      "   120                                             Reshape a variable in a GridRad dataset to a 3D grid. Adapted from code provided by\n",
      "   121                                             Stacey Hitchcock.\n",
      "   122                                             \"\"\"\n",
      "   123                                         \n",
      "   124   3796.2 MiB      0.0 MiB           1       values = ds[variable].values\n",
      "   125   3796.2 MiB      0.0 MiB           1       attrs = ds[variable].attrs\n",
      "   126   3796.2 MiB      0.0 MiB           1       alt, lat, lon = ds[\"Altitude\"], ds[\"Latitude\"], ds[\"Longitude\"]\n",
      "   127   3796.2 MiB      0.0 MiB           1       new_values = np.zeros(len(alt) * len(lat) * len(lon))\n",
      "   128   4030.9 MiB    234.6 MiB           1       new_values[ds.index.values] = values\n",
      "   129   4114.2 MiB     83.4 MiB           1       new_values = new_values.astype(ds[variable].dtype)\n",
      "   130   4114.2 MiB      0.0 MiB           1       new_shape = (len(alt), len(lat), len(lon))\n",
      "   131   4114.2 MiB      0.0 MiB           1       new_dims = [\"Altitude\", \"Latitude\", \"Longitude\"]\n",
      "   132   4114.2 MiB      0.0 MiB           1       new_coords = {\"Altitude\": alt, \"Latitude\": lat, \"Longitude\": lon}\n",
      "   133   4114.2 MiB      0.0 MiB           2       ds[variable] = xr.DataArray(\n",
      "   134   4114.2 MiB      0.0 MiB           1           new_values.reshape(new_shape), dims=new_dims, coords=new_coords\n",
      "   135                                             )\n",
      "   136   4114.2 MiB      0.0 MiB           1       ds[variable].attrs = attrs\n",
      "   137   4114.2 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   117   4114.2 MiB   4114.2 MiB           1   @profile\n",
      "   118                                         def reshape_variable(ds, variable):\n",
      "   119                                             \"\"\"\n",
      "   120                                             Reshape a variable in a GridRad dataset to a 3D grid. Adapted from code provided by\n",
      "   121                                             Stacey Hitchcock.\n",
      "   122                                             \"\"\"\n",
      "   123                                         \n",
      "   124   4114.2 MiB      0.0 MiB           1       values = ds[variable].values\n",
      "   125   4114.2 MiB      0.0 MiB           1       attrs = ds[variable].attrs\n",
      "   126   4114.2 MiB      0.0 MiB           1       alt, lat, lon = ds[\"Altitude\"], ds[\"Latitude\"], ds[\"Longitude\"]\n",
      "   127   4114.2 MiB      0.0 MiB           1       new_values = np.zeros(len(alt) * len(lat) * len(lon))\n",
      "   128   4349.0 MiB    234.8 MiB           1       new_values[ds.index.values] = values\n",
      "   129   4432.3 MiB     83.3 MiB           1       new_values = new_values.astype(ds[variable].dtype)\n",
      "   130   4432.3 MiB      0.0 MiB           1       new_shape = (len(alt), len(lat), len(lon))\n",
      "   131   4432.3 MiB      0.0 MiB           1       new_dims = [\"Altitude\", \"Latitude\", \"Longitude\"]\n",
      "   132   4432.3 MiB      0.0 MiB           1       new_coords = {\"Altitude\": alt, \"Latitude\": lat, \"Longitude\": lon}\n",
      "   133   4432.3 MiB      0.0 MiB           2       ds[variable] = xr.DataArray(\n",
      "   134   4432.3 MiB      0.0 MiB           1           new_values.reshape(new_shape), dims=new_dims, coords=new_coords\n",
      "   135                                             )\n",
      "   136   4432.3 MiB      0.0 MiB           1       ds[variable].attrs = attrs\n",
      "   137   4432.3 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "    99   3796.2 MiB   3796.2 MiB           1   @profile\n",
      "   100                                         def open_gridrad(path, dataset_options):\n",
      "   101                                             \"\"\"\n",
      "   102                                             Open a GridRad netcdf file, converting variables with an \"Index\" dimension back to 3D\n",
      "   103                                             \"\"\"\n",
      "   104                                         \n",
      "   105   3796.2 MiB      0.0 MiB           4       kept_variables = [gridrad_names_dict[f] for f in dataset_options[\"fields\"]]\n",
      "   106   3796.2 MiB      0.0 MiB           1       kept_variables += [\"Nradobs\", \"Nradecho\", \"wReflectivity\", \"CorrelationCoefficient\"]\n",
      "   107   3796.2 MiB      0.0 MiB           1       ds = xr.open_dataset(path)\n",
      "   108   3796.2 MiB      0.0 MiB           8       kept_variables = [v for v in kept_variables if v in ds.data_vars]\n",
      "   109   3796.2 MiB      0.0 MiB          15       dropped_variables = [v for v in ds.data_vars if v not in kept_variables]\n",
      "   110   4432.3 MiB      0.0 MiB           5       for var in kept_variables:\n",
      "   111   4114.2 MiB      0.0 MiB           4           if var != \"index\" and \"Index\" in ds[var].dims:\n",
      "   112   4432.3 MiB    636.1 MiB           2               ds = reshape_variable(ds, var)\n",
      "   113   4432.3 MiB      0.0 MiB           1       ds = ds.drop_vars(dropped_variables + [\"index\"])\n",
      "   114   4432.3 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   140   4432.3 MiB   4432.3 MiB           1   @profile\n",
      "   141                                         def filter(\n",
      "   142                                             ds,\n",
      "   143                                             weight_thresh=1.5,\n",
      "   144                                             echo_frac_thresh=0.6,\n",
      "   145                                             refl_thresh=0,\n",
      "   146                                             obs_thresh=2,\n",
      "   147                                             variables=None,\n",
      "   148                                         ):\n",
      "   149                                             \"\"\"\n",
      "   150                                             Filter a GridRad dataset. Based on code from the GridRad website\n",
      "   151                                             https://gridrad.org/software.html and edits by Stacey Hitchcock.\n",
      "   152                                         \n",
      "   153                                             Parameters\n",
      "   154                                             ----------\n",
      "   155                                             ds : xarray.Dataset\n",
      "   156                                                 The GridRad dataset.\n",
      "   157                                             weight_thresh : float, optional\n",
      "   158                                                 The bin weight threshold. Default is 1.5.\n",
      "   159                                             echo_frac_thresh : float, optional\n",
      "   160                                                 The echo fraction threshold. Default is 0.6.\n",
      "   161                                             refl_thresh : float, optional\n",
      "   162                                                 The reflectivity threshold. Default is 0.\n",
      "   163                                             obs_thresh : int, optional\n",
      "   164                                                 The number of observations. Default is 2.\n",
      "   165                                         \n",
      "   166                                             Returns\n",
      "   167                                             -------\n",
      "   168                                             ds : xarray.Dataset\n",
      "   169                                                 The filtered GridRad dataset\n",
      "   170                                             \"\"\"\n",
      "   171                                         \n",
      "   172   4432.3 MiB      0.0 MiB           1       logger.debug(\"Filtering GridRad data\")\n",
      "   173                                         \n",
      "   174   4432.3 MiB      0.0 MiB           1       if variables is None:\n",
      "   175   4432.3 MiB      0.0 MiB          10           variables = [v for v in gridrad_variables if v in ds.variables]\n",
      "   176                                         \n",
      "   177                                             # echo_fraction = xr.zeros_like(ds[\"Nradecho\"]).astype(np.float32)\n",
      "   178                                             # Calcualate echo fraction efficiently using lazy loading and where\n",
      "   179   4432.3 MiB      0.0 MiB           1       kwargs = {\"keep_attrs\": True}\n",
      "   180   5227.6 MiB    -79.5 MiB           3       echo_fraction = xr.where(\n",
      "   181   5227.6 MiB    795.2 MiB           2           ds[\"Nradobs\"] > 0, ds[\"Nradecho\"] / ds[\"Nradobs\"], 0.0, **kwargs\n",
      "   182                                             )\n",
      "   183   4830.0 MiB   -397.6 MiB           1       echo_fraction = echo_fraction.astype(np.float32)\n",
      "   184                                         \n",
      "   185                                             # Get indices to filter\n",
      "   186   4909.5 MiB     79.5 MiB           1       weight_cond = xr.where(ds[\"wReflectivity\"] < weight_thresh, True, False, **kwargs)\n",
      "   187   4989.0 MiB     79.5 MiB           1       refl_cond = xr.where(ds[\"Reflectivity\"] <= refl_thresh, True, False, **kwargs)\n",
      "   188   5068.5 MiB     79.5 MiB           1       frac_cond = xr.where(echo_fraction < echo_frac_thresh, True, False, **kwargs)\n",
      "   189   5148.1 MiB     79.5 MiB           1       obs_cond = xr.where(ds[\"Nradobs\"] <= obs_thresh, True, False, **kwargs)\n",
      "   190                                             # Filter cells below weight and reflectivity thresholds\n",
      "   191   5227.6 MiB     79.5 MiB           1       cond_refl = xr.where(weight_cond & refl_cond, True, False, **kwargs)\n",
      "   192                                             # Filter cells containing at < obs_thresh observations. If at least obs_thresh\n",
      "   193                                             # observations, filter cells with echoes in less than echo_fraction_thresh of the\n",
      "   194                                             # total observations\n",
      "   195   5307.1 MiB     79.5 MiB           1       cond_frac = xr.where(obs_cond | frac_cond, True, False, **kwargs)\n",
      "   196                                             # Retain values not filtered\n",
      "   197   5386.7 MiB     79.5 MiB           1       preserved = xr.where(~cond_refl & ~cond_frac, True, False, **kwargs)\n",
      "   198   5386.8 MiB      0.0 MiB           2       for var in variables:\n",
      "   199   5386.8 MiB      0.1 MiB           1           ds[var] = ds[var].where(preserved)\n",
      "   200                                         \n",
      "   201   5386.8 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   204   4591.5 MiB   4591.5 MiB           1   @profile\n",
      "   205                                         def remove_speckles(ds, window_size=5, coverage_thresh=0.32, variables=None):\n",
      "   206                                             \"\"\"\n",
      "   207                                             Remove speckles in GridRad data. Based on code from the GridRad website\n",
      "   208                                             https://gridrad.org/software.html and edits by Stacey Hitchcock. Modified from the\n",
      "   209                                             original to use xr.rolling instead of np.roll to correctly handle edges and corners.\n",
      "   210                                             \"\"\"\n",
      "   211                                         \n",
      "   212   4591.5 MiB      0.0 MiB           1       logger.debug(\"Removing speckles from the GridRad data\")\n",
      "   213                                         \n",
      "   214   4591.5 MiB      0.0 MiB           1       if variables is None:\n",
      "   215                                                 variables = [v for v in gridrad_variables if v in ds.variables]\n",
      "   216                                         \n",
      "   217                                             # refl_exists = np.isfinite(ds[\"Reflectivity\"]).astype(float)\n",
      "   218   4670.9 MiB     79.4 MiB           1       refl_exists = xr.where(ds[\"Reflectivity\"] != np.nan, True, False)\n",
      "   219   4670.9 MiB      0.0 MiB           1       min_size = window_size**3 * coverage_thresh\n",
      "   220   4750.4 MiB     79.5 MiB           1       speckle_mask = remove_small_objects(refl_exists.values > 0, min_size=min_size)\n",
      "   221   4750.5 MiB      0.0 MiB           2       for var in variables:\n",
      "   222   4750.5 MiB      0.1 MiB           1           ds[var] = ds[var].where(speckle_mask)\n",
      "   223                                         \n",
      "   224   4750.5 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   227   4591.4 MiB   4591.4 MiB           1   @profile\n",
      "   228                                         def remove_low_level_clutter(ds, variables=None):\n",
      "   229                                             \"\"\"\n",
      "   230                                             Remove low level clutter from GridRad data. Based on code from the GridRad website\n",
      "   231                                             https://gridrad.org/software.html and edits by Stacey Hitchcock.\n",
      "   232                                             \"\"\"\n",
      "   233                                         \n",
      "   234   4591.4 MiB      0.0 MiB           1       logger.debug(\"Removing low level clutter from the GridRad data\")\n",
      "   235                                         \n",
      "   236                                             # Determine max heights of non-nan reflectivity values. If entire column is nan,\n",
      "   237                                             # set max altitude to zero.\n",
      "   238   4591.4 MiB      0.0 MiB           1       refl_max = ds.Reflectivity.max(dim=\"Altitude\", skipna=True)\n",
      "   239   5227.6 MiB    636.2 MiB           1       refl_0_alts = ds.Altitude.where(ds.Reflectivity > 0.0, 0.0)\n",
      "   240   5227.6 MiB      0.0 MiB           1       refl_0_max_alt = refl_0_alts.max(dim=\"Altitude\")\n",
      "   241   5227.6 MiB      0.0 MiB           1       refl_0_min_alt = refl_0_alts.min(dim=\"Altitude\")\n",
      "   242   5227.6 MiB      0.0 MiB           1       refl_5_max_alt = ds.Altitude.where(ds.Reflectivity > 5.0, 0.0).max(dim=\"Altitude\")\n",
      "   243   5227.6 MiB      0.0 MiB           1       refl_15_max_alt = ds.Altitude.where(ds.Reflectivity > 15.0, 0.0).max(dim=\"Altitude\")\n",
      "   244                                         \n",
      "   245                                             # Check for very weak echos below 4 km\n",
      "   246   5227.6 MiB      0.0 MiB           1       cond_1 = (refl_max < 20.0) & (refl_0_max_alt <= 4.0) & (refl_0_min_alt <= 3.0)\n",
      "   247                                             # Check for very weak echos below 5 km\n",
      "   248   5227.6 MiB      0.0 MiB           1       cond_2 = (refl_max < 10.0) & (refl_0_max_alt <= 5.0) & (refl_0_min_alt <= 3.0)\n",
      "   249                                             # Check for weak echos below 5 km. Note the > 0.0 ensures values actually exist\n",
      "   250   5227.6 MiB      0.0 MiB           1       cond_3 = (refl_5_max_alt <= 5.0) & (refl_5_max_alt > 0.0) & (refl_15_max_alt <= 3.0)\n",
      "   251                                             # Check for weak echos below 2 km\n",
      "   252   5227.6 MiB      0.0 MiB           1       cond_4 = (refl_15_max_alt < 2.0) & (refl_15_max_alt > 0.0)\n",
      "   253   5227.6 MiB      0.0 MiB           1       cond = np.logical_not(cond_1 | cond_2 | cond_3 | cond_4)\n",
      "   254   5227.7 MiB      0.0 MiB           2       for var in variables:\n",
      "   255   5227.7 MiB      0.1 MiB           1           ds[var] = ds[var].where(cond)\n",
      "   256   5227.7 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   204   4591.4 MiB   4591.4 MiB           1   @profile\n",
      "   205                                         def remove_speckles(ds, window_size=5, coverage_thresh=0.32, variables=None):\n",
      "   206                                             \"\"\"\n",
      "   207                                             Remove speckles in GridRad data. Based on code from the GridRad website\n",
      "   208                                             https://gridrad.org/software.html and edits by Stacey Hitchcock. Modified from the\n",
      "   209                                             original to use xr.rolling instead of np.roll to correctly handle edges and corners.\n",
      "   210                                             \"\"\"\n",
      "   211                                         \n",
      "   212   4591.4 MiB      0.0 MiB           1       logger.debug(\"Removing speckles from the GridRad data\")\n",
      "   213                                         \n",
      "   214   4591.4 MiB      0.0 MiB           1       if variables is None:\n",
      "   215                                                 variables = [v for v in gridrad_variables if v in ds.variables]\n",
      "   216                                         \n",
      "   217                                             # refl_exists = np.isfinite(ds[\"Reflectivity\"]).astype(float)\n",
      "   218   4670.9 MiB     79.5 MiB           1       refl_exists = xr.where(ds[\"Reflectivity\"] != np.nan, True, False)\n",
      "   219   4670.9 MiB      0.0 MiB           1       min_size = window_size**3 * coverage_thresh\n",
      "   220   4750.4 MiB     79.5 MiB           1       speckle_mask = remove_small_objects(refl_exists.values > 0, min_size=min_size)\n",
      "   221   4750.5 MiB      0.0 MiB           2       for var in variables:\n",
      "   222   4750.5 MiB      0.1 MiB           1           ds[var] = ds[var].where(speckle_mask)\n",
      "   223                                         \n",
      "   224   4750.5 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   281   4511.9 MiB   4511.9 MiB           1   @profile\n",
      "   282                                         def remove_clutter(ds, variables=None, low_level=True, below_anvil=False):\n",
      "   283                                             \"\"\"\n",
      "   284                                             Remove clutter from GridRad data. Based on code from the GridRad website\n",
      "   285                                             https://gridrad.org/software.html and edits by Stacey Hitchcock.\n",
      "   286                                         \n",
      "   287                                             Parameters\n",
      "   288                                             ----------\n",
      "   289                                             ds : xarray.Dataset\n",
      "   290                                                 The GridRad dataset.\n",
      "   291                                             variables : list, optional\n",
      "   292                                                 The variables to remove clutter from. Default is [\"Reflectivity\"].\n",
      "   293                                         \n",
      "   294                                             Returns\n",
      "   295                                             -------\n",
      "   296                                             ds : xarray.Dataset\n",
      "   297                                                 The GridRad dataset with clutter removed.\n",
      "   298                                             \"\"\"\n",
      "   299                                         \n",
      "   300   4511.9 MiB      0.0 MiB           1       logger.debug(\"Removing clutter from the GridRad data\")\n",
      "   301                                         \n",
      "   302   4511.9 MiB      0.0 MiB           1       if variables is None:\n",
      "   303   4511.9 MiB      0.0 MiB          10           variables = [v for v in gridrad_variables if v in ds.variables]\n",
      "   304                                         \n",
      "   305                                             # Remove low reflectivity low level clutter\n",
      "   306   4591.4 MiB     79.5 MiB           1       cond = (ds.Reflectivity >= 10.0) | (ds.Altitude > 4.0)\n",
      "   307   4591.5 MiB      0.0 MiB           2       for var in variables:\n",
      "   308   4591.5 MiB      0.1 MiB           1           ds[var] = ds[var].where(cond)\n",
      "   309                                         \n",
      "   310                                             # Attempt correlation based clutter removal if relevant variables exist\n",
      "   311   4591.5 MiB      0.0 MiB           1       correlation_var_list = [\"DifferentialReflectivity\", \"CorrelationCoefficient\"]\n",
      "   312   4591.5 MiB      0.0 MiB           4       if all(corr_var in ds.variables for corr_var in correlation_var_list):\n",
      "   313                                         \n",
      "   314                                                 # Require either high correlation or reflectivity\n",
      "   315                                                 cond1 = ds[\"Reflectivity\"] >= 40.0 | ds[\"r_HV\"] >= 0.9\n",
      "   316                                                 # Require moderate reflectivity or high correlation or low altitude\n",
      "   317                                                 cond2 = ds[\"Reflectivity\"] >= 25.0 | ds[\"CorrelationCoefficient\"] >= 0.95\n",
      "   318                                                 cond2 = cond2 | ds[\"Altitude\"] < 10.0\n",
      "   319                                                 # Require both conditions above be met\n",
      "   320                                                 for var in variables:\n",
      "   321                                                     ds[var] = ds[var].where(cond1 & cond2)\n",
      "   322                                         \n",
      "   323                                             # First pass at speckle removal\n",
      "   324   4591.4 MiB     -0.1 MiB           1       ds = remove_speckles(ds, variables=variables)\n",
      "   325                                         \n",
      "   326   4591.4 MiB      0.0 MiB           1       if low_level:\n",
      "   327                                                 # Remove low level clutter. Note this can remove some low level cloud/drizzle\n",
      "   328   4591.4 MiB      0.0 MiB           1           ds = remove_low_level_clutter(ds, variables=variables)\n",
      "   329                                         \n",
      "   330   4591.4 MiB      0.0 MiB           1       if below_anvil:\n",
      "   331                                                 # Remove clutter below anvils\n",
      "   332                                                 ds = remove_clutter_below_anvils(ds, variables=variables)\n",
      "   333                                         \n",
      "   334                                             # Second pass at speckle removal\n",
      "   335   4591.4 MiB      0.0 MiB           1       ds = remove_speckles(ds, variables=variables)\n",
      "   336                                         \n",
      "   337   4591.4 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   350   3796.2 MiB   3796.2 MiB           1   @profile\n",
      "   351                                         def convert_gridrad(time, filepath, track_options, dataset_options, grid_options):\n",
      "   352                                             \"\"\"Convert gridrad data to the standard format.\"\"\"\n",
      "   353                                         \n",
      "   354   3796.2 MiB      0.0 MiB           1       logger.debug(f\"Converting GridRad dataset at time {time}.\")\n",
      "   355                                         \n",
      "   356                                             # Open the dataset and perform preliminary filtering and decluttering\n",
      "   357   3796.2 MiB      0.0 MiB           1       lock = multiprocessing.Lock()\n",
      "   358   4432.3 MiB      0.0 MiB           2       with lock:\n",
      "   359   4432.3 MiB    636.1 MiB           1           ds = open_gridrad(filepath, dataset_options)\n",
      "   360   4511.9 MiB     79.5 MiB           1       ds = filter(ds, refl_thresh=-10)\n",
      "   361   4511.9 MiB      0.0 MiB           1       ds = remove_clutter(ds)\n",
      "   362                                         \n",
      "   363                                             # Ensure the intended time is in the dataset\n",
      "   364   4511.9 MiB      0.0 MiB           1       if time not in ds.time.values:\n",
      "   365                                                 raise ValueError(f\"{time} not in {filepath}\")\n",
      "   366                                         \n",
      "   367                                             # Restructure the dataset\n",
      "   368   4511.9 MiB      0.0 MiB           1       names_dict = {\"Latitude\": \"latitude\", \"Longitude\": \"longitude\"}\n",
      "   369   4511.9 MiB      0.0 MiB           1       names_dict.update({\"Altitude\": \"altitude\", \"Reflectivity\": \"reflectivity\"})\n",
      "   370   4511.9 MiB      0.0 MiB           1       names_dict.update({\"Nradobs\": \"number_of_observations\"})\n",
      "   371   4511.9 MiB      0.0 MiB           1       names_dict.update({\"Nradecho\": \"number_of_echoes\"})\n",
      "   372                                         \n",
      "   373   4511.9 MiB      0.0 MiB           1       ds = ds.rename(names_dict)\n",
      "   374                                         \n",
      "   375   4511.9 MiB      0.0 MiB           4       for dim in [\"latitude\", \"longitude\", \"altitude\"]:\n",
      "   376   4511.9 MiB      0.0 MiB           3           ds[dim].attrs[\"standard_name\"] = dim\n",
      "   377   4511.9 MiB      0.0 MiB           3           ds[dim].attrs[\"long_name\"] = dim\n",
      "   378   4511.9 MiB      0.0 MiB           1       ds[\"altitude\"] = ds[\"altitude\"] * 1000  # Convert to meters\n",
      "   379   4511.9 MiB      0.0 MiB           1       kept_fields = dataset_options[\"fields\"] + [\"number_of_observations\"]\n",
      "   380   4511.9 MiB      0.0 MiB           1       kept_fields += [\"number_of_echoes\"]\n",
      "   381   4511.9 MiB      0.0 MiB           7       dropped_fields = [f for f in ds.data_vars if f not in kept_fields]\n",
      "   382   4193.9 MiB   -318.0 MiB           1       ds = ds.drop_vars(dropped_fields)\n",
      "   383                                         \n",
      "   384   4193.9 MiB      0.0 MiB           2       for field in dataset_options[\"fields\"]:\n",
      "   385   4193.9 MiB      0.0 MiB           1           ds[field] = ds[field].expand_dims(\"time\")\n",
      "   386   4193.9 MiB      0.0 MiB           1           ds[field].attrs[\"long_name\"] = field\n",
      "   387                                         \n",
      "   388   4193.9 MiB      0.0 MiB           1       spacing = [ds.latitude.delta, ds.longitude.delta]\n",
      "   389   4193.9 MiB      0.0 MiB           1       if grid_options[\"name\"] == \"geographic\":\n",
      "   390   4193.9 MiB      0.0 MiB           1           grid_options[\"latitude\"] = ds.latitude.values\n",
      "   391   4193.9 MiB      0.0 MiB           1           grid_options[\"longitude\"] = ds.longitude.values\n",
      "   392   4193.9 MiB      0.0 MiB           1           grid_options[\"altitude\"] = ds.altitude.values\n",
      "   393   4193.9 MiB      0.0 MiB           1           grid_options[\"geographic_spacing\"] = spacing\n",
      "   394   4193.9 MiB      0.0 MiB           1           grid_options[\"shape\"] = [len(ds.latitude), len(ds.longitude)]\n",
      "   395                                         \n",
      "   396   4193.9 MiB      0.0 MiB           1       ds[\"longitude\"] = ds[\"longitude\"] % 360\n",
      "   397                                         \n",
      "   398                                             # Get the domain mask associated with the given object\n",
      "   399                                             # Note the relevant domain mask is a function of how the object is detected, e.g.\n",
      "   400                                             # which levels!\n",
      "   401   4193.9 MiB      0.0 MiB           1       domain_mask = get_domain_mask(ds, track_options, dataset_options)\n",
      "   402   4193.9 MiB      0.0 MiB           1       boundary_coords, boundary_mask = utils.get_mask_boundary(domain_mask, grid_options)\n",
      "   403   4193.9 MiB      0.0 MiB           1       ds[\"domain_mask\"] = domain_mask\n",
      "   404   4193.9 MiB      0.0 MiB           1       ds[\"boundary_mask\"] = boundary_mask\n",
      "   405                                         \n",
      "   406                                             # Don't mask the gridcell areas\n",
      "   407   4193.9 MiB      0.0 MiB           1       cell_areas = grid.get_cell_areas(grid_options)\n",
      "   408   4193.9 MiB      0.0 MiB           1       ds[\"gridcell_area\"] = ([\"latitude\", \"longitude\"], cell_areas)\n",
      "   409   4193.9 MiB      0.0 MiB           1       area_attrs = {\"units\": \"km^2\", \"standard_name\": \"area\", \"valid_min\": 0}\n",
      "   410   4193.9 MiB      0.0 MiB           1       ds[\"gridcell_area\"].attrs.update(area_attrs)\n",
      "   411                                         \n",
      "   412                                             # Apply the domain mask to the current grid\n",
      "   413   4273.3 MiB     79.4 MiB           1       ds = utils.apply_mask(ds, grid_options)\n",
      "   414   4114.2 MiB   -159.1 MiB           1       ds = ds.drop_vars([\"number_of_observations\", \"number_of_echoes\"])\n",
      "   415   4114.2 MiB      0.0 MiB           1       return ds, boundary_coords\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 17:35:42,210 - thor.track - INFO - Processing hierarchy level 0.\n",
      "2024-10-21 17:35:42,211 - thor.track - INFO - Tracking convective.\n",
      "2024-10-21 17:36:03,381 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:36:03,382 - thor.track - INFO - Tracking middle.\n",
      "2024-10-21 17:36:09,531 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:36:09,531 - thor.track - INFO - Tracking anvil.\n",
      "2024-10-21 17:36:11,566 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:36:11,567 - thor.track - INFO - Processing hierarchy level 1.\n",
      "2024-10-21 17:36:11,568 - thor.track - INFO - Tracking mcs.\n",
      "2024-10-21 17:36:11,594 - thor.write.mask - INFO - Writing mcs masks to /home/ewan/THOR_output/runs/gridrad_demo_20100121/masks/mcs.zarr.\n",
      "2024-10-21 17:36:23,631 - thor.match.match - INFO - Matching mcs objects.\n",
      "2024-10-21 17:36:24,144 - thor.match.match - INFO - Updating object record.\n",
      "2024-10-21 17:36:24,265 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:36:25,145 - thor.track - INFO - Processing 2010-01-21T13:00:00.\n",
      "2024-10-21 17:36:25,147 - thor.data.gridrad - INFO - Updating gridrad dataset for 2010-01-21T13:00:00.\n",
      "2024-10-21 17:36:25,148 - thor.data.gridrad - INFO - Converting gridrad data from nexrad_3d_v4_2_20100121T130000Z.nc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   117   3752.6 MiB   3752.6 MiB           1   @profile\n",
      "   118                                         def reshape_variable(ds, variable):\n",
      "   119                                             \"\"\"\n",
      "   120                                             Reshape a variable in a GridRad dataset to a 3D grid. Adapted from code provided by\n",
      "   121                                             Stacey Hitchcock.\n",
      "   122                                             \"\"\"\n",
      "   123                                         \n",
      "   124   3752.6 MiB      0.0 MiB           1       values = ds[variable].values\n",
      "   125   3752.6 MiB      0.0 MiB           1       attrs = ds[variable].attrs\n",
      "   126   3752.6 MiB      0.0 MiB           1       alt, lat, lon = ds[\"Altitude\"], ds[\"Latitude\"], ds[\"Longitude\"]\n",
      "   127   3752.6 MiB      0.0 MiB           1       new_values = np.zeros(len(alt) * len(lat) * len(lon))\n",
      "   128   3988.8 MiB    236.2 MiB           1       new_values[ds.index.values] = values\n",
      "   129   4070.7 MiB     81.9 MiB           1       new_values = new_values.astype(ds[variable].dtype)\n",
      "   130   4070.7 MiB      0.0 MiB           1       new_shape = (len(alt), len(lat), len(lon))\n",
      "   131   4070.7 MiB      0.0 MiB           1       new_dims = [\"Altitude\", \"Latitude\", \"Longitude\"]\n",
      "   132   4070.7 MiB      0.0 MiB           1       new_coords = {\"Altitude\": alt, \"Latitude\": lat, \"Longitude\": lon}\n",
      "   133   4070.7 MiB      0.0 MiB           2       ds[variable] = xr.DataArray(\n",
      "   134   4070.7 MiB      0.0 MiB           1           new_values.reshape(new_shape), dims=new_dims, coords=new_coords\n",
      "   135                                             )\n",
      "   136   4070.7 MiB      0.0 MiB           1       ds[variable].attrs = attrs\n",
      "   137   4070.7 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   117   4070.7 MiB   4070.7 MiB           1   @profile\n",
      "   118                                         def reshape_variable(ds, variable):\n",
      "   119                                             \"\"\"\n",
      "   120                                             Reshape a variable in a GridRad dataset to a 3D grid. Adapted from code provided by\n",
      "   121                                             Stacey Hitchcock.\n",
      "   122                                             \"\"\"\n",
      "   123                                         \n",
      "   124   4070.7 MiB      0.0 MiB           1       values = ds[variable].values\n",
      "   125   4070.7 MiB      0.0 MiB           1       attrs = ds[variable].attrs\n",
      "   126   4070.7 MiB      0.0 MiB           1       alt, lat, lon = ds[\"Altitude\"], ds[\"Latitude\"], ds[\"Longitude\"]\n",
      "   127   4070.7 MiB      0.0 MiB           1       new_values = np.zeros(len(alt) * len(lat) * len(lon))\n",
      "   128   4307.1 MiB    236.4 MiB           1       new_values[ds.index.values] = values\n",
      "   129   4388.9 MiB     81.8 MiB           1       new_values = new_values.astype(ds[variable].dtype)\n",
      "   130   4388.9 MiB      0.0 MiB           1       new_shape = (len(alt), len(lat), len(lon))\n",
      "   131   4388.9 MiB      0.0 MiB           1       new_dims = [\"Altitude\", \"Latitude\", \"Longitude\"]\n",
      "   132   4388.9 MiB      0.0 MiB           1       new_coords = {\"Altitude\": alt, \"Latitude\": lat, \"Longitude\": lon}\n",
      "   133   4388.9 MiB      0.0 MiB           2       ds[variable] = xr.DataArray(\n",
      "   134   4388.9 MiB      0.0 MiB           1           new_values.reshape(new_shape), dims=new_dims, coords=new_coords\n",
      "   135                                             )\n",
      "   136   4388.9 MiB      0.0 MiB           1       ds[variable].attrs = attrs\n",
      "   137   4388.9 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "    99   3752.6 MiB   3752.6 MiB           1   @profile\n",
      "   100                                         def open_gridrad(path, dataset_options):\n",
      "   101                                             \"\"\"\n",
      "   102                                             Open a GridRad netcdf file, converting variables with an \"Index\" dimension back to 3D\n",
      "   103                                             \"\"\"\n",
      "   104                                         \n",
      "   105   3752.6 MiB      0.0 MiB           4       kept_variables = [gridrad_names_dict[f] for f in dataset_options[\"fields\"]]\n",
      "   106   3752.6 MiB      0.0 MiB           1       kept_variables += [\"Nradobs\", \"Nradecho\", \"wReflectivity\", \"CorrelationCoefficient\"]\n",
      "   107   3752.6 MiB      0.0 MiB           1       ds = xr.open_dataset(path)\n",
      "   108   3752.6 MiB      0.0 MiB           8       kept_variables = [v for v in kept_variables if v in ds.data_vars]\n",
      "   109   3752.6 MiB      0.0 MiB          15       dropped_variables = [v for v in ds.data_vars if v not in kept_variables]\n",
      "   110   4388.9 MiB      0.0 MiB           5       for var in kept_variables:\n",
      "   111   4070.7 MiB      0.0 MiB           4           if var != \"index\" and \"Index\" in ds[var].dims:\n",
      "   112   4388.9 MiB    636.3 MiB           2               ds = reshape_variable(ds, var)\n",
      "   113   4388.9 MiB      0.0 MiB           1       ds = ds.drop_vars(dropped_variables + [\"index\"])\n",
      "   114   4388.9 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   140   4388.9 MiB   4388.9 MiB           1   @profile\n",
      "   141                                         def filter(\n",
      "   142                                             ds,\n",
      "   143                                             weight_thresh=1.5,\n",
      "   144                                             echo_frac_thresh=0.6,\n",
      "   145                                             refl_thresh=0,\n",
      "   146                                             obs_thresh=2,\n",
      "   147                                             variables=None,\n",
      "   148                                         ):\n",
      "   149                                             \"\"\"\n",
      "   150                                             Filter a GridRad dataset. Based on code from the GridRad website\n",
      "   151                                             https://gridrad.org/software.html and edits by Stacey Hitchcock.\n",
      "   152                                         \n",
      "   153                                             Parameters\n",
      "   154                                             ----------\n",
      "   155                                             ds : xarray.Dataset\n",
      "   156                                                 The GridRad dataset.\n",
      "   157                                             weight_thresh : float, optional\n",
      "   158                                                 The bin weight threshold. Default is 1.5.\n",
      "   159                                             echo_frac_thresh : float, optional\n",
      "   160                                                 The echo fraction threshold. Default is 0.6.\n",
      "   161                                             refl_thresh : float, optional\n",
      "   162                                                 The reflectivity threshold. Default is 0.\n",
      "   163                                             obs_thresh : int, optional\n",
      "   164                                                 The number of observations. Default is 2.\n",
      "   165                                         \n",
      "   166                                             Returns\n",
      "   167                                             -------\n",
      "   168                                             ds : xarray.Dataset\n",
      "   169                                                 The filtered GridRad dataset\n",
      "   170                                             \"\"\"\n",
      "   171                                         \n",
      "   172   4388.9 MiB      0.0 MiB           1       logger.debug(\"Filtering GridRad data\")\n",
      "   173                                         \n",
      "   174   4388.9 MiB      0.0 MiB           1       if variables is None:\n",
      "   175   4388.9 MiB      0.0 MiB          10           variables = [v for v in gridrad_variables if v in ds.variables]\n",
      "   176                                         \n",
      "   177                                             # echo_fraction = xr.zeros_like(ds[\"Nradecho\"]).astype(np.float32)\n",
      "   178                                             # Calcualate echo fraction efficiently using lazy loading and where\n",
      "   179   4388.9 MiB      0.0 MiB           1       kwargs = {\"keep_attrs\": True}\n",
      "   180   5184.1 MiB    -79.6 MiB           3       echo_fraction = xr.where(\n",
      "   181   5184.1 MiB    795.2 MiB           2           ds[\"Nradobs\"] > 0, ds[\"Nradecho\"] / ds[\"Nradobs\"], 0.0, **kwargs\n",
      "   182                                             )\n",
      "   183   4786.5 MiB   -397.6 MiB           1       echo_fraction = echo_fraction.astype(np.float32)\n",
      "   184                                         \n",
      "   185                                             # Get indices to filter\n",
      "   186   4866.0 MiB     79.5 MiB           1       weight_cond = xr.where(ds[\"wReflectivity\"] < weight_thresh, True, False, **kwargs)\n",
      "   187   4945.5 MiB     79.5 MiB           1       refl_cond = xr.where(ds[\"Reflectivity\"] <= refl_thresh, True, False, **kwargs)\n",
      "   188   5025.1 MiB     79.5 MiB           1       frac_cond = xr.where(echo_fraction < echo_frac_thresh, True, False, **kwargs)\n",
      "   189   5104.6 MiB     79.5 MiB           1       obs_cond = xr.where(ds[\"Nradobs\"] <= obs_thresh, True, False, **kwargs)\n",
      "   190                                             # Filter cells below weight and reflectivity thresholds\n",
      "   191   5184.1 MiB     79.5 MiB           1       cond_refl = xr.where(weight_cond & refl_cond, True, False, **kwargs)\n",
      "   192                                             # Filter cells containing at < obs_thresh observations. If at least obs_thresh\n",
      "   193                                             # observations, filter cells with echoes in less than echo_fraction_thresh of the\n",
      "   194                                             # total observations\n",
      "   195   5263.6 MiB     79.5 MiB           1       cond_frac = xr.where(obs_cond | frac_cond, True, False, **kwargs)\n",
      "   196                                             # Retain values not filtered\n",
      "   197   5343.2 MiB     79.5 MiB           1       preserved = xr.where(~cond_refl & ~cond_frac, True, False, **kwargs)\n",
      "   198   5343.3 MiB      0.0 MiB           2       for var in variables:\n",
      "   199   5343.3 MiB      0.1 MiB           1           ds[var] = ds[var].where(preserved)\n",
      "   200                                         \n",
      "   201   5343.3 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   204   4548.0 MiB   4548.0 MiB           1   @profile\n",
      "   205                                         def remove_speckles(ds, window_size=5, coverage_thresh=0.32, variables=None):\n",
      "   206                                             \"\"\"\n",
      "   207                                             Remove speckles in GridRad data. Based on code from the GridRad website\n",
      "   208                                             https://gridrad.org/software.html and edits by Stacey Hitchcock. Modified from the\n",
      "   209                                             original to use xr.rolling instead of np.roll to correctly handle edges and corners.\n",
      "   210                                             \"\"\"\n",
      "   211                                         \n",
      "   212   4548.0 MiB      0.0 MiB           1       logger.debug(\"Removing speckles from the GridRad data\")\n",
      "   213                                         \n",
      "   214   4548.0 MiB      0.0 MiB           1       if variables is None:\n",
      "   215                                                 variables = [v for v in gridrad_variables if v in ds.variables]\n",
      "   216                                         \n",
      "   217                                             # refl_exists = np.isfinite(ds[\"Reflectivity\"]).astype(float)\n",
      "   218   4627.4 MiB     79.4 MiB           1       refl_exists = xr.where(ds[\"Reflectivity\"] != np.nan, True, False)\n",
      "   219   4627.4 MiB      0.0 MiB           1       min_size = window_size**3 * coverage_thresh\n",
      "   220   4707.0 MiB     79.5 MiB           1       speckle_mask = remove_small_objects(refl_exists.values > 0, min_size=min_size)\n",
      "   221   4707.1 MiB      0.0 MiB           2       for var in variables:\n",
      "   222   4707.1 MiB      0.1 MiB           1           ds[var] = ds[var].where(speckle_mask)\n",
      "   223                                         \n",
      "   224   4707.1 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   227   4547.9 MiB   4547.9 MiB           1   @profile\n",
      "   228                                         def remove_low_level_clutter(ds, variables=None):\n",
      "   229                                             \"\"\"\n",
      "   230                                             Remove low level clutter from GridRad data. Based on code from the GridRad website\n",
      "   231                                             https://gridrad.org/software.html and edits by Stacey Hitchcock.\n",
      "   232                                             \"\"\"\n",
      "   233                                         \n",
      "   234   4547.9 MiB      0.0 MiB           1       logger.debug(\"Removing low level clutter from the GridRad data\")\n",
      "   235                                         \n",
      "   236                                             # Determine max heights of non-nan reflectivity values. If entire column is nan,\n",
      "   237                                             # set max altitude to zero.\n",
      "   238   4547.9 MiB      0.0 MiB           1       refl_max = ds.Reflectivity.max(dim=\"Altitude\", skipna=True)\n",
      "   239   5184.1 MiB    636.2 MiB           1       refl_0_alts = ds.Altitude.where(ds.Reflectivity > 0.0, 0.0)\n",
      "   240   5184.1 MiB      0.0 MiB           1       refl_0_max_alt = refl_0_alts.max(dim=\"Altitude\")\n",
      "   241   5184.1 MiB      0.0 MiB           1       refl_0_min_alt = refl_0_alts.min(dim=\"Altitude\")\n",
      "   242   5184.1 MiB      0.0 MiB           1       refl_5_max_alt = ds.Altitude.where(ds.Reflectivity > 5.0, 0.0).max(dim=\"Altitude\")\n",
      "   243   5184.1 MiB      0.0 MiB           1       refl_15_max_alt = ds.Altitude.where(ds.Reflectivity > 15.0, 0.0).max(dim=\"Altitude\")\n",
      "   244                                         \n",
      "   245                                             # Check for very weak echos below 4 km\n",
      "   246   5184.1 MiB      0.0 MiB           1       cond_1 = (refl_max < 20.0) & (refl_0_max_alt <= 4.0) & (refl_0_min_alt <= 3.0)\n",
      "   247                                             # Check for very weak echos below 5 km\n",
      "   248   5184.1 MiB      0.0 MiB           1       cond_2 = (refl_max < 10.0) & (refl_0_max_alt <= 5.0) & (refl_0_min_alt <= 3.0)\n",
      "   249                                             # Check for weak echos below 5 km. Note the > 0.0 ensures values actually exist\n",
      "   250   5184.1 MiB      0.0 MiB           1       cond_3 = (refl_5_max_alt <= 5.0) & (refl_5_max_alt > 0.0) & (refl_15_max_alt <= 3.0)\n",
      "   251                                             # Check for weak echos below 2 km\n",
      "   252   5184.1 MiB      0.0 MiB           1       cond_4 = (refl_15_max_alt < 2.0) & (refl_15_max_alt > 0.0)\n",
      "   253   5184.1 MiB      0.0 MiB           1       cond = np.logical_not(cond_1 | cond_2 | cond_3 | cond_4)\n",
      "   254   5184.2 MiB      0.0 MiB           2       for var in variables:\n",
      "   255   5184.2 MiB      0.1 MiB           1           ds[var] = ds[var].where(cond)\n",
      "   256   5184.2 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   204   4547.9 MiB   4547.9 MiB           1   @profile\n",
      "   205                                         def remove_speckles(ds, window_size=5, coverage_thresh=0.32, variables=None):\n",
      "   206                                             \"\"\"\n",
      "   207                                             Remove speckles in GridRad data. Based on code from the GridRad website\n",
      "   208                                             https://gridrad.org/software.html and edits by Stacey Hitchcock. Modified from the\n",
      "   209                                             original to use xr.rolling instead of np.roll to correctly handle edges and corners.\n",
      "   210                                             \"\"\"\n",
      "   211                                         \n",
      "   212   4547.9 MiB      0.0 MiB           1       logger.debug(\"Removing speckles from the GridRad data\")\n",
      "   213                                         \n",
      "   214   4547.9 MiB      0.0 MiB           1       if variables is None:\n",
      "   215                                                 variables = [v for v in gridrad_variables if v in ds.variables]\n",
      "   216                                         \n",
      "   217                                             # refl_exists = np.isfinite(ds[\"Reflectivity\"]).astype(float)\n",
      "   218   4627.4 MiB     79.5 MiB           1       refl_exists = xr.where(ds[\"Reflectivity\"] != np.nan, True, False)\n",
      "   219   4627.4 MiB      0.0 MiB           1       min_size = window_size**3 * coverage_thresh\n",
      "   220   4706.9 MiB     79.5 MiB           1       speckle_mask = remove_small_objects(refl_exists.values > 0, min_size=min_size)\n",
      "   221   4707.0 MiB      0.0 MiB           2       for var in variables:\n",
      "   222   4707.0 MiB      0.1 MiB           1           ds[var] = ds[var].where(speckle_mask)\n",
      "   223                                         \n",
      "   224   4707.0 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   281   4468.4 MiB   4468.4 MiB           1   @profile\n",
      "   282                                         def remove_clutter(ds, variables=None, low_level=True, below_anvil=False):\n",
      "   283                                             \"\"\"\n",
      "   284                                             Remove clutter from GridRad data. Based on code from the GridRad website\n",
      "   285                                             https://gridrad.org/software.html and edits by Stacey Hitchcock.\n",
      "   286                                         \n",
      "   287                                             Parameters\n",
      "   288                                             ----------\n",
      "   289                                             ds : xarray.Dataset\n",
      "   290                                                 The GridRad dataset.\n",
      "   291                                             variables : list, optional\n",
      "   292                                                 The variables to remove clutter from. Default is [\"Reflectivity\"].\n",
      "   293                                         \n",
      "   294                                             Returns\n",
      "   295                                             -------\n",
      "   296                                             ds : xarray.Dataset\n",
      "   297                                                 The GridRad dataset with clutter removed.\n",
      "   298                                             \"\"\"\n",
      "   299                                         \n",
      "   300   4468.4 MiB      0.0 MiB           1       logger.debug(\"Removing clutter from the GridRad data\")\n",
      "   301                                         \n",
      "   302   4468.4 MiB      0.0 MiB           1       if variables is None:\n",
      "   303   4468.4 MiB      0.0 MiB          10           variables = [v for v in gridrad_variables if v in ds.variables]\n",
      "   304                                         \n",
      "   305                                             # Remove low reflectivity low level clutter\n",
      "   306   4547.9 MiB     79.5 MiB           1       cond = (ds.Reflectivity >= 10.0) | (ds.Altitude > 4.0)\n",
      "   307   4548.0 MiB      0.0 MiB           2       for var in variables:\n",
      "   308   4548.0 MiB      0.1 MiB           1           ds[var] = ds[var].where(cond)\n",
      "   309                                         \n",
      "   310                                             # Attempt correlation based clutter removal if relevant variables exist\n",
      "   311   4548.0 MiB      0.0 MiB           1       correlation_var_list = [\"DifferentialReflectivity\", \"CorrelationCoefficient\"]\n",
      "   312   4548.0 MiB      0.0 MiB           4       if all(corr_var in ds.variables for corr_var in correlation_var_list):\n",
      "   313                                         \n",
      "   314                                                 # Require either high correlation or reflectivity\n",
      "   315                                                 cond1 = ds[\"Reflectivity\"] >= 40.0 | ds[\"r_HV\"] >= 0.9\n",
      "   316                                                 # Require moderate reflectivity or high correlation or low altitude\n",
      "   317                                                 cond2 = ds[\"Reflectivity\"] >= 25.0 | ds[\"CorrelationCoefficient\"] >= 0.95\n",
      "   318                                                 cond2 = cond2 | ds[\"Altitude\"] < 10.0\n",
      "   319                                                 # Require both conditions above be met\n",
      "   320                                                 for var in variables:\n",
      "   321                                                     ds[var] = ds[var].where(cond1 & cond2)\n",
      "   322                                         \n",
      "   323                                             # First pass at speckle removal\n",
      "   324   4547.9 MiB     -0.1 MiB           1       ds = remove_speckles(ds, variables=variables)\n",
      "   325                                         \n",
      "   326   4547.9 MiB      0.0 MiB           1       if low_level:\n",
      "   327                                                 # Remove low level clutter. Note this can remove some low level cloud/drizzle\n",
      "   328   4547.9 MiB      0.0 MiB           1           ds = remove_low_level_clutter(ds, variables=variables)\n",
      "   329                                         \n",
      "   330   4547.9 MiB      0.0 MiB           1       if below_anvil:\n",
      "   331                                                 # Remove clutter below anvils\n",
      "   332                                                 ds = remove_clutter_below_anvils(ds, variables=variables)\n",
      "   333                                         \n",
      "   334                                             # Second pass at speckle removal\n",
      "   335   4547.8 MiB     -0.1 MiB           1       ds = remove_speckles(ds, variables=variables)\n",
      "   336                                         \n",
      "   337   4547.8 MiB      0.0 MiB           1       return ds\n",
      "\n",
      "\n",
      "Filename: /home/ewan/Documents/THOR/thor/data/gridrad.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurences   Line Contents\n",
      "============================================================\n",
      "   350   3752.6 MiB   3752.6 MiB           1   @profile\n",
      "   351                                         def convert_gridrad(time, filepath, track_options, dataset_options, grid_options):\n",
      "   352                                             \"\"\"Convert gridrad data to the standard format.\"\"\"\n",
      "   353                                         \n",
      "   354   3752.6 MiB      0.0 MiB           1       logger.debug(f\"Converting GridRad dataset at time {time}.\")\n",
      "   355                                         \n",
      "   356                                             # Open the dataset and perform preliminary filtering and decluttering\n",
      "   357   3752.6 MiB      0.0 MiB           1       lock = multiprocessing.Lock()\n",
      "   358   4388.9 MiB      0.0 MiB           2       with lock:\n",
      "   359   4388.9 MiB    636.3 MiB           1           ds = open_gridrad(filepath, dataset_options)\n",
      "   360   4468.4 MiB     79.5 MiB           1       ds = filter(ds, refl_thresh=-10)\n",
      "   361   4468.3 MiB     -0.1 MiB           1       ds = remove_clutter(ds)\n",
      "   362                                         \n",
      "   363                                             # Ensure the intended time is in the dataset\n",
      "   364   4468.3 MiB      0.0 MiB           1       if time not in ds.time.values:\n",
      "   365                                                 raise ValueError(f\"{time} not in {filepath}\")\n",
      "   366                                         \n",
      "   367                                             # Restructure the dataset\n",
      "   368   4468.3 MiB      0.0 MiB           1       names_dict = {\"Latitude\": \"latitude\", \"Longitude\": \"longitude\"}\n",
      "   369   4468.3 MiB      0.0 MiB           1       names_dict.update({\"Altitude\": \"altitude\", \"Reflectivity\": \"reflectivity\"})\n",
      "   370   4468.3 MiB      0.0 MiB           1       names_dict.update({\"Nradobs\": \"number_of_observations\"})\n",
      "   371   4468.3 MiB      0.0 MiB           1       names_dict.update({\"Nradecho\": \"number_of_echoes\"})\n",
      "   372                                         \n",
      "   373   4468.3 MiB      0.0 MiB           1       ds = ds.rename(names_dict)\n",
      "   374                                         \n",
      "   375   4468.3 MiB      0.0 MiB           4       for dim in [\"latitude\", \"longitude\", \"altitude\"]:\n",
      "   376   4468.3 MiB      0.0 MiB           3           ds[dim].attrs[\"standard_name\"] = dim\n",
      "   377   4468.3 MiB      0.0 MiB           3           ds[dim].attrs[\"long_name\"] = dim\n",
      "   378   4468.3 MiB      0.0 MiB           1       ds[\"altitude\"] = ds[\"altitude\"] * 1000  # Convert to meters\n",
      "   379   4468.3 MiB      0.0 MiB           1       kept_fields = dataset_options[\"fields\"] + [\"number_of_observations\"]\n",
      "   380   4468.3 MiB      0.0 MiB           1       kept_fields += [\"number_of_echoes\"]\n",
      "   381   4468.3 MiB      0.0 MiB           7       dropped_fields = [f for f in ds.data_vars if f not in kept_fields]\n",
      "   382   4150.3 MiB   -318.0 MiB           1       ds = ds.drop_vars(dropped_fields)\n",
      "   383                                         \n",
      "   384   4150.3 MiB      0.0 MiB           2       for field in dataset_options[\"fields\"]:\n",
      "   385   4150.3 MiB      0.0 MiB           1           ds[field] = ds[field].expand_dims(\"time\")\n",
      "   386   4150.3 MiB      0.0 MiB           1           ds[field].attrs[\"long_name\"] = field\n",
      "   387                                         \n",
      "   388   4150.3 MiB      0.0 MiB           1       spacing = [ds.latitude.delta, ds.longitude.delta]\n",
      "   389   4150.3 MiB      0.0 MiB           1       if grid_options[\"name\"] == \"geographic\":\n",
      "   390   4150.3 MiB      0.0 MiB           1           grid_options[\"latitude\"] = ds.latitude.values\n",
      "   391   4150.3 MiB      0.0 MiB           1           grid_options[\"longitude\"] = ds.longitude.values\n",
      "   392   4150.3 MiB      0.0 MiB           1           grid_options[\"altitude\"] = ds.altitude.values\n",
      "   393   4150.3 MiB      0.0 MiB           1           grid_options[\"geographic_spacing\"] = spacing\n",
      "   394   4150.3 MiB      0.0 MiB           1           grid_options[\"shape\"] = [len(ds.latitude), len(ds.longitude)]\n",
      "   395                                         \n",
      "   396   4150.3 MiB      0.0 MiB           1       ds[\"longitude\"] = ds[\"longitude\"] % 360\n",
      "   397                                         \n",
      "   398                                             # Get the domain mask associated with the given object\n",
      "   399                                             # Note the relevant domain mask is a function of how the object is detected, e.g.\n",
      "   400                                             # which levels!\n",
      "   401   4150.3 MiB      0.0 MiB           1       domain_mask = get_domain_mask(ds, track_options, dataset_options)\n",
      "   402   4150.3 MiB      0.0 MiB           1       boundary_coords, boundary_mask = utils.get_mask_boundary(domain_mask, grid_options)\n",
      "   403   4150.3 MiB      0.0 MiB           1       ds[\"domain_mask\"] = domain_mask\n",
      "   404   4150.3 MiB      0.0 MiB           1       ds[\"boundary_mask\"] = boundary_mask\n",
      "   405                                         \n",
      "   406                                             # Don't mask the gridcell areas\n",
      "   407   4150.3 MiB      0.0 MiB           1       cell_areas = grid.get_cell_areas(grid_options)\n",
      "   408   4150.3 MiB      0.0 MiB           1       ds[\"gridcell_area\"] = ([\"latitude\", \"longitude\"], cell_areas)\n",
      "   409   4150.3 MiB      0.0 MiB           1       area_attrs = {\"units\": \"km^2\", \"standard_name\": \"area\", \"valid_min\": 0}\n",
      "   410   4150.3 MiB      0.0 MiB           1       ds[\"gridcell_area\"].attrs.update(area_attrs)\n",
      "   411                                         \n",
      "   412                                             # Apply the domain mask to the current grid\n",
      "   413   4229.7 MiB     79.4 MiB           1       ds = utils.apply_mask(ds, grid_options)\n",
      "   414   4070.7 MiB   -159.1 MiB           1       ds = ds.drop_vars([\"number_of_observations\", \"number_of_echoes\"])\n",
      "   415   4070.7 MiB      0.0 MiB           1       return ds, boundary_coords\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 17:36:38,359 - thor.write.filepath - INFO - Writing gridrad filepaths from 2010-01-21T12 to 2010-01-21T13, inclusive and non-inclusive, respectively.\n",
      "2024-10-21 17:36:38,372 - thor.track - INFO - Processing hierarchy level 0.\n",
      "2024-10-21 17:36:38,375 - thor.track - INFO - Tracking convective.\n",
      "2024-10-21 17:36:38,379 - thor.write.attribute - INFO - Writing convective attributes from 2010-01-21T12:00:00 to 2010-01-21T13:00:00, inclusive and non-inclusive, respectively.\n",
      "2024-10-21 17:36:58,037 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:36:58,038 - thor.track - INFO - Tracking middle.\n",
      "2024-10-21 17:36:58,041 - thor.write.attribute - INFO - Writing middle attributes from 2010-01-21T12:00:00 to 2010-01-21T13:00:00, inclusive and non-inclusive, respectively.\n",
      "2024-10-21 17:37:03,745 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:37:03,745 - thor.track - INFO - Tracking anvil.\n",
      "2024-10-21 17:37:03,747 - thor.write.attribute - INFO - Writing anvil attributes from 2010-01-21T12:00:00 to 2010-01-21T13:00:00, inclusive and non-inclusive, respectively.\n",
      "2024-10-21 17:37:05,421 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:37:05,422 - thor.track - INFO - Processing hierarchy level 1.\n",
      "2024-10-21 17:37:05,424 - thor.track - INFO - Tracking mcs.\n",
      "2024-10-21 17:37:05,439 - thor.write.mask - INFO - Writing mcs masks to /home/ewan/THOR_output/runs/gridrad_demo_20100121/masks/mcs.zarr.\n",
      "2024-10-21 17:37:05,510 - thor.write.attribute - INFO - Writing mcs attributes from 2010-01-21T12:00:00 to 2010-01-21T13:00:00, inclusive and non-inclusive, respectively.\n",
      "2024-10-21 17:37:17,943 - thor.match.match - INFO - Matching mcs objects.\n",
      "2024-10-21 17:37:18,399 - thor.match.match - INFO - Updating object record.\n",
      "2024-10-21 17:37:18,533 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:37:19,401 - thor.write.attribute - INFO - Writing convective attributes from 2010-01-21T13:00:00 to 2010-01-21T14:00:00, inclusive and non-inclusive, respectively.\n",
      "2024-10-21 17:37:19,402 - thor.write.attribute - INFO - Writing middle attributes from 2010-01-21T13:00:00 to 2010-01-21T14:00:00, inclusive and non-inclusive, respectively.\n",
      "2024-10-21 17:37:19,404 - thor.write.attribute - INFO - Writing anvil attributes from 2010-01-21T13:00:00 to 2010-01-21T14:00:00, inclusive and non-inclusive, respectively.\n",
      "2024-10-21 17:37:19,407 - thor.write.attribute - INFO - Writing mcs attributes from 2010-01-21T13:00:00 to 2010-01-21T14:00:00, inclusive and non-inclusive, respectively.\n",
      "2024-10-21 17:37:19,485 - thor.write.filepath - INFO - Writing gridrad filepaths from 2010-01-21T13 to 2010-01-21T14, inclusive and non-inclusive, respectively.\n",
      "2024-10-21 17:37:19,493 - thor.write.attribute - INFO - Aggregating attribute files.\n",
      "2024-10-21 17:37:19,677 - thor.write.filepath - INFO - Aggregating filepath records.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 5885.63 MiB, increment: 4060.18 MiB\n"
     ]
    }
   ],
   "source": [
    "times = data.utils.generate_times(data_options[\"gridrad\"])\n",
    "args = [times, data_options.copy(), grid_options.copy()]\n",
    "args += [track_options.model_copy(), visualize_options]\n",
    "%memit track.simultaneous_track(*args, output_directory=output_parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## You are using the Python ARM Radar Toolkit (Py-ART), an open source\n",
      "## library for working with weather radar data. Py-ART is partly\n",
      "## supported by the U.S. Department of Energy as part of the Atmospheric\n",
      "## Radiation Measurement (ARM) Climate Research Facility, an Office of\n",
      "## Science user facility.\n",
      "##\n",
      "## If you use this software to prepare a publication, please cite:\n",
      "##\n",
      "##     JJ Helmus and SM Collis, JORS 2016, doi: 10.5334/jors.119\n",
      "\n",
      "\n",
      "## You are using the Python ARM Radar Toolkit (Py-ART), an open source\n",
      "## library for working with weather radar data. Py-ART is partly\n",
      "## supported by the U.S. Department of Energy as part of the Atmospheric\n",
      "## Radiation Measurement (ARM) Climate Research Facility, an Office of\n",
      "## Science user facility.\n",
      "##\n",
      "## If you use this software to prepare a publication, please cite:\n",
      "##\n",
      "##     JJ Helmus and SM Collis, JORS 2016, doi: 10.5334/jors.119\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 17:49:44,027 - thor.track - INFO - Beginning thor run. Saving output to /home/ewan/THOR_output/runs/gridrad_demo_20100121/interval_0.\n",
      "2024-10-21 17:49:44,028 - thor.track - INFO - Beginning simultaneous tracking.\n",
      "2024-10-21 17:49:44,068 - thor.track - INFO - Beginning thor run. Saving output to /home/ewan/THOR_output/runs/gridrad_demo_20100121/interval_1.\n",
      "2024-10-21 17:49:44,069 - thor.track - INFO - Beginning simultaneous tracking.\n",
      "2024-10-21 17:49:44,118 - thor.track - INFO - Processing 2010-01-21T12:00:00.\n",
      "2024-10-21 17:49:44,118 - thor.data.gridrad - INFO - Updating gridrad dataset for 2010-01-21T12:00:00.\n",
      "2024-10-21 17:49:44,119 - thor.data.gridrad - INFO - Converting gridrad data from nexrad_3d_v4_2_20100121T120000Z.nc\n",
      "2024-10-21 17:49:44,169 - thor.track - INFO - Processing 2010-01-21T13:00:00.\n",
      "2024-10-21 17:49:44,170 - thor.data.gridrad - INFO - Updating gridrad dataset for 2010-01-21T13:00:00.\n",
      "2024-10-21 17:49:44,170 - thor.data.gridrad - INFO - Converting gridrad data from nexrad_3d_v4_2_20100121T130000Z.nc\n",
      "2024-10-21 17:49:59,560 - thor.track - INFO - Processing hierarchy level 0.\n",
      "2024-10-21 17:49:59,560 - thor.track - INFO - Tracking convective.\n",
      "2024-10-21 17:49:59,618 - thor.track - INFO - Processing hierarchy level 0.\n",
      "2024-10-21 17:49:59,618 - thor.track - INFO - Tracking convective.\n",
      "2024-10-21 17:50:31,482 - thor.track - INFO - Tracking middle.\n",
      "2024-10-21 17:50:33,889 - thor.track - INFO - Tracking middle.\n",
      "2024-10-21 17:50:41,253 - thor.track - INFO - Tracking anvil.\n",
      "2024-10-21 17:50:43,097 - thor.track - INFO - Tracking anvil.\n",
      "2024-10-21 17:50:44,279 - thor.track - INFO - Processing hierarchy level 1.\n",
      "2024-10-21 17:50:44,279 - thor.track - INFO - Tracking mcs.\n",
      "2024-10-21 17:50:47,514 - thor.track - INFO - Processing hierarchy level 1.\n",
      "2024-10-21 17:50:47,515 - thor.track - INFO - Tracking mcs.\n",
      "2024-10-21 17:51:06,892 - thor.match.match - INFO - Matching mcs objects.\n",
      "2024-10-21 17:51:06,927 - thor.match.match - INFO - No previous mask, or no objects in previous mask.\n",
      "2024-10-21 17:51:07,132 - thor.track - INFO - Processing 2010-01-21T13:10:00.\n",
      "2024-10-21 17:51:07,134 - thor.data.gridrad - INFO - Updating gridrad dataset for 2010-01-21T13:10:00.\n",
      "2024-10-21 17:51:07,134 - thor.data.gridrad - INFO - Converting gridrad data from nexrad_3d_v4_2_20100121T131000Z.nc\n",
      "2024-10-21 17:51:09,186 - thor.match.match - INFO - Matching mcs objects.\n",
      "2024-10-21 17:51:09,209 - thor.match.match - INFO - No previous mask, or no objects in previous mask.\n",
      "2024-10-21 17:51:09,376 - thor.track - INFO - Processing 2010-01-21T12:10:00.\n",
      "2024-10-21 17:51:09,377 - thor.data.gridrad - INFO - Updating gridrad dataset for 2010-01-21T12:10:00.\n",
      "2024-10-21 17:51:09,378 - thor.data.gridrad - INFO - Converting gridrad data from nexrad_3d_v4_2_20100121T121000Z.nc\n",
      "2024-10-21 17:51:22,402 - thor.data.era5 - INFO - Updating era5_pl dataset for 2010-01-21T13:00:00.\n",
      "2024-10-21 17:51:24,065 - thor.data.era5 - INFO - Updating era5_pl dataset for 2010-01-21T12:00:00.\n",
      "2024-10-21 17:51:24,414 - thor.data.era5 - INFO - Updating era5_sl dataset for 2010-01-21T13:00:00.\n",
      "2024-10-21 17:51:24,553 - thor.track - INFO - Processing hierarchy level 0.\n",
      "2024-10-21 17:51:24,553 - thor.track - INFO - Tracking convective.\n",
      "2024-10-21 17:51:25,866 - thor.data.era5 - INFO - Updating era5_sl dataset for 2010-01-21T12:00:00.\n",
      "2024-10-21 17:51:26,001 - thor.track - INFO - Processing hierarchy level 0.\n",
      "2024-10-21 17:51:26,001 - thor.track - INFO - Tracking convective.\n",
      "2024-10-21 17:51:45,185 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:51:45,185 - thor.track - INFO - Tracking middle.\n",
      "2024-10-21 17:51:50,863 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:51:50,864 - thor.track - INFO - Tracking middle.\n",
      "2024-10-21 17:51:54,413 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:51:54,413 - thor.track - INFO - Tracking anvil.\n",
      "2024-10-21 17:51:57,751 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:51:57,752 - thor.track - INFO - Processing hierarchy level 1.\n",
      "2024-10-21 17:51:57,752 - thor.track - INFO - Tracking mcs.\n",
      "2024-10-21 17:51:57,783 - thor.write.mask - INFO - Writing mcs masks to /home/ewan/THOR_output/runs/gridrad_demo_20100121/interval_1/masks/mcs.zarr.\n",
      "2024-10-21 17:52:02,427 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:52:02,428 - thor.track - INFO - Tracking anvil.\n",
      "2024-10-21 17:52:05,475 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:52:05,475 - thor.track - INFO - Processing hierarchy level 1.\n",
      "2024-10-21 17:52:05,475 - thor.track - INFO - Tracking mcs.\n",
      "2024-10-21 17:52:05,499 - thor.write.mask - INFO - Writing mcs masks to /home/ewan/THOR_output/runs/gridrad_demo_20100121/interval_0/masks/mcs.zarr.\n",
      "2024-10-21 17:52:13,604 - thor.match.match - INFO - Matching mcs objects.\n",
      "2024-10-21 17:52:14,688 - thor.match.match - INFO - New matchable objects. Initializing object record.\n",
      "2024-10-21 17:52:14,972 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:52:16,805 - thor.track - INFO - Processing 2010-01-21T13:20:00.\n",
      "2024-10-21 17:52:16,807 - thor.data.gridrad - INFO - Updating gridrad dataset for 2010-01-21T13:20:00.\n",
      "2024-10-21 17:52:16,807 - thor.data.gridrad - INFO - Converting gridrad data from nexrad_3d_v4_2_20100121T132000Z.nc\n",
      "2024-10-21 17:52:23,015 - thor.match.match - INFO - Matching mcs objects.\n",
      "2024-10-21 17:52:23,456 - thor.match.match - INFO - New matchable objects. Initializing object record.\n",
      "2024-10-21 17:52:23,546 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:52:23,959 - thor.track - INFO - Processing 2010-01-21T12:20:00.\n",
      "2024-10-21 17:52:23,960 - thor.data.gridrad - INFO - Updating gridrad dataset for 2010-01-21T12:20:00.\n",
      "2024-10-21 17:52:23,960 - thor.data.gridrad - INFO - Converting gridrad data from nexrad_3d_v4_2_20100121T122000Z.nc\n",
      "2024-10-21 17:52:32,526 - thor.track - INFO - Processing hierarchy level 0.\n",
      "2024-10-21 17:52:32,528 - thor.track - INFO - Tracking convective.\n",
      "2024-10-21 17:52:39,310 - thor.track - INFO - Processing hierarchy level 0.\n",
      "2024-10-21 17:52:39,310 - thor.track - INFO - Tracking convective.\n",
      "2024-10-21 17:52:57,403 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:52:57,403 - thor.track - INFO - Tracking middle.\n",
      "2024-10-21 17:53:03,992 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:53:03,993 - thor.track - INFO - Tracking anvil.\n",
      "2024-10-21 17:53:04,564 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:53:04,564 - thor.track - INFO - Tracking middle.\n",
      "2024-10-21 17:53:06,729 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:53:06,729 - thor.track - INFO - Processing hierarchy level 1.\n",
      "2024-10-21 17:53:06,729 - thor.track - INFO - Tracking mcs.\n",
      "2024-10-21 17:53:06,758 - thor.write.mask - INFO - Writing mcs masks to /home/ewan/THOR_output/runs/gridrad_demo_20100121/interval_1/masks/mcs.zarr.\n",
      "2024-10-21 17:53:15,781 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:53:15,781 - thor.track - INFO - Tracking anvil.\n",
      "2024-10-21 17:53:20,235 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:53:20,235 - thor.track - INFO - Processing hierarchy level 1.\n",
      "2024-10-21 17:53:20,235 - thor.track - INFO - Tracking mcs.\n",
      "2024-10-21 17:53:20,264 - thor.write.mask - INFO - Writing mcs masks to /home/ewan/THOR_output/runs/gridrad_demo_20100121/interval_0/masks/mcs.zarr.\n",
      "2024-10-21 17:53:25,646 - thor.match.match - INFO - Matching mcs objects.\n",
      "2024-10-21 17:53:26,343 - thor.match.match - INFO - Updating object record.\n",
      "2024-10-21 17:53:26,549 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:53:28,046 - thor.track - INFO - Processing 2010-01-21T13:30:00.\n",
      "2024-10-21 17:53:28,047 - thor.data.gridrad - INFO - Updating gridrad dataset for 2010-01-21T13:30:00.\n",
      "2024-10-21 17:53:28,047 - thor.data.gridrad - INFO - Converting gridrad data from nexrad_3d_v4_2_20100121T133000Z.nc\n",
      "2024-10-21 17:53:36,966 - thor.match.match - INFO - Matching mcs objects.\n",
      "2024-10-21 17:53:37,680 - thor.match.match - INFO - Updating object record.\n",
      "2024-10-21 17:53:37,923 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:53:37,925 - thor.attribute.core - INFO - Object 0 has a nan u_displacement.\n",
      "2024-10-21 17:53:39,229 - thor.attribute.core - INFO - Object 0 has a nan u_displacement.\n",
      "2024-10-21 17:53:39,265 - thor.track - INFO - Processing 2010-01-21T12:30:00.\n",
      "2024-10-21 17:53:39,266 - thor.data.gridrad - INFO - Updating gridrad dataset for 2010-01-21T12:30:00.\n",
      "2024-10-21 17:53:39,266 - thor.data.gridrad - INFO - Converting gridrad data from nexrad_3d_v4_2_20100121T123000Z.nc\n",
      "2024-10-21 17:53:44,248 - thor.track - INFO - Processing hierarchy level 0.\n",
      "2024-10-21 17:53:44,248 - thor.track - INFO - Tracking convective.\n",
      "2024-10-21 17:53:51,713 - thor.track - INFO - Processing hierarchy level 0.\n",
      "2024-10-21 17:53:51,713 - thor.track - INFO - Tracking convective.\n",
      "2024-10-21 17:54:06,212 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:54:06,212 - thor.track - INFO - Tracking middle.\n",
      "2024-10-21 17:54:11,999 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:54:12,000 - thor.track - INFO - Tracking anvil.\n",
      "2024-10-21 17:54:13,544 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:54:13,545 - thor.track - INFO - Processing hierarchy level 1.\n",
      "2024-10-21 17:54:13,545 - thor.track - INFO - Tracking mcs.\n",
      "2024-10-21 17:54:13,562 - thor.write.mask - INFO - Writing mcs masks to /home/ewan/THOR_output/runs/gridrad_demo_20100121/interval_1/masks/mcs.zarr.\n",
      "2024-10-21 17:54:17,031 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:54:17,031 - thor.track - INFO - Tracking middle.\n",
      "2024-10-21 17:54:28,830 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:54:28,831 - thor.track - INFO - Tracking anvil.\n",
      "2024-10-21 17:54:31,766 - thor.match.match - INFO - Matching mcs objects.\n",
      "2024-10-21 17:54:32,300 - thor.match.match - INFO - Updating object record.\n",
      "2024-10-21 17:54:32,346 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:54:32,346 - thor.track - INFO - Processing hierarchy level 1.\n",
      "2024-10-21 17:54:32,347 - thor.track - INFO - Tracking mcs.\n",
      "2024-10-21 17:54:32,365 - thor.write.mask - INFO - Writing mcs masks to /home/ewan/THOR_output/runs/gridrad_demo_20100121/interval_0/masks/mcs.zarr.\n",
      "2024-10-21 17:54:32,463 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:54:33,928 - thor.track - INFO - Processing 2010-01-21T13:40:00.\n",
      "2024-10-21 17:54:33,929 - thor.data.gridrad - INFO - Updating gridrad dataset for 2010-01-21T13:40:00.\n",
      "2024-10-21 17:54:33,930 - thor.data.gridrad - INFO - Converting gridrad data from nexrad_3d_v4_2_20100121T134000Z.nc\n",
      "2024-10-21 17:54:49,091 - thor.match.match - INFO - Matching mcs objects.\n",
      "2024-10-21 17:54:49,613 - thor.match.match - INFO - Updating object record.\n",
      "2024-10-21 17:54:49,741 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:54:50,853 - thor.track - INFO - Processing 2010-01-21T12:40:00.\n",
      "2024-10-21 17:54:50,854 - thor.data.gridrad - INFO - Updating gridrad dataset for 2010-01-21T12:40:00.\n",
      "2024-10-21 17:54:50,855 - thor.data.gridrad - INFO - Converting gridrad data from nexrad_3d_v4_2_20100121T124000Z.nc\n",
      "2024-10-21 17:54:51,829 - thor.track - INFO - Processing hierarchy level 0.\n",
      "2024-10-21 17:54:51,829 - thor.track - INFO - Tracking convective.\n",
      "2024-10-21 17:55:03,072 - thor.track - INFO - Processing hierarchy level 0.\n",
      "2024-10-21 17:55:03,073 - thor.track - INFO - Tracking convective.\n",
      "2024-10-21 17:55:13,565 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:55:13,566 - thor.track - INFO - Tracking middle.\n",
      "2024-10-21 17:55:19,885 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:55:19,885 - thor.track - INFO - Tracking anvil.\n",
      "2024-10-21 17:55:21,316 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:55:21,316 - thor.track - INFO - Processing hierarchy level 1.\n",
      "2024-10-21 17:55:21,316 - thor.track - INFO - Tracking mcs.\n",
      "2024-10-21 17:55:21,335 - thor.write.mask - INFO - Writing mcs masks to /home/ewan/THOR_output/runs/gridrad_demo_20100121/interval_1/masks/mcs.zarr.\n",
      "2024-10-21 17:55:29,919 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:55:29,919 - thor.track - INFO - Tracking middle.\n",
      "2024-10-21 17:55:37,811 - thor.match.match - INFO - Matching mcs objects.\n",
      "2024-10-21 17:55:38,409 - thor.match.match - INFO - Updating object record.\n",
      "2024-10-21 17:55:38,580 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:55:38,581 - thor.attribute.core - INFO - Object 1 has a nan u_displacement.\n",
      "2024-10-21 17:55:40,296 - thor.attribute.core - INFO - Object 1 has a nan u_displacement.\n",
      "2024-10-21 17:55:40,332 - thor.track - INFO - Processing 2010-01-21T13:50:00.\n",
      "2024-10-21 17:55:40,332 - thor.data.gridrad - INFO - Updating gridrad dataset for 2010-01-21T13:50:00.\n",
      "2024-10-21 17:55:40,332 - thor.data.gridrad - INFO - Converting gridrad data from nexrad_3d_v4_2_20100121T135000Z.nc\n",
      "2024-10-21 17:55:41,328 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:55:41,329 - thor.track - INFO - Tracking anvil.\n",
      "2024-10-21 17:55:44,465 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:55:44,465 - thor.track - INFO - Processing hierarchy level 1.\n",
      "2024-10-21 17:55:44,466 - thor.track - INFO - Tracking mcs.\n",
      "2024-10-21 17:55:44,488 - thor.write.mask - INFO - Writing mcs masks to /home/ewan/THOR_output/runs/gridrad_demo_20100121/interval_0/masks/mcs.zarr.\n",
      "2024-10-21 17:55:58,387 - thor.track - INFO - Processing hierarchy level 0.\n",
      "2024-10-21 17:55:58,387 - thor.track - INFO - Tracking convective.\n",
      "2024-10-21 17:56:00,657 - thor.match.match - INFO - Matching mcs objects.\n",
      "2024-10-21 17:56:01,152 - thor.match.match - INFO - Updating object record.\n",
      "2024-10-21 17:56:01,266 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:56:02,152 - thor.track - INFO - Processing 2010-01-21T12:50:00.\n",
      "2024-10-21 17:56:02,153 - thor.data.gridrad - INFO - Updating gridrad dataset for 2010-01-21T12:50:00.\n",
      "2024-10-21 17:56:02,153 - thor.data.gridrad - INFO - Converting gridrad data from nexrad_3d_v4_2_20100121T125000Z.nc\n",
      "2024-10-21 17:56:14,134 - thor.track - INFO - Processing hierarchy level 0.\n",
      "2024-10-21 17:56:14,134 - thor.track - INFO - Tracking convective.\n",
      "2024-10-21 17:56:20,871 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:56:20,871 - thor.track - INFO - Tracking middle.\n",
      "2024-10-21 17:56:28,214 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:56:28,215 - thor.track - INFO - Tracking anvil.\n",
      "2024-10-21 17:56:29,547 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:56:29,548 - thor.track - INFO - Processing hierarchy level 1.\n",
      "2024-10-21 17:56:29,548 - thor.track - INFO - Tracking mcs.\n",
      "2024-10-21 17:56:29,562 - thor.write.mask - INFO - Writing mcs masks to /home/ewan/THOR_output/runs/gridrad_demo_20100121/interval_1/masks/mcs.zarr.\n",
      "2024-10-21 17:56:41,999 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:56:42,000 - thor.track - INFO - Tracking middle.\n",
      "2024-10-21 17:56:43,108 - thor.match.match - INFO - Matching mcs objects.\n",
      "2024-10-21 17:56:43,695 - thor.match.match - INFO - Updating object record.\n",
      "2024-10-21 17:56:43,883 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:56:45,274 - thor.track - INFO - Processing 2010-01-21T14:00:00.\n",
      "2024-10-21 17:56:45,276 - thor.data.gridrad - INFO - Updating gridrad dataset for 2010-01-21T14:00:00.\n",
      "2024-10-21 17:56:45,277 - thor.data.gridrad - INFO - Converting gridrad data from nexrad_3d_v4_2_20100121T140000Z.nc\n",
      "2024-10-21 17:56:50,741 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:56:50,741 - thor.track - INFO - Tracking anvil.\n",
      "2024-10-21 17:56:53,114 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:56:53,114 - thor.track - INFO - Processing hierarchy level 1.\n",
      "2024-10-21 17:56:53,114 - thor.track - INFO - Tracking mcs.\n",
      "2024-10-21 17:56:53,136 - thor.write.mask - INFO - Writing mcs masks to /home/ewan/THOR_output/runs/gridrad_demo_20100121/interval_0/masks/mcs.zarr.\n",
      "2024-10-21 17:57:02,962 - thor.write.filepath - INFO - Writing gridrad filepaths from 2010-01-21T13 to 2010-01-21T14, inclusive and non-inclusive, respectively.\n",
      "2024-10-21 17:57:02,969 - thor.track - INFO - Processing hierarchy level 0.\n",
      "2024-10-21 17:57:02,969 - thor.track - INFO - Tracking convective.\n",
      "2024-10-21 17:57:02,971 - thor.write.attribute - INFO - Writing convective attributes from 2010-01-21T13:00:00 to 2010-01-21T14:00:00, inclusive and non-inclusive, respectively.\n",
      "2024-10-21 17:57:08,167 - thor.match.match - INFO - Matching mcs objects.\n",
      "2024-10-21 17:57:08,682 - thor.match.match - INFO - Updating object record.\n",
      "2024-10-21 17:57:08,800 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:57:09,668 - thor.track - INFO - Processing 2010-01-21T13:00:00.\n",
      "2024-10-21 17:57:09,668 - thor.data.gridrad - INFO - Updating gridrad dataset for 2010-01-21T13:00:00.\n",
      "2024-10-21 17:57:09,668 - thor.data.gridrad - INFO - Converting gridrad data from nexrad_3d_v4_2_20100121T130000Z.nc\n",
      "2024-10-21 17:57:21,544 - thor.write.filepath - INFO - Writing gridrad filepaths from 2010-01-21T12 to 2010-01-21T13, inclusive and non-inclusive, respectively.\n",
      "2024-10-21 17:57:21,548 - thor.track - INFO - Processing hierarchy level 0.\n",
      "2024-10-21 17:57:21,548 - thor.track - INFO - Tracking convective.\n",
      "2024-10-21 17:57:21,549 - thor.write.attribute - INFO - Writing convective attributes from 2010-01-21T12:00:00 to 2010-01-21T13:00:00, inclusive and non-inclusive, respectively.\n",
      "2024-10-21 17:57:26,299 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:57:26,299 - thor.track - INFO - Tracking middle.\n",
      "2024-10-21 17:57:26,300 - thor.write.attribute - INFO - Writing middle attributes from 2010-01-21T13:00:00 to 2010-01-21T14:00:00, inclusive and non-inclusive, respectively.\n",
      "2024-10-21 17:57:33,076 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:57:33,076 - thor.track - INFO - Tracking anvil.\n",
      "2024-10-21 17:57:33,079 - thor.write.attribute - INFO - Writing anvil attributes from 2010-01-21T13:00:00 to 2010-01-21T14:00:00, inclusive and non-inclusive, respectively.\n",
      "2024-10-21 17:57:34,812 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:57:34,812 - thor.track - INFO - Processing hierarchy level 1.\n",
      "2024-10-21 17:57:34,812 - thor.track - INFO - Tracking mcs.\n",
      "2024-10-21 17:57:34,833 - thor.write.mask - INFO - Writing mcs masks to /home/ewan/THOR_output/runs/gridrad_demo_20100121/interval_1/masks/mcs.zarr.\n",
      "2024-10-21 17:57:34,885 - thor.write.attribute - INFO - Writing mcs attributes from 2010-01-21T13:00:00 to 2010-01-21T14:00:00, inclusive and non-inclusive, respectively.\n",
      "2024-10-21 17:57:48,580 - thor.match.match - INFO - Matching mcs objects.\n",
      "2024-10-21 17:57:48,964 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:57:48,965 - thor.track - INFO - Tracking middle.\n",
      "2024-10-21 17:57:48,966 - thor.write.attribute - INFO - Writing middle attributes from 2010-01-21T12:00:00 to 2010-01-21T13:00:00, inclusive and non-inclusive, respectively.\n",
      "2024-10-21 17:57:49,203 - thor.match.match - INFO - Updating object record.\n",
      "2024-10-21 17:57:49,380 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:57:49,381 - thor.attribute.core - INFO - Object 1 has a nan u_displacement.\n",
      "2024-10-21 17:57:51,008 - thor.attribute.core - INFO - Object 1 has a nan u_displacement.\n",
      "2024-10-21 17:57:51,012 - thor.write.attribute - INFO - Writing convective attributes from 2010-01-21T14:00:00 to 2010-01-21T15:00:00, inclusive and non-inclusive, respectively.\n",
      "2024-10-21 17:57:51,014 - thor.write.attribute - INFO - Writing middle attributes from 2010-01-21T14:00:00 to 2010-01-21T15:00:00, inclusive and non-inclusive, respectively.\n",
      "2024-10-21 17:57:51,015 - thor.write.attribute - INFO - Writing anvil attributes from 2010-01-21T14:00:00 to 2010-01-21T15:00:00, inclusive and non-inclusive, respectively.\n",
      "2024-10-21 17:57:51,017 - thor.write.attribute - INFO - Writing mcs attributes from 2010-01-21T14:00:00 to 2010-01-21T15:00:00, inclusive and non-inclusive, respectively.\n",
      "2024-10-21 17:57:51,111 - thor.write.filepath - INFO - Writing gridrad filepaths from 2010-01-21T14 to 2010-01-21T15, inclusive and non-inclusive, respectively.\n",
      "2024-10-21 17:57:51,116 - thor.write.attribute - INFO - Aggregating attribute files.\n",
      "2024-10-21 17:57:51,366 - thor.write.filepath - INFO - Aggregating filepath records.\n",
      "2024-10-21 17:57:55,354 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:57:55,354 - thor.track - INFO - Tracking anvil.\n",
      "2024-10-21 17:57:55,356 - thor.write.attribute - INFO - Writing anvil attributes from 2010-01-21T12:00:00 to 2010-01-21T13:00:00, inclusive and non-inclusive, respectively.\n",
      "2024-10-21 17:57:57,151 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:57:57,151 - thor.track - INFO - Processing hierarchy level 1.\n",
      "2024-10-21 17:57:57,151 - thor.track - INFO - Tracking mcs.\n",
      "2024-10-21 17:57:57,170 - thor.write.mask - INFO - Writing mcs masks to /home/ewan/THOR_output/runs/gridrad_demo_20100121/interval_0/masks/mcs.zarr.\n",
      "2024-10-21 17:57:57,231 - thor.write.attribute - INFO - Writing mcs attributes from 2010-01-21T12:00:00 to 2010-01-21T13:00:00, inclusive and non-inclusive, respectively.\n",
      "2024-10-21 17:58:09,300 - thor.match.match - INFO - Matching mcs objects.\n",
      "2024-10-21 17:58:09,751 - thor.match.match - INFO - Updating object record.\n",
      "2024-10-21 17:58:09,867 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:58:10,745 - thor.track - INFO - Processing 2010-01-21T13:10:00.\n",
      "2024-10-21 17:58:10,746 - thor.data.gridrad - INFO - Updating gridrad dataset for 2010-01-21T13:10:00.\n",
      "2024-10-21 17:58:10,746 - thor.data.gridrad - INFO - Converting gridrad data from nexrad_3d_v4_2_20100121T131000Z.nc\n",
      "2024-10-21 17:58:22,397 - thor.track - INFO - Processing hierarchy level 0.\n",
      "2024-10-21 17:58:22,397 - thor.track - INFO - Tracking convective.\n",
      "2024-10-21 17:58:41,632 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:58:41,632 - thor.track - INFO - Tracking middle.\n",
      "2024-10-21 17:58:46,797 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:58:46,797 - thor.track - INFO - Tracking anvil.\n",
      "2024-10-21 17:58:48,515 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:58:48,515 - thor.track - INFO - Processing hierarchy level 1.\n",
      "2024-10-21 17:58:48,515 - thor.track - INFO - Tracking mcs.\n",
      "2024-10-21 17:58:48,534 - thor.write.mask - INFO - Writing mcs masks to /home/ewan/THOR_output/runs/gridrad_demo_20100121/interval_0/masks/mcs.zarr.\n",
      "2024-10-21 17:59:01,456 - thor.match.match - INFO - Matching mcs objects.\n",
      "2024-10-21 17:59:02,024 - thor.match.match - INFO - Updating object record.\n",
      "2024-10-21 17:59:02,164 - thor.attribute.attribute - INFO - Recording object attributes.\n",
      "2024-10-21 17:59:03,119 - thor.write.attribute - INFO - Writing convective attributes from 2010-01-21T13:00:00 to 2010-01-21T14:00:00, inclusive and non-inclusive, respectively.\n",
      "2024-10-21 17:59:03,120 - thor.write.attribute - INFO - Writing middle attributes from 2010-01-21T13:00:00 to 2010-01-21T14:00:00, inclusive and non-inclusive, respectively.\n",
      "2024-10-21 17:59:03,120 - thor.write.attribute - INFO - Writing anvil attributes from 2010-01-21T13:00:00 to 2010-01-21T14:00:00, inclusive and non-inclusive, respectively.\n",
      "2024-10-21 17:59:03,121 - thor.write.attribute - INFO - Writing mcs attributes from 2010-01-21T13:00:00 to 2010-01-21T14:00:00, inclusive and non-inclusive, respectively.\n",
      "2024-10-21 17:59:03,195 - thor.write.filepath - INFO - Writing gridrad filepaths from 2010-01-21T13 to 2010-01-21T14, inclusive and non-inclusive, respectively.\n",
      "2024-10-21 17:59:03,199 - thor.write.attribute - INFO - Aggregating attribute files.\n",
      "2024-10-21 17:59:03,396 - thor.write.filepath - INFO - Aggregating filepath records.\n"
     ]
    }
   ],
   "source": [
    "# num_processes = int(0.75 * os.cpu_count())\n",
    "# num_processes = os.cpu_count()\n",
    "num_processes = 2\n",
    "\n",
    "with log.logging_listener(), multiprocessing.get_context(\"spawn\").Pool(\n",
    "    initializer=parallel.initialize_process, processes=num_processes\n",
    ") as pool:\n",
    "    results = []\n",
    "    for i, time_interval in enumerate(intervals):\n",
    "        time.sleep(1)\n",
    "        args = [i, time_interval, data_options.copy(), grid_options.copy()]\n",
    "        args += [track_options.model_copy(), visualize_options]\n",
    "        args += [output_parent, \"gridrad\"]\n",
    "        args = tuple(args)\n",
    "        results.append(pool.apply_async(parallel.track_interval, args))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    parallel.check_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 17:59:13,866 - thor.parallel - INFO - Stitching all attribute, mask and record files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 17:59:16,448 - thor.parallel - INFO - Stitching record files.\n",
      "2024-10-21 17:59:16,477 - thor.parallel - INFO - Stitching attribute files.\n",
      "2024-10-21 17:59:16,958 - thor.parallel - INFO - Stitching mask files.\n"
     ]
    }
   ],
   "source": [
    "parallel.stitch_run(output_parent, intervals, cleanup=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>convective_contained</th>\n",
       "      <th>anvil_contained</th>\n",
       "      <th>velocity</th>\n",
       "      <th>area</th>\n",
       "      <th>offset</th>\n",
       "      <th>major_axis</th>\n",
       "      <th>axis_ratio</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th>universal_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-21 12:00:00</th>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2010-01-21 12:10:00</th>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2010-01-21 12:20:00</th>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2010-01-21 12:30:00</th>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2010-01-21 12:40:00</th>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2010-01-21 12:50:00</th>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2010-01-21 13:00:00</th>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2010-01-21 13:10:00</th>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2010-01-21 13:20:00</th>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2010-01-21 13:30:00</th>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2010-01-21 13:40:00</th>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2010-01-21 13:50:00</th>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  convective_contained  anvil_contained  \\\n",
       "time                universal_id                                          \n",
       "2010-01-21 12:00:00 1                             True             True   \n",
       "2010-01-21 12:10:00 1                             True             True   \n",
       "                    2                             True             True   \n",
       "2010-01-21 12:20:00 1                             True             True   \n",
       "                    3                             True             True   \n",
       "2010-01-21 12:30:00 1                             True             True   \n",
       "                    3                             True             True   \n",
       "2010-01-21 12:40:00 1                             True             True   \n",
       "                    3                             True             True   \n",
       "2010-01-21 12:50:00 1                             True             True   \n",
       "                    3                             True             True   \n",
       "2010-01-21 13:00:00 1                             True             True   \n",
       "                    3                             True             True   \n",
       "2010-01-21 13:10:00 1                             True             True   \n",
       "                    3                             True             True   \n",
       "2010-01-21 13:20:00 1                             True             True   \n",
       "                    3                             True             True   \n",
       "2010-01-21 13:30:00 1                             True             True   \n",
       "                    3                             True             True   \n",
       "                    4                             True             True   \n",
       "2010-01-21 13:40:00 1                             True             True   \n",
       "                    3                             True             True   \n",
       "2010-01-21 13:50:00 1                             True             True   \n",
       "                    3                             True             True   \n",
       "                    5                             True             True   \n",
       "\n",
       "                                  velocity  area  offset  major_axis  \\\n",
       "time                universal_id                                       \n",
       "2010-01-21 12:00:00 1                 True  True    True        True   \n",
       "2010-01-21 12:10:00 1                 True  True    True        True   \n",
       "                    2                 True  True    True        True   \n",
       "2010-01-21 12:20:00 1                 True  True    True        True   \n",
       "                    3                 True  True    True        True   \n",
       "2010-01-21 12:30:00 1                 True  True    True        True   \n",
       "                    3                 True  True    True        True   \n",
       "2010-01-21 12:40:00 1                 True  True    True        True   \n",
       "                    3                 True  True    True        True   \n",
       "2010-01-21 12:50:00 1                 True  True    True        True   \n",
       "                    3                 True  True    True        True   \n",
       "2010-01-21 13:00:00 1                 True  True    True        True   \n",
       "                    3                 True  True    True        True   \n",
       "2010-01-21 13:10:00 1                 True  True    True        True   \n",
       "                    3                 True  True    True        True   \n",
       "2010-01-21 13:20:00 1                 True  True    True        True   \n",
       "                    3                 True  True    True        True   \n",
       "2010-01-21 13:30:00 1                 True  True    True        True   \n",
       "                    3                 True  True    True        True   \n",
       "                    4                 True  True    True        True   \n",
       "2010-01-21 13:40:00 1                 True  True    True        True   \n",
       "                    3                 True  True    True        True   \n",
       "2010-01-21 13:50:00 1                 True  True    True        True   \n",
       "                    3                 True  True    True        True   \n",
       "                    5                 True  True    True        True   \n",
       "\n",
       "                                  axis_ratio  duration  \n",
       "time                universal_id                        \n",
       "2010-01-21 12:00:00 1                  False      True  \n",
       "2010-01-21 12:10:00 1                  False      True  \n",
       "                    2                   True     False  \n",
       "2010-01-21 12:20:00 1                  False      True  \n",
       "                    3                   True      True  \n",
       "2010-01-21 12:30:00 1                  False      True  \n",
       "                    3                   True      True  \n",
       "2010-01-21 12:40:00 1                  False      True  \n",
       "                    3                   True      True  \n",
       "2010-01-21 12:50:00 1                  False      True  \n",
       "                    3                   True      True  \n",
       "2010-01-21 13:00:00 1                  False      True  \n",
       "                    3                   True      True  \n",
       "2010-01-21 13:10:00 1                  False      True  \n",
       "                    3                   True      True  \n",
       "2010-01-21 13:20:00 1                  False      True  \n",
       "                    3                   True      True  \n",
       "2010-01-21 13:30:00 1                  False      True  \n",
       "                    3                   True      True  \n",
       "                    4                   True     False  \n",
       "2010-01-21 13:40:00 1                  False      True  \n",
       "                    3                   True      True  \n",
       "2010-01-21 13:50:00 1                  False      True  \n",
       "                    3                   True      True  \n",
       "                    5                  False     False  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_options = analyze.mcs.analysis_options()\n",
    "analyze.mcs.process_velocities(output_parent, profile_dataset=None)\n",
    "analyze.mcs.quality_control(output_parent, analysis_options)\n",
    "# analyze.mcs.classify_all(output_parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 14:15:23,340 - thor.visualize.attribute - INFO - Visualizing MCS at time 2010-01-20T22:00:00.000000000.\n",
      "2024-10-22 14:15:27,860 - thor.visualize.horizontal - INFO - No figsize provided. Using default.\n",
      "2024-10-22 14:15:35,152 - thor.visualize.attribute - INFO - Saving mcs_velocity_analysis figure for 2010-01-20T22:00:00.000000000.\n",
      "2024-10-22 14:15:48,090 - thor.visualize.attribute - INFO - Visualizing MCS at time 2010-01-20T22:10:00.000000000.\n",
      "2024-10-22 14:15:52,103 - thor.visualize.horizontal - INFO - No figsize provided. Using default.\n",
      "2024-10-22 14:15:59,894 - thor.visualize.attribute - INFO - Saving mcs_velocity_analysis figure for 2010-01-20T22:10:00.000000000.\n",
      "2024-10-22 14:16:14,618 - thor.visualize.attribute - INFO - Visualizing MCS at time 2010-01-20T22:20:00.000000000.\n",
      "2024-10-22 14:16:18,752 - thor.visualize.horizontal - INFO - No figsize provided. Using default.\n",
      "2024-10-22 14:16:25,972 - thor.visualize.attribute - INFO - Saving mcs_velocity_analysis figure for 2010-01-20T22:20:00.000000000.\n",
      "2024-10-22 14:16:39,748 - thor.visualize.attribute - INFO - Visualizing MCS at time 2010-01-20T22:30:00.000000000.\n",
      "2024-10-22 14:16:43,735 - thor.visualize.horizontal - INFO - No figsize provided. Using default.\n",
      "2024-10-22 14:16:50,902 - thor.visualize.attribute - INFO - Saving mcs_velocity_analysis figure for 2010-01-20T22:30:00.000000000.\n",
      "2024-10-22 14:17:03,974 - thor.visualize.attribute - INFO - Visualizing MCS at time 2010-01-20T22:40:00.000000000.\n",
      "2024-10-22 14:17:08,135 - thor.visualize.horizontal - INFO - No figsize provided. Using default.\n",
      "2024-10-22 14:17:15,000 - thor.visualize.attribute - INFO - Saving mcs_velocity_analysis figure for 2010-01-20T22:40:00.000000000.\n",
      "2024-10-22 14:17:28,113 - thor.visualize.attribute - INFO - Visualizing MCS at time 2010-01-20T22:50:00.000000000.\n",
      "2024-10-22 14:17:32,200 - thor.visualize.horizontal - INFO - No figsize provided. Using default.\n",
      "2024-10-22 14:17:39,857 - thor.visualize.attribute - INFO - Saving mcs_velocity_analysis figure for 2010-01-20T22:50:00.000000000.\n",
      "2024-10-22 14:17:53,950 - thor.visualize.attribute - INFO - Visualizing MCS at time 2010-01-20T23:00:00.000000000.\n",
      "2024-10-22 14:17:58,036 - thor.visualize.horizontal - INFO - No figsize provided. Using default.\n",
      "2024-10-22 14:18:06,350 - thor.visualize.attribute - INFO - Saving mcs_velocity_analysis figure for 2010-01-20T23:00:00.000000000.\n",
      "2024-10-22 14:18:21,324 - thor.visualize.visualize - INFO - Animating mcs_velocity_analysis figures for mcs objects.\n",
      "2024-10-22 14:18:21,336 - thor.visualize.visualize - INFO - Saving animation to /home/ewan/THOR_output/runs/gridrad_demo_20100120/visualize/mcs_velocity_analysis.gif.\n"
     ]
    }
   ],
   "source": [
    "figure_options = visualize.option.horizontal_attribute_options(\n",
    "    \"mcs_velocity_analysis\", style=\"presentation\", attributes=[\"velocity\", \"offset\"]\n",
    ")\n",
    "start_time = np.datetime64(\"2010-01-20T22:00\")\n",
    "end_time = np.datetime64(np.datetime64(\"2010-01-20T23:00\"))\n",
    "args = [output_parent, start_time, end_time, figure_options]\n",
    "args_dict = {\"parallel_figure\": False, \"dt\": 7200, \"by_date\": False, \"num_processes\": (os.cpu_count()-2)}\n",
    "visualize.attribute.mcs_series(*args, **args_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "THOR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
